
{
    
    
    
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
        
        
        
    
    "pages": [{"date":"2024-06-07","image":"","imageAlt":"","link":"https://0xttfx.github.io/pages/about/","summary":"Desc Text.","tags":["Linux"],"text":"üññ üè¥‚Äç‚ò†Ô∏è\nhey! i\u0026rsquo;m faioli, aka 0xttfx\nafter more than 25 years of experience, i think i\u0026rsquo;m an expert in it infrastructure, unix and linux systems administrator, cloud computing, platform engineer, {s,n} re, cyber security, geek and üè¥‚Äç‚ò†Ô∏è hacker culture enthusiast\ni also had the pleasure of being invited by the fearless friend @coffinix through the master @cybernetus to be a founding member (with the train already moving under the tracks\u0026hellip;) of area31 hackerspace - minas gerais - brazil üè¥‚Äç‚ò†Ô∏è\nthis blog is about me, unix, linux, infrastructure, cyber security, hacker culture and what i feel like talking about :)\nhave fun at this place and get in touch if you want\u0026hellip;\n","title":"About"},{"date":"2024-01-23","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadmin-windowsservertroubleshooting/","summary":"Desc Text.","tags":["Linux"],"text":"aqui temos uma abordagem simples de identifica√ß√£o de causa raiz para troubleshooting em ambientes microsoft windows server.\ncomo exemplo estou usando um problema, que a equipe microsoft de uma multinacional, enfrentou com um produto de mercado que estava causando um alto uso de non-paged pool memory(memory leak). e que causou, durante uma rotina de madrugada, o travamento de +500 servidores\u0026hellip;\neu era de uma equipe multidiciplinar. respons√°vel por virtualiza√ß√£o, storage, backup, unix e linux e acabei me envolvendo pois as equipes de seguran√ßa e microsoft estavam apenas trocando acusa√ß√µes e ainda n√£o identificado a causa raiz\u0026hellip; problema verificado que o non-paged pool est√° com tamanho anormal\nconforme documenta√ß√£o da microsoft, o non-paged pool, pode ocupar at√© 75% da mem√≥ria f√≠sica.\npor√©m n√£o deve ser considerado como \u0026ldquo;normal\u0026rdquo; o grande uso da mesma, principalmente sem uma investiga√ß√£o etc\u0026hellip; o non-paged pool s√£o dados na ram do computador usados ‚Äã‚Äãpelo kernel e pelos drivers do sistema operacional.\nnon-paged pool nunca √© enviado para o disco (page cache)! sempre ficar√° armazenado na mem√≥ria f√≠sica. conforme a minha viv√™ncia, leak de mem√≥ria, √© quando um programa que armazena dados no pool de mem√≥ria n√£o pagin√°vel do sistema faz \u0026ldquo;merda\u0026rdquo;. simples assim!\ninvestiga√ß√£o identificando o que est√° utilizando os pools memory no servidor wind√£o.\npara o troubleshooting de pool memory √© usada a ferramenta poolmon que √© um monitor que exibe dados que o wind√£o coleta sobre aloca√ß√µes de mem√≥ria dos pools de kernel paginados e n√£o paginados do sistema\u0026hellip; os dados s√£o agrupados por marca de aloca√ß√£o de pool que evidencia as tags que identificam o software etc\u0026hellip; chega de conversa! para tanto abra o command ou power shell e navegue at√© a pasta em que o execut√°vel \u0026ldquo;poolmon.exe\u0026rdquo;¬†est√° localizado:\npode-se executar a ferramenta para que seja gerado um log: c:\\temp\\windows kits\\10\\tools\\x64\u0026gt; poolmon -b -n c:\\temp\\log_poolmon.txt ou imprimir na stdout: c:\\temp\\windows kits\\10\\tools\\x64\u0026gt; poolmon -b ‚Äú-b‚Äù executa o aplicativo e organiza os processos em ordem de consumo. aqui conseguimos ver que no topo da lista, temos o processo com maior consumo de ram \u0026ldquo;5053046496\u0026rdquo; bytes e sua tag √© \u0026ldquo;nfes\u0026rdquo;. a tag √© um valor √∫nico e que √© dado pela fabricante do driver. 5053046496¬†/ 1024 = 4.934.615,... / 1024 = 4.818,... / 1024 = 4,7...gb com a tag em m√£os, deve-se usar a ferramenta findstr que procura por cadeia de caracteres! dessa forma vamos tentar localizar o arquivo que possui a tag em seu conte√∫do\u0026hellip;\nvamos em seguida acessar o diret√≥rio de drives no windows: path: c:\\windows\\system32\\drivers c:\\\u0026gt; cd c:\\windows\\system32\\drivers e executar a tool para a busca da tag c:\\windows\\system32\\drivers\\\u0026gt; findstr /m /l /s nfes *.sys c:\\windows\\system32\\drivers\\mfeavfk.sys /l: pesquisa por caracteres literais /m: lista apenas resultados correspondentes /s: pesquisa recursiva bingo\u0026hellip;.\\o/!\nidentificamos com sucesso um aquivo que possui a tag: \u0026ldquo;mfeavfk.sys\u0026rdquo;! agora para tentar identificar o programa que est√° usando esse driver.\nvamos usar a ferramenta sigcheck¬†que mostra metadados como, por exemplo: o n√∫mero da vers√£o do arquivo, carimbo de data/hora e detalhes da assinatura digital etc\u0026hellip; c:\\\u0026gt; sigcheck c:\\windows\\system32\\drivers\\mfeavfk.sys assim identificamos que o propriet√°rio √© o anti-v√≠rus mcafee.\nsobre o arquivo e driver identificado dados do host afetado\nhost: windows server vers√£o: windows server enterprise 2012 r2 x64 vers√µes do produto mcafee:\nmcafee agent - version: 5.6.2.209 mcafee endpoint security plataform - version: 10.6.11910 mcafee endpoint security threat prevention - version: 10.6.11910 informa√ß√µes relevantes dos processos iniciados e drivers utilizados pelo virus scan enterprise no wind√£o:\no driver mfeavfk:\n√© um filtro para verifica√ß√£o de arquivos de sistema e para manter um cache desses arquivos aferidos. o arquivo mfeavfk.sys:\n√© um componente de software do syscore da mcafee que opera como anti-virus filter link para os produtos de seguran√ßa do mcafee. o vse( virusscan enterprise) atrav√©s do driver mfeavfk que opera a n√≠vel de kernel, juntamente com o microsoft filter manager, consegue verificar o v√≠rus em tempo real e de forma aut√¥noma quando arquivos s√£o abertos ou fechados. basicamente √© assim que a mcafee identifica um v√≠rus manipulando arquivos etc\u0026hellip; mfeavfk √© um acr√¥nimo para = mcafee for enterprise anti-virus file link filter driver caracter√≠sticas\nmfeavfk.sys n√£o √© essencial para so e por n√£o ser nativo do sistema causa relativamente poucos problemas. mfeavfk.sys est√° localizado na pasta c:\\windows\\system32\\drivers o tamanho do arquivo no wind√£o tem em m√©dia 91.672 bytes. o driver pode ser iniciado ou parado quando feito de forma can√¥nica. o programa n√£o est√° vis√≠vel no task manager. √© assinado pela verisign. n√£o h√° descri√ß√£o detalhada do servi√ßo. mfeavfk.sys parece ser um arquivo compactado. portanto, a classifica√ß√£o de seguran√ßa t√©cnica √© 0% perigosa; no entanto: ao pesquisar reviews da comunidade a quantidade de problemas relacionados s√£o incont√°veis\u0026hellip; :( pesquisando na documenta√ß√£o t√©cnica do produto, √© informado pelo fabricante, que programas de backup e criptografia tamb√©m usam o mesmo mecanismo:\npor isso, conflitos e at√© mesmo corrompimentos de arquivos, podem ocorrer. at√© mesmo quando um v√≠rus, que possui mecanismo de prote√ß√£o contra o driver \u0026ldquo;mfeavfk\u0026rdquo;, pode gerar problemas cr√≠ticos ao tentar matar o processo que faz uso do driver etc\u0026hellip; continuando com a pesquisa, mas agora, tentando cruzar ocorr√™ncias do driver \u0026ldquo;mfeavfk.sys\u0026rdquo; e leaks de \u0026ldquo;non-paged pool\u0026rdquo; na base de conhecimento mcafee e internet:\no primeiro matching foi certeiro! encontrei diversos casos conhecidos pela mcafee do problema que estamos enfrentando e justamente com a mesma vers√£o de so e anti-v√≠rus üòâ segue link onde o assunto √© extensivamente tratado entre clientes e suporte mcafee link original est√° quebrado! egra√ßado como as fabricantes desaparecem com alguns dados \u0026hellip; mas a waybackmachine salvou uma c√≥pia para a posteridade üòâ logo em seguida, repassei essa investiga√ß√£o para as equipes de seginfo e microfofy para continuidade do troubleshooting\u0026hellip;\nrefer√™ncias\nhttps://kc.mcafee.com/corporate/index?page=content\u0026amp;id=kb65784 https://www.file.net/process/mfeavfk.sys.html https://support.microsoft.com/pt-br/help/177415/how-to-use-memory-pool-monitor-poolmon-exe-to-troubleshoot-kernel-mode https://developer.microsoft.com/pt-br/windows/hardware https://docs.microsoft.com/en-us/sysinternals/downloads/sigcheck https://community.mcafee.com/t5/endpoint-security-ens/nonpaged-pool-memory-leak-mfeavfk-sys-on-multiple-windows-server/td-p/617169 https://docs.microsoft.com/en-us/windows-hardware/drivers/ifs/filter-manager-concepts\n","title":"RTFM \u0026 Aleatoriedades para SysAdmin - Windows Server Troubleshooting"},{"date":"2024-01-21","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadmin-ocspstapling/","summary":"Desc Text.","tags":["Linux","TLS"],"text":"oscp stapling √© o servidor web (e n√£o o navegador) obtendo resposta ocsp com status do certificado armazenando-o em cache, e esses dados s√£o inclu√≠dos nas respostas https junto com o certificado\u0026hellip;\no ocsp¬†-¬†online certificate status protocol, descrita na rfc 2560, √© um protocolo √∫til para determinar o status de um certificado digital x.509 rfc5280 sem exigir crl - certificate revocation lists¬†descrita na rfc 2560 ou como complemento, pois fornece informa√ß√µes oportunas sobre o status de revoga√ß√£o de um certificado (rfc2459 se√ß√£o 3.3) que s√£o utilizados por exemplo por transfer√™ncias de fundos de alto valor ou grandes negocia√ß√µes de a√ß√µes.\no cliente ocsp emite uma solicita√ß√£o de status para um ocsp responder e suspende a aceita√ß√£o do certificado em quest√£o at√© que o responder forne√ßa uma resposta.\numa ocsp request cont√©m os seguintes dados\nvers√£o do protocolo requisi√ß√£o de servi√ßo identificador do certificado de destino extens√µes opcionais que podem ser processadas pelo ocsp responder $ openssl s_client -status -connect 0xttfx.github.io:443 connected(00000003) depth=2 c = us, o = digicert inc, ou = www.digicert.com, cn = digicert global root ca verify return:1 depth=1 c = us, o = digicert inc, cn = digicert tls rsa sha256 2020 ca1 verify return:1 depth=0 c = us, st = california, l = san francisco, o = \u0026#34;github, inc.\u0026#34;, cn = *.github.io verify return:1 ocsp response: ====================================== ocsp response data: ocsp response status: successful (0x0) response type: basic ocsp response version: 1 (0x0) responder id: b76ba2eaa8aa848c79eab4da0f98b2c59576b9f4 produced at: jan 11 12:13:07 2024 gmt responses: certificate id: hash algorithm: sha1 issuer name hash: e4e395a229d3d4c1c31ff0980c0b4ec0098aabd8 issuer key hash: b76ba2eaa8aa848c79eab4da0f98b2c59576b9f4 serial number: 044d72d77cdda702dd5a67f2a23bbdd9 cert status: good this update: jan 11 11:57:01 2024 gmt next update: jan 18 10:57:01 2024 gmt signature algorithm: sha256withrsaencryption signature value: 15:e9:8c:5a:f3:19:e5:22:9a:a1:63:7c:c6:f1:fd:18:34:f3: ea:20:2b:8c:93:63:50:29:17:99:a4:45:72:77:6b:56:8f:68: f4:78:2b:b6:b2:9d:de:09:ac:1f:df:e4:fb:7d:03:9e:7b:aa: 77:ca:58:bf:4b:0a:2d:08:08:ff:ed:7a:49:03:3c:87:08:08: df:1b:be:bc:62:5a:42:fc:32:be:bb:46:7e:1b:ac:6d:a1:e8: f8:38:da:7d:bc:dd:e4:bb:1b:09:ce:e5:1e:4a:97:92:01:f4: 4b:ac:2b:d0:2c:5b:14:d2:29:26:2b:a7:9d:a7:10:93:22:cc: f4:b8:11:66:a4:34:5e:35:c3:2e:0d:e7:38:0c:ae:c1:15:2f: 32:f3:73:59:fb:9c:9c:6d:24:63:e5:7d:54:24:60:ed:a6:bc: 6a:a1:95:49:f1:fc:29:bf:1a:92:9d:a4:a0:0d:e3:df:fd:79: 76:21:76:c1:cf:cd:8e:fa:3d:89:d9:1f:be:39:1a:44:5a:1b: 89:c1:ff:27:ec:37:f2:8b:ae:b2:e7:08:dd:ee:ca:c0:28:ca: 9a:5b:a9:fe:df:fe:9c:94:dd:fb:1f:44:b2:6b:b3:6e:ac:c3: 24:ef:1a:63:e7:3b:dd:1e:6f:29:21:a3:c0:a7:9e:c3:6a:6a: fd:a8:e1:21 ====================================== --- certificate chain 0 s:c = us, st = california, l = san francisco, o = \u0026#34;github, inc.\u0026#34;, cn = *.github.io i:c = us, o = digicert inc, cn = digicert tls rsa sha256 2020 ca1 a:pkey: rsaencryption, 2048 (bit); sigalg: rsa-sha256 v:notbefore: feb 21 00:00:00 2023 gmt; notafter: mar 20 23:59:59 2024 gmt 1 s:c = us, o = digicert inc, cn = digicert tls rsa sha256 2020 ca1 i:c = us, o = digicert inc, ou = www.digicert.com, cn = digicert global root ca a:pkey: rsaencryption, 2048 (bit); sigalg: rsa-sha256 v:notbefore: apr 14 00:00:00 2021 gmt; notafter: apr 13 23:59:59 2031 gmt --- server certificate -----begin certificate----- miihejccbfqgawibagiqbe1y13zdpwldwmfyoju92tanbgkqhkig9w0baqsfadbp mqswcqydvqqgewjvuzevmbmga1uechmmrglnaunlcnqgsw5jmskwjwydvqqdeybe awdpq2vydcbutfmgulnbifniqti1niaymdiwienbmtaefw0ymzaymjewmdawmdba fw0yndazmjaymzu5ntlamgcxczajbgnvbaytalvtmrmweqydvqqiewpdywxpzm9y bmlhmrywfaydvqqhew1tyw4grnjhbmnpc2nvmruwewydvqqkewxhaxridwisielu yy4xfdasbgnvbammcyouz2l0ahvilmlvmiibijanbgkqhkig9w0baqefaaocaq8a miibcgkcaqeaulbgdhov8bggs2tsez+meb7oh/gixbrjmxc7yq/qr75udhhdf8p7 tkvbcyqp8bsj/bmkx2xwsxzt0wkjzbjie7ycqgca4nka+xpe5xb4pkrvoapidfdx 7+34chzbutql0oyebi/5d5llallknogkysaz05foenffaxamqyjhr6kvxfy/dqi4 y7jwrnj6q8f+j6ne1up256uwcl0qlid6e/ta0ld3rymsj0i6xgtqjl26le4/nxxu ylekppvqr0owrha44q7z/1bsdfcgtr+wlngvbew3bwettp7ywjgfp49dwt48v9pi eldgidgvyjcsloz4oqk2vrmna1zbzgck4widaqabo4id0dcca8wwhwydvr0jbbgw foaut2ui6qiqhix56rtad5iyxzv2ufqwhqydvr0obbyefi0chhvazcamqxhpkmp3 qqeyo9w7mhsga1udeqr0mhkccyouz2l0ahvilmlvgglnaxrodwiuaw+cdcouz2l0 ahvilmnvbyikz2l0ahvilmnvbyiod3d3lmdpdgh1yi5jb22cfyouz2l0ahvidxnl cmnvbnrlbnquy29tghvnaxrodwj1c2vyy29udgvudc5jb20wdgydvr0paqh/baqd agwgmb0ga1udjqqwmbqgccsgaqufbwmbbggrbgefbqcdajcbjwydvr0fbighmige mecgpqa8hjpodhrwoi8vy3jsmy5kawdpy2vydc5jb20vrglnaunlcnrutfnsu0ft seeyntyymdiwq0exltquy3jsmecgpqa8hjpodhrwoi8vy3jsnc5kawdpy2vydc5j b20vrglnaunlcnrutfnsu0ftseeyntyymdiwq0exltquy3jsmd4ga1udiaq3mduw mwygz4emaqicmckwjwyikwybbquhagewg2h0dha6ly93d3cuzglnawnlcnquy29t l0nquzb/bggrbgefbqcbaqrzmhewjayikwybbquhmaggggh0dha6ly9vy3nwlmrp z2ljzxj0lmnvbtbjbggrbgefbqcwaoy9ahr0cdovl2nhy2vydhmuzglnawnlcnqu y29tl0rpz2ldzxj0vextulnbu0hbmju2mjaymenbms0xlmnyddajbgnvhrmeajaa miibfgykkwybbahweqieagscaw4eggfqawgadwb2/4g/crb7lvhcycz1h7o0tktn uyncaeikn+zntfo6daaaayz0ghv7aaaeawbimeyciqcqfmfso8mxeevz/fjzqqbb p+vqerduoubvgytton43ewihajt0s27mmgulpqnidadp+jo8c6kyhf+7u6ty74bh xhaaahyac9meirtmlnigih1hneayxhzquv5xgsqma4aqesf3cruaaaggdib1agaa bamarzbfaieagub+xqvanbj2mpcjzbz+lbprkddoeo3op52jdhusw3icif0fnydw qvdtmgqnsns13pappdqwp4/f/jernyski7krahuasldja9qmrzqp5woc+p0w6xxs actw3syb2bu/qznyhhmaaaggdib1sgaabamarjbeaiat/wa2qgghskzqbam84z6q e+dgpqz1acmy52pfsfcw8qigp/sciuzg02x2mbo/midt2hcp4y5d2sc7fe5pthyc pbmwdqyjkozihvcnaqelbqadggebadekgxein/yfywchj6qge5/gcb1udi1l+wn5 umz2ujcqokqcermhuvoyjzdmbxgk0cixxhmiiosd9iyecwxv3+kzq2xl17e3n0zg yoxx2kd7b13rubxqpkoo8ez4ugpywb5ddoretv6pnj9aq2sczodedvs+phikbmi7 d+fm70tnz6/2csdrg5xiu6d/7xyyxpd2xkwku1dx4ukmpa7h9zpyavopcge+twbx lxookcxsnb/12jov3iqsdfxdi41agtfc694kcojlg+ukizpeme53t5/cq37oqchp qnlpyb6pyihua/kgbh84ltba1xedq9i4uyfomijnzezedsfq498= -----end certificate----- subject=c = us, st = california, l = san francisco, o = \u0026#34;github, inc.\u0026#34;, cn = *.github.io issuer=c = us, o = digicert inc, cn = digicert tls rsa sha256 2020 ca1 --- no client certificate ca names sent peer signing digest: sha256 peer signature type: rsa-pss server temp key: x25519, 253 bits --- ssl handshake has read 4060 bytes and written 393 bytes verification: ok --- new, tlsv1.3, cipher is tls_aes_128_gcm_sha256 server public key is 2048 bit this tls version forbids renegotiation. compression: none expansion: none no alpn negotiated early data was not sent verify return code: 0 (ok) --- --- post-handshake new session ticket arrived: ssl-session: protocol : tlsv1.3 cipher : tls_aes_128_gcm_sha256 session-id: 899a5eb90a464a1a310c86986066e2fcfb68aa146c1846809043bc0c7a739186 session-id-ctx: resumption psk: b24e53f7e7ff18d18be22ee2ace052dd858a2226e3f6528e0166a5c90fca50f5 psk identity: none psk identity hint: none srp username: none tls session ticket lifetime hint: 3600 (seconds) tls session ticket: 0000 - 1b bb 4f 78 61 17 18 f9-dd c9 5c 55 da 7e 75 f8 ..oxa.....\\u.~u. 0010 - f7 88 9b a1 26 e4 5f 03-8f b7 3d b2 4f be df ac ....\u0026amp;._...=.o... 0020 - 24 40 e5 4f 46 0d 68 a3-e3 93 76 d0 5f bf 6d 11 $@.of.h...v._.m. 0030 - 8a 31 67 e8 75 5d 1f c2-5f 68 6f e9 27 4c e1 46 .1g.u].._ho.\u0026#39;l.f 0040 - df 8c b2 92 e5 6f bf 0b-48 09 1b d5 b9 19 b7 9e .....o..h....... 0050 - 55 9c 04 b1 28 ae 4e 90-4b 6b c7 a8 0c b1 58 d2 u...(.n.kk....x. 0060 - 46 6a 5c 9c ca 4d ac 52-f5 74 3a 48 78 f7 22 02 fj\\..m.r.t:hx.\u0026#34;. 0070 - b7 ab 64 78 c0 07 3a 62-d3 47 f2 51 48 2a b4 2e ..dx..:b.g.qh*.. 0080 - 96 a7 df a4 cb f1 9b 42-17 a8 0f 03 ba a7 50 63 .......b......pc 0090 - 39 af 34 cd fe 3d b6 52-a1 f2 e9 53 b8 1e ee e1 9.4..=.r...s.... start time: 1705071930 timeout : 7200 (sec) verify return code: 0 (ok) extended master secret: no max early data: 0 --- read r block closed a verifica√ß√£o de status de revoga√ß√£o est√° dispon√≠vel para o certificado de entidade final.\no protocolo v1 sobre http e o tipo de resposta b√°sica s√£o suportados. o status de revoga√ß√£o √© verificado via ocsp quando pelo menos uma destas condi√ß√µes for verdadeira:\nendere√ßo de url de um ocsp responder √© configurado. a verifica√ß√£o da autoridade de acesso √† informa√ß√£o (aia) est√° ativada e o certificado a ser validado tem uma extens√£o aia. a extens√£o aia deve conter um m√©todo de acesso pkik_ad_ad_ocsp com uma uri que indica o local http do responder do ocsp. [!nota] apenas o primeiro ocsp responder que √© identificado na extens√£o aia √© consultado para o status de revoga√ß√£o.\nquando ativado a verifica√ß√£o de url e aia, o url responder √© consultado primeiro.\na ordem pode ser mudada configurando o atributo da api global security kit (gskit) , gsk_ocsp_check_aia_first. consulta para um segundo responder ocorre apenas se o primeiro responder resultar em um status de revoga√ß√£o indeterminado. as sess√µes cliente com processamento de ocsp habilitado podem solicitar a sess√£o do servidor para enviar uma resposta do ocsp como parte da negocia√ß√£o de sess√£o para protocolos tls tlsv1.3 e tlsv1.2.\na sess√£o cliente processa a resposta do ocsp stapling no servidor, eliminando a necessidade do cliente consultar um do ocsp responder para o status de revoga√ß√£o de certificado. uma sess√£o do servidor tamb√©m deve ativar o processamento de solicita√ß√£o de status do certificado, para suportar o stapling do ocsp quando solicitado por um software cliente. ","title":"RTFM\u0026AleatoriedadesParaSysAdmin OCSPStapling"},{"date":"2024-01-09","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadmin-oldntp/","summary":"Desc Text.","tags":["Linux","NTP","RTFM"],"text":"sempre existe a possibilidade de um dia aparecer um servidor com uma vers√£o de so n√£o atual precisando que o ntp client seja configurado ou revisado‚Ä¶ :)\ninstalando o servi√ßo ntp\ninstale o pacote ntp com o utilit√°rio yum $ yum install ntp -y em seguida liste os comandos de administra√ß√£o fornecidos pelo pacote npt $ ntp\u0026lt;tab\u0026gt;\u0026lt;tab\u0026gt; ntpd ntpdate ntpdc ntp-keygen ntpq ntpstat ntptime inicialize o servi√ßo $ sudo service ntpd start ou $ sudo /etc/rc.d/init.d/ntpd start ao iniciar o servi√ßo, analise em seguida os logs no /var/log/messages $ sudo tail /var/log/messages ou $ grep ntpd /var/log/messages jul 23 13:11:51 labcentos01 yum[9343]: installed: ntpdate-4.2.4p83.el6.centos.x86_64 jul 23 13:12:11 labcentos01 ntpd[9375]: ntpd fri feb 22 11:23:27 utc 2013 (1) jul 23 13:12:11 labcentos01 ntpd[9376]: precision = 0.111 usec jul 23 13:12:11 labcentos01 ntpd[9376]: listening on interface #0 wildcard... jul 23 13:12:11 labcentos01 ntpd[9376]: listening on interface #1 wildca... jul 23 13:12:11 labcentos01 ntpd[9376]: listening on interface #2 lo, ::1... jul 23 13:12:11 labcentos01 ntpd[9376]: listening on interface #3 eth0, .... jul 23 13:12:11 labcentos01 ntpd[9376]: listening on interface #4 lo, 127.0.... automatize o servi√ßo para que inicie no boot: $ sudo chkconfig --level 35 ntpd on configura√ß√£o do arquivo padr√£o do servi√ßo ‚Äú/etc/ntp.conf‚Äù\nsegue o arquivo padr√£o fornecido pelo pacote de instala√ß√£o: # be tightened as well, but to do so would effect some of # the administrative functions. restrict 127.0.0.1 restrict -6 ::1 # hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # use public servers from the pool.ntp.org project. # please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst #broadcast 192.168.1.255 autokey # broadcast server #broadcastclient # broadcast client #broadcast 224.0.1.1 autokey # multicast server #multicastclient 224.0.1.1 # multicast client #manycastserver 239.255.254.254 # manycast server #manycastclient 239.255.254.254 autokey # manycast client # enable public key cryptography. #crypto includefile /etc/ntp/crypto/pw # key file containing the keys and key identifiers used when operating # with symmetric key cryptography. keys /etc/ntp/keys # specify the key identifiers which are trusted. #trustedkey 4 8 42 # specify the key identifier to use with the ntpdc utility. #requestkey 8 # specify the key identifier to use with the ntpq utility. #controlkey 8 # enable writing of statistics records. #statistics clockstats cryptostats loopstats peerstat modifique as linhas ‚Äúserver‚Äù, substituindo pelo servidor ntp local; sendo uma linha para cada servidor\u0026hellip; : server 0.redhat.pool.ntp.org iburst server 1.redhat.pool.ntp.org iburst modificando para o ntp brasileiro ou na lan: server 192.0.2.151 iburst ou server a.st1.ntp.br iburst ou server a.ntp.br iburst a flag iburst faz com que uma saraivada de mensagens sejam trocadas para preparar os dados e ajustar o rel√≥gio por cerca de 10s. reinicie o servi√ßo ntp sudo /etc/init.d/ntpd restart agora visualize como ficou o arquivo de configura√ß√£o do servi√ßo ntp: $ sudo cat /etc/ntp.conf |grep -e -v \u0026#34;^$|^#\u0026#34; |nl 1 driftfile /var/lib/ntp/drift 2 restrict default kod nomodify notrap nopeer noquery 3 restrict -6 default kod nomodify notrap nopeer noquery 4 restrict 127.0.0.1 5 restrict -6 ::1 6 server 192.0.2.151 iburst 7 includefile /etc/ntp/crypto/pw 8 keys /etc/ntp/keys outra op√ß√£o interessante para habilitar no ‚Äúntp.conf‚Äù para a configura√ß√£o cliente √© a diretiva de estat√≠sticas: # estatisticas do ntp que exibe informa√µes de funcionamento. statsdir /var/log/ntpstats/ statistics loopstats peerstats filegen loopstats file loopstats type day enable ilegen peerstats file peerstats type day enable verificando se o daemon ntp est√° devidamente configurado e operando:\nexecute o comando ‚Äúntpq‚Äù com a op√ß√£o ‚Äú-c peers‚Äù que lista estat√≠sticas dos servidores cadastrados no arquivo /etc/ntp.conf. $ sudo ntpq -c pe** ou $ sudo ntpq -c peers** se a resposta for algo parecido com a descrita abaixo, o daemon n√£o est√° ativo localhost.localdomain: timed out, nothing received *****request timed out** se a resposta for pr√≥xima da descrita abaixo, o ntp est√° operando: remote refid st t when poll reach delay offset jitter ========================================================================== *192.0.2.151 200.186.125.195 2 u 84 1024 377 0.750 0.138 0.279 segue mais um resultado de um ntp com mais de 1 servidor de horas configurado remote refid st t when poll reach delay\toffset\tjitter ============================================================================= +a.st1.ntp.br .onbr. 1 u 8 64\t1 11.929 -0.405\t1.353 201.49.148.135 .step. 16 u - 64 0 0.000 0.000 0.000 *d.st1.ntp.br .onbr. 1 u 4 64 1 19.496 -0.530\t0.392 -a.ntp.br 200.160.7.186 2 u 4 64 1 11.061 0.117\t1.151 +b.ntp.br 200.20.186.76 2 u - 64 1 14.459 -2.561\t2.544 stratum 16 indica servidor inoperante. compreendendo cada campo offset - mostra em milissegundos o quanto a hora no servidor precisa adiantar ou se atrasar para ficar igual a do servidor ntp ( esses valores devem estar em milissegundos! acima de segundos n√£o √© um bom resultado.) delay mostra o tempo que o pacote demora para ir ao servidor e voltar para o host. jitter mostra o quanto em milissegundos existe de varia√ß√£o nas medidas de deslocamento dos pacotes e, o quanto mais baixo melhor. reach mostra o resultado em octal das √∫ltimas 8 tentativas de conex√£o ao servidor preferencial de horas. o valor esperado √© ‚Äú377‚Äù que indica que as √∫ltimas tentativas obtiveram sucesso! valores diferentes indicam falhas ocorridas. para melhor compreens√£o, √© um registrador de 8 bits que vai girando para a esquerda representado na forma octal, que mostra o resultado das √∫ltimas 8 consultas √† fonte de tempo: 377 = 11.111.111 significa que todas as consultas foram bem sucedidas; outros n√∫mero indicam falhas, por exemplo 375 = 11.111.101, indica que a pen√∫ltima consulta falhou. refid mostra a refer√™ncia (par do sistema) ao qual, o servidor de tempo remoto est√° sincronizado. st mostra o strato da fonte de tempo. when quanto segundos se passaram desde a √∫ltima consulta √† essa fonte de tempo. poll mostra de quantos em quantos segundos essa fonte √© consultada. execute-o novamente com a op√ß√£o ‚Äú-c rv‚Äù para visualizar o estado da hora local $ sudo ntpq -c rv assid=0 status=46f4 leap_add_sec, sync_ntp, 15 events, event_peer/strat_chg, version=\u0026#34;ntpd 4.2.4p8@1.1612-o thu jan 10 15:17:40 utc 2013 (1)\u0026#34;, processor=\u0026#34;x86_64\u0026#34;, system=\u0026#34;linux/2.6.32-279.19.1.el6.x86_64\u0026#34;, leap=01, stratum=3, precision=-24, rootdelay=15.668, rootdispersion=59.025, peer=14178, refid=192.0.2.151, reftime=d59b9d48.ef695513 thu, jul 25 2013 9:49:12.935, poll=10, clock=d59ba39e.61ba5ac8 thu, jul 25 2013 10:16:14.381, state=4, offset=0.073, frequency=7.577, jitter=0.051, noise=0.232, stability=0.018, tai=0 compreendendo os campos version mostra a vers√£o do ntp e sua data e hora de constru√ß√£o. processor mostra a vers√£o e plataforma do hardware. stratum que pode ir de 1 at√© 15 mostra a dist√¢ncia que o servidor ntp usado est√° do o rel√≥gio de refer√™ncia que transmite a hora uct, que por sua vez est√° em stratum-0! lembrando que quanto mais pr√≥ximo o servidor estiver do stratum-0, menos atraso ele ter√° em reala√ß√£o ao uct; ou seja quanto menor a dist√¢ncia melhor\u0026hellip; vari√°vel ‚Äúpeer‚Äù id associado ao servidor ntp preferencial. reftime mostra a data e hora que o servidor preferencial foi atualizado pela √∫ltima vez pelo seu stratum superior. clock data e hora do dia! aquele que foi setado/configurado no seu servidor host. offset deslocamento, quanto o rel√≥gio local tem de ser adiantado ou atrasado para chegar √† hora certa (horaigual √† do estrato 0). precision precis√£o indicada com o expoente de um n√∫mero base 2 vari√°vel ‚Äúrootdisperion‚Äù erro m√°ximo da medida de offset em rela√ß√£o ao strato 0, em milissegundos. rootdelay atraso ou tempo de ida e volta dos pacotes at√©o strato 0, em milissegundos. refid o par do sistema, ou principal refer√™ncia. frequency erro na freq√º√™ncia do rel√≥gio local, em rela√ß√£o √† freq√º√™ncia do estrato 0, em partes por milh√£o (ppm). obtendo informa√ß√µes separadamente de cada servidor ntp configurado! essa forma √© utilizada por exemplo para medir as informa√ß√µes de um servidor ntp secund√°rio afim de tomar alguma decis√£o como a de substituir o servidor preferencial problem√°tico por algum outro do pool\u0026hellip; primeiro liste o id dos servidores ntp configurados com o comando ‚Äúntpq -c as‚Äù: $ sudo ntpq -c as ou sudo ntpq -c associations ind assid\tstatus conf\treach\tauth\tcondition\tlast_event\tcnt ===================================================================== 1 14178\t9614 yes\tyes none\tsys.peer\treachable\t1 depois de obtido o id obtenha as informa√ß√µes do servisor ntp entrando na linha de comando da ferramenta ntpq e utilize a op√ß√£o ‚Äúrv‚Äù seguido do id. $ sudo ntpq [enter] $ sudo ntpq\u0026gt; rv 14178 assid=14178 status=9614 reach, conf, sel_sys.peer, 1 event, event_reach, srcadr=192.0.2.151, srcport=123, dstadr=192.0.2.140, dstport=123, leap=00, stratum=2, precision=-23, rootdelay=16.342,rootdispersion=16.281, refid=200.186.125.195, reach=377, unreach=0, hmode=3, pmode=4, hpoll=10, ppoll=10, flash=00 ok, keyid=0, ttl=0, offset=0.345, delay=1.032, dispersion=14.833, jitter=0.124, reftime=d59c0533.3051b8eb thu, jul 25 2013 17:12:35.188, org=d59c0552.e99941c5 thu, jul 25 2013 17:13:06.912, rec=d59c0552.e9a47a2b thu, jul 25 2013 17:13:06.912, xmt=d59c0552.e95ea055 thu, jul 25 2013 17:13:06.911, filtdelay= 1.03 1.12 1.22 1.10 0.64 1.30 1.57 1.09, filtoffset= 0.34 0.22 0.00 -0.01 0.16 -0.41 -0.41 -0.32, filtdisp= 0.00 15.38 30.75 46.11 61.50 76.85 92.22 107.58 caso precise gerar alguma evid√™ncia para documenta√ß√£o, etc\u0026hellip; √© poss√≠vel gerar gr√°ficos utilizando os logs de estat√≠sticas do diret√≥rio ‚Äú/var/log/ntpstats‚Äù, que s√£o:\nloopstats, que apresenta as informa√ß√µes do loop local, ou seja, as vari√°veis do sistema. formato 54475 73467.286 -0.000057852 31.695 0.000015298 0.006470 4 54475 73548.286 -0.000084064 31.688 0.000017049 0.006471 4 54475 73682.286 -0.000077221 31.678 0.000016130 0.006988 4 54475 73698.286 -0.000077448 31.677 0.000015103 0.006550 4 54475 73761.286 -0.000083230 31.672 0.000014275 0.006376 4 54475 73889.286 -0.000059100 31.665 0.000015846 0.006487 4 54475 74004.285 -0.000045825 31.660 0.000015548 0.006324 4 - campos: - coluna 1: day - coluna 2: second - coluna 3: offset - coluna 4: drift compensation - coluna 5: estimed error - coluna 6: stability - coluna 7: polling interval peerstats que apresenta as informa√ß√µes de cada associa√ß√£o formato 54475 34931.294 200.20.186.75 9074 0.009958844 0.008390600 0.000390895 0.000132755 54475 34931.301 200.192.232.43 f0f4 0.000348814 0.015550265 0.001120348 0.000023645 54475 34932.303 200.189.40.28 f0f4 0.000810708 0.017701986 0.188995109 0.000043145 54475 34934.286 200.160.0.28 f0d4 0.000332344 0.000271801 0.000620139 0.000037467 54475 34935.286 200.160.7.165 9614 0.000003557 0.000216088 0.000826694 0.000022076 - campos - coluna 1: day - coluna 2: second - coluna 3: address - coluna 4: status - coluna 5: offset - coluna 6: delay - coluna 7: dispersion - coluna 8: skew/variance al√©m de poder ser usado para documenta√ß√£o, tamb√©m fica mais f√°cil a leitura com o gr√°fico para ilustr√°-lo. excell pode ser usado\u0026hellip; mas porque n√£o usar terminal e gnuplot :). segue algumas refer√™ncias: ibm segue um exemplo de uso: crie um arquivo texto com um nome pretendido, com o seguinte conte√∫do: cat \u0026lt;\u0026lt;fin\u0026gt; /tmp/deslocamento.txt set term gifset output \u0026#39;deslocamento.png\u0026#39; set title \u0026#34;deslocamento\u0026#34; plot \u0026#34;/var/log/ntpstats/loopstats\u0026#34; using 2:3 t\u0026#34;deslocamento\u0026#34; with linespoints lt rgb \u0026#34;#d82886\u0026#34;; fin estamos referenciando o arquivo loopstats e, fazendo uso das colunas 2 e 3! a coluna 2 indica o tempo, no dia, em segundos; e a coluna 3 indica o deslocamento, em milissegundos. tamb√©m estamos utilizando cores rgb declarada em hexadecimal. agora geramos o gr√°fico $ gnuplot /tmp/deslocamento.txt ","title":"RTFM \u0026 Aleatoriedades Para SysAdmin - Old NTP Client"},{"date":"2024-01-06","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadminsecopsdevopssnre-ntcdocker/","summary":"Desc Text.","tags":["first"],"text":"o intuito desse how to √© apoiar na solu√ß√£o de problemas rede de containers docker\ndisclaimer se caiu aqui no momento em que est√° tentando apagar um incendio: voc√™ est√° no lugar errado!\nmas retorne depois do incendio .. ;) requeriments para fazer um debug descente, precisamos estar familiarizados com quest√µes b√°sicas!\ncomo as coisas \u0026ldquo;funfam\u0026rdquo; dabaixo do cap√¥ da containeriza√ß√£o namespaces linux fornecem as tecnologias fundamentais da implementa√ß√£o de containers. fornecendo isolamento de recursos globais entre processos independentes\nnamespaces fornece isolamento e n√£o restri√ß√£o ao hardware adjacente! isso √© papel do cgroups s√£o 8 namespaces at√© o momento\nmount - mount points cria uma hierarquia de diret√≥rios isolado do sistema de arquivos do host, visivel apenas pelo processo em execu√ß√£o nessa √°rvore de diret√≥rios do namespace. uts - hostname and nis domain name cria isolamento dos identificadores hostname e o nis domain name que s√£o definidos usando sethostname(2), setdomainname(2) e pode ser recuperado usando uname(2) , gethostname(2) e getdomainname(2) . ipc - system v ipc, posix message queues isolam sysvipc(7) - system v objetos ipc e mq_overview(7) - posix filas de mensagens. dessa forma, o namespace tem seus identificadores ipc e filas de mensageria posix pr√≥prios, vistos apenas pelos processos que executam nele. pid - process ids cria espa√ßo do n√∫mero de id do processo isolados do host. permite que o processo containerizado fa√ßa uso do recurso bem legal, o freezing of tasks que permite suspender um conjunto de processos de um cont√™iner e migralos para outro container, em outro host, enquanto os processos internos mant√™m os mesmos pids\u0026hellip; agrade√ßa ao freezing tasks pelas m√°gicas no seu notebook ao hibernar\u0026hellip; network - network devices, stacks, ports, etc. fornecem isolamento dos dispositivos de rede, pilhas de protocolos ip v4 e v6, tabelas de roteamento ip, regras de firewall, os diret√≥rios /proc/net (link para /proc/ pid /net ), /sys/class/net , arquivos em /proc/sys/net , soquetes etc\u0026hellip; bem como tamb√©m dos soquetes abstratos do domain unix(7). tanto uma interface de rede f√≠sica, quanto uma veth(4) user - user and group ids faz isolamento dos recursos credentials(7) que s√£o os identificadores relacionados √† seguran√ßa e atributos, em particular, ids de usu√°rio e ids de grupo, o diret√≥rio raiz, keyrings(7) e capabilities(7). cgroup - cgroup root directory faz o isolamento virtualizando a vis√£o do cgroups(7) por um processo via /proc/pid/cgroup e /proc/pid/mountinfo. dessa forma o namespace possui seu pr√≥prio conjunto de diret√≥rios raiz cgroup, que s√£o os caminhos relativos dos registros correspondentes no arquivo /proc/pid/cgroup, quando um processo cria um novo namespace usando clone(2) ou unshare(2) com a flag clone_newcgroup\u0026hellip; time - boot and monotonic clocks o time afeta afeta v√°rias apis como o clock_gettime(2), clock_nanosleep(2), nanosleep(2), timer_settime(2), timerfd_settime(2) e /proc/uptime, fazendo a virtualiza√ß√£o isolada dos rel√≥gios de sistema: clock_monotonic (e tamb√©m clock_monotonic_coarse e clock_monotonic_raw ), um rel√≥gio n√£o configur√°vel que representa um tempo mon√≥tono desde ent√£o(conforme descrito por posix - \u0026ldquo;algun ponto n√£o especificado no passado\u0026rdquo;). clock_boottime (e tamb√©m clock_boottime_alarm ), um rel√≥gio n√£o configur√°vel que √© id√™ntico a clock_monotonic , exceto que tamb√©m inclui qualquer momento em que o sistema est√° suspenso. dessa forma j√° conseguimos tridimensionalizar mentalmente que:\na coisa toda √© meio que um processo containerizado por recursos que o fazem rodar em um diret√≥rio onde existir√° um sistema de arquivos, fazendo com que o processo o veja como o uma arvore filesystem, com seus pid/gid e pilha de rede, hostname e domainname / nisdomainname bem como as chamadas ipc e rel√≥gios de sistema isolados do host hospedeiro.. aqui vale lembrar que esses namespaces n√£o s√£o de propriedade do processo! eles operam de forma independente qualquer outro processo pode ser containerizado nesses namespaces j√° existentes, dessa forma compatilhando-os\u0026hellip; e de forma independente pois voc√™ pode executar um processo dentro de um namespace network, sem que ele tenha um mount e uts por exemplo isso √© massa porque √© poss√≠vel usar um comando que existe no host, por√©m a execu√ß√£o ser√° dentro de um namespace! por isso, n√£o √© necess√°rio instalar uma tool em um mount de um processo containerizado para fazer teste ou debug\u0026hellip; o que nos interessa √© o namespace network! por isso, apesar de eu explorar outros pontos, nesse nivelamento: network √© o nosso foco\ncontinua\u0026hellip; ","title":"RTFM \u0026 Aleatoriedades Para SysAdmin, SecOps, DevOps,{S,N}RE - Network Trobleshooting Container Docker"},{"date":"2024-01-06","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadmin-swap/","summary":"Desc Text.","tags":["first"],"text":"swapping foi introduzida como um backup em disco para p√°ginas n√£o mapeadas. e existem tr√™s tipos de p√°ginas que devem ser tratadas pelo subsistema de swapping:\npages que pertencem a uma regi√£o de mem√≥ria an√¥nima de um processo (user mode stack) dirty pages que pertencem a um mapeamento de mem√≥ria privada de um processo pages que pertencem a uma regi√£o de mem√≥ria compartilhada ipc numa \u0026ldquo;regular paging\u0026rdquo; cada entrada na \u0026ldquo;page table\u0026rdquo; inclui um sinalizador, uma \u0026ldquo;present flag\u0026rdquo; e o kernel explora esse sinalizador para sinalizar que uma p√°gina pertencente a um espa√ßo de endere√ßo de um processo qualquer foi \u0026ldquo;swapped out\u0026rdquo;! e al√©m desse sinalizador, o linux faz uso dos bits restantes do \u0026ldquo;page table\u0026rdquo; pra armazenar um identificador de \u0026ldquo;swapped-out page\u0026rdquo; que informa a localiza√ß√£o no disco.\na principais caracter√≠sticas do subsistema swapping s√£o:\nconfigura area swap para armazenamento de pages que n√£o possuem \u0026ldquo;disk image\u0026rdquo;. gerencia espa√ßo na √°rea de swap alocando e liberando \u0026ldquo;page slots\u0026rdquo;. fornece a fun√ß√£o de \u0026ldquo;swap out\u0026rdquo; pages da ram para a √°rea de swap e \u0026ldquo;swap in\u0026rdquo; pages da √°rea de swap para ram. faz uso da ‚Äúswapped-out page identifiers‚Äù das entradas na \u0026ldquo;page table\u0026rdquo; que foram swapped para acompanhar as posi√ß√µes dos dados na √°rea de swap. em suma, o swapping √© o principal recurso de \u0026ldquo;page frame reclaiming\u0026rdquo;! e se queremos ter certeza que todos os \u0026ldquo;page frames\u0026rdquo; obtidos por um processo, n√£o apenas os \u0026ldquo;pages\u0026rdquo; que contem \u0026ldquo;disk image\u0026rdquo;, possam ser recuperados pelo pfra, devemos fazer uso do swapping\u0026hellip;\ncom isso podemos deduzir que grandes √°reas de swap d√£o poder ao kernel para iniciar v√°rios processos onde o total de solicita√ß√µes de mem√≥ria ultrapassa a quantidade de ram f√≠sica.\ne como na ti, nem tudo s√£o flores, precisamos nos atentar que simular ram em disco, nos traz um desempenho em milissegundos se comparado aos nanosegundos da ram f√≠sica ;)\n[!note] referencia: daniel p. bovet, marco cesati - understanding the linux kernel - cap√≠tulo 2 - memory addressing e cap√≠tulo 17 - page frame reclaiming\nagora que nivelamos a introdu√ß√£o sobre swapping, vamos criar um espa√ßo de troca, do tipo arquivo, que n√£o muda em nada quando parti√ß√£o em disco: a n√£o ser o processo de particionamento de disco etc\u0026hellip;\nverificando se h√° algum swap sudo swapon --show criando arquivo de swap de 2gib sudo dd if=/dev/zero of=/swapfile count=2192 bs=1mib alterando permiss√£o do arquivo sudo chmod 600 /swapfile marcando o arquivo como um espa√ßo de swap sudo mkswap /swapfile verificando se est√° tudo ok sudo swapon --show adicionando a linha no \u0026lsquo;/etc/fstab\u0026rsquo; para montagem autom√°tica echo \u0026#39;/swapfile none swap sw 0 0\u0026#39; | sudo tee -a /etc/fstab ajustando a configura√ß√£o de swap o par√¢metro /proc/sys/vmwappiness configura a frequ√™ncia com que o sistema transfere dados da ram para o espa√ßo de swap. sendo um¬†valor entre 0 e 100 que representa uma porcentagem! um valor baixo significa que o seu sistema linux troca processos raramente enquanto um alto valor significa que os processos s√£o gravados em disco imediatamente\ncom valores pr√≥ximos de zero, o kernel n√£o ir√° transferir dados para o¬†disco a menos que seja absolutamente necess√°rio. lembre-se, as¬†intera√ß√µes com o arquivo de swap s√£o ‚Äúdispendiosas‚Äù! pois s√£o mais lentas que as intera√ß√µes com a ram. valores que est√£o mais pr√≥ximos de 100 ir√£o tentar colocar mais dados¬†no swap em um esfor√ßo para manter mais espa√ßo da ram livre. dependendo¬†do perfil de mem√≥ria de seus aplicativos ou do motivo pelo qual voc√™¬†est√° usando o seu servidor, isso pode ser melhor em alguns casos. swappiness: 60 swap a partir de 40% de uso de ram. swappiness: 40 swap a partir de 60% de uso de ram. swappiness: 20 swap a partir de 80% de uso de ram. swappiness: 10. swap a partir de 90% de uso de ram. swappiness: 1 swap a partir de 99% de uso de ram. para um desktop, um valor de swappiness de 60 n√£o √© um valor ruim e normalmente √© o valor dfault em uma distro linux. mas para um servidor, podemos deix√°-lo mais pr√≥ximo de 0, para fazer uso somente quando realmente necess√°rio\ncomo exemplo podemos setar para¬†\u0026lsquo;10\u0026rsquo; para que o swap seja utilizado ap√≥s 90% de ram ocupada\nsudo sysctl vm.swappiness=10 para garantir que esse valor ir√° se manter ap√≥s um boot\necho \u0026#39;vm.swappiness=10\u0026#39; | sudo tee -a /etc/sysctl.conf mas como sempre, n√£o h√° uma receita de bolo! em determinados cen√°rios¬†trocar processos de tempo de execu√ß√£o da ram para o disco, deve ser evitado, noutros h√° vantagem\u0026hellip; conhecer a aplica√ß√£o ir√° lhe guiar na configura√ß√£o mais apropriada!\najustando a confiura√ß√£o do vfs_cache_pressure esta op√ß√£o controla a tend√™ncia do kernel de recuperar a mem√≥ria que √© usada para cache de diret√≥rios e objetos inode.\nno valor padr√£o de vfs_cache_pressure=100, o kernel tentar√° recuperar dentries e inodes a uma taxa \u0026ldquo;justa\u0026rdquo; em rela√ß√£o ao pagecache e √† recupera√ß√£o do swapcache. diminuir vfs_cache_pressure faz com que o kernel prefira manter os caches dentry e inode. quando vfs_cache_pressure=0, o kernel nunca recuperar√° dentries e inodes devido √† press√£o de mem√≥ria e isso pode levar facilmente a condi√ß√µes de falta de mem√≥ria. aumentar vfs_cache_pressure al√©m de 100 faz com que o kernel prefira recuperar dentries e inodes. podemos definir isso em um valor mais conservador como 50\nsudo sysctl vm.vfs_cache_pressure=50 vamos garantir que ap√≥s um boot o valor permane√ßa\necho \u0026#39;vm.vfs_cache_pressure=50\u0026#39; | sudo tee -a /etc/sysctl.conf agora sim! vamos ativar o novo espa√ßo de swapping sudo swapon /swapfile ","title":"RTFM \u0026 AleatoriedadesParaSysAdmin - Swap"},{"date":"2024-01-05","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/rtfmaleatoriedadesparasysadmin-journalctl/","summary":"journalctl SystemD","tags":["Linux","SystemD"],"text":"para quando a lei de murphy exerce a sua for√ßa. √© nessa hora, que do seu kit macgyver, voc√™ tira o journalctl para identificar o que pode estar errado!\ndas muitas formas poss√≠veis. tem mais essa:\n$ journalctl --no-pager --since today --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq com a op√ß√£o \u0026ldquo;\u0026ndash;grep\u0026rdquo; filtramos palavras chave com a op√ß√£o \u0026ldquo;\u0026ndash;since\u0026rdquo; melhoramos nossa assertividade. ex: \u0026ndash;since \u0026ldquo;1 hour ago\u0026rdquo; \u0026ndash;since \u0026ldquo;1 minutes ago\u0026rdquo; \u0026ndash;since \u0026ldquo;5 seconds ago\u0026rdquo; \u0026ndash;since 07:00 \u0026ndash;until \u0026ldquo;1 hour ago\u0026rdquo; com o \u0026ldquo;\u0026ndash;output\u0026rdquo; usando o formato json, fazemos um parser amig√°vel pra organizarmos com jq. $ journalctl --no-pager --since today --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq { \u0026#34;_pid\u0026#34;: \u0026#34;5605\u0026#34;, \u0026#34;_systemd_slice\u0026#34;: \u0026#34;user-1000.slice\u0026#34;, \u0026#34;_systemd_user_unit\u0026#34;: \u0026#34;org.gnome.shell@wayland.service\u0026#34;, \u0026#34;_runtime_scope\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;_systemd_unit\u0026#34;: \u0026#34;user@1000.service\u0026#34;, \u0026#34;__seqnum\u0026#34;: \u0026#34;7540847\u0026#34;, ... ... \u0026#34;_systemd_owner_uid\u0026#34;: \u0026#34;1000\u0026#34;, \u0026#34;syslog_identifier\u0026#34;: \u0026#34;google-chrome.desktop\u0026#34;, \u0026#34;_comm\u0026#34;: \u0026#34;cat\u0026#34;, \u0026#34;__monotonic_timestamp\u0026#34;: \u0026#34;285995139402\u0026#34;, \u0026#34;_cmdline\u0026#34;: \u0026#34;cat\u0026#34;, \u0026#34;_boot_id\u0026#34;: \u0026#34;da45ccab9c404e9444444a9c51300cae\u0026#34;, \u0026#34;_exe\u0026#34;: \u0026#34;/usr/bin/cat\u0026#34; } { ... ... ainda √© poss√≠vel filtrar por algum objeto com o jq e quantificar as ocorr√™ncias com sort e uniq\ntalvez, alguns objetos interessantes seriam _exe, _cmdline, _pid, syslog_identifier, message\u0026hellip; $ journalctl --no-pager --since \u0026#34;60 minutes ago\u0026#34; --grep \u0026#39;fail|error|fatal\u0026#39; --output json|jq \u0026#39;.syslog_identifier\u0026#39; | sort | uniq -c 1 \u0026#34;audit\u0026#34; 1 \u0026#34;cupsd\u0026#34; 19 \u0026#34;discord.desktop\u0026#34; 2 \u0026#34;fprintd\u0026#34; 7 \u0026#34;gnome-shell\u0026#34; 10518 \u0026#34;google-chrome.desktop\u0026#34; 18 null 4 \u0026#34;org.gnome.software.desktop\u0026#34; 173 \u0026#34;slack.desktop\u0026#34; ","title":"RTFM \u0026 Aleatoriedades para SysAdmin - journalctl "},{"date":"2023-11-15","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/pagecache/","summary":"Desc Text.","tags":["first"],"text":"ram √© um hardware valioso e caro bem como a sua lat√™ncia √© ainda mais importante que a lat√™ncia do disco. e por isso, o kernel linux tenta ao m√°ximo otimizar os uso da mem√≥ria, fazendo uso de t√©cnicas como compartilhando de p√°ginas entre processos e page cache para melhorar a velocidade de i/o de armazenamento, armazenando um subconjunto de dados do disco na mem√≥ria.\no page cache realiza compartilhamento impl√≠cito de mem√≥ria e de forma ass√≠ncrona com o armazenamento em segundo plano! isso por s√≠ s√≥, traz ainda mais complexidade √† estimativa de uso de mem√≥ria por parte dos administradores!\nmas o que √© page cache o page cache faz parte do virtual file system - vfs que √© uma camada de software do n√∫cleo que trata de todas as chamadas de sistema relacionadas a um sistema de arquivos unix.\nsua principal vantagem √© prover uma interface gen√©rica para diversos tipos de sistemas de arquivos. ou seja, o vfs permite que chamadas de sistemas gen√©ricas, tais como open( ) e read( ),possam ser executadas independentemente do sistema de arquivos usados ou do meio f√≠sico! o que implica diretamente na lat√™ncia de i/o das opera√ß√µes de leitura e grava√ß√£o.\nquando um sistema grava dados no cache, em algum momento tamb√©m deve gravar esses dados no armazenamento. o tempo dessa grava√ß√£o √© controlado pelo que √© conhecido como write policy, e existem duas abordagens b√°sicas de escrita: write-through: a grava√ß√£o √© feita de forma s√≠ncrona tanto no cache quanto no armazenamento de apoio.\nwrite-back: inicialmente, a escrita √© feita apenas no cache. a grava√ß√£o no armazenamento de apoio √© adiada at√© que o conte√∫do modificado esteja prestes a ser substitu√≠do por outro bloco de cache.\nnesse link voc√™ pode ter mais informa√ß√µes sobre o algor√≠timo page √© a unidade de mem√≥ria que o kernel trabalha com page cache, e geralmente possui 4k de comprimento m√≠nimo de armazenamento no page cache.\ndessa forma todo i/o de arquivo est√° alinhado a uma quantidade espec√≠fica de p√°ginas\u0026hellip; at√© aqui, podemos entender que o page cache, √© o principal cache de disco usado pelo kernel do linux e √© utilizado ao ler ou gravar no disco quando novas p√°ginas s√£o adicionadas ao page cache para satisfazer as solicita√ß√µes de leitura dos processos do user mode stack.\nse a p√°gina ainda n√£o estiver no cache, uma nova entrada ser√° adicionada ao cache e preenchida com os dados lidos do disco. se houver mem√≥ria livre suficiente, a p√°gina √© mantida no cache por um per√≠odo indefinido e pode ent√£o ser reutilizada por outros processos sem acessar o disco. da mesma forma, antes de gravar page de dados em um dispositivo de bloco, o kernel verifica se a page correspondente j√° est√° inclu√≠da no cache; caso contr√°rio, uma nova entrada √© adicionada ao cache e preenchida com os dados a serem gravados no disco.\na transfer√™ncia de dados de i/o n√£o come√ßa imediatamente: - a atualiza√ß√£o do disco √© atrasada por alguns segundos, dando assim aos processos a chance de modificar ainda mais os dados a serem gravados em outras palavras, o kernel implementa opera√ß√µes de deferred write as p√°ginas inclu√≠das no page cache podem ser os seguintes tipos:\npages contendo dados de arquivos regulares; no cap√≠tulo 16, descrevemos como o kernel lida com opera√ß√µes de leitura, grava√ß√£o e mapeamento de mem√≥ria neles. pages contendo diret√≥rios; o linux lida com os diret√≥rios de forma muito semelhante aos arquivos normais. pages contendo dados lidos diretamente de arquivos de dispositivos de bloco (ignorando a camada do sistema de arquivos); o kernel os trata usando o mesmo conjunto de fun√ß√µes como para pages contendo dados de arquivos regulares. pages contendo dados de processos do user mode stack que foram trocados em disco; o kernel pode for√ßar a manter-se armazenado em page cache algumas pages cujo conte√∫do j√° foi escrito em uma √°rea de swap. pages pertencentes a arquivos de sistemas de arquivos especiais, como o sistema de arquivos especial shm usado para regi√£o de mem√≥ria compartilhada de comunica√ß√£o entre processos (ipc). como podemos ver, cada page inclu√≠da no page cache cont√©m dados pertencentes a algum arquivo. este arquivo ‚Äì ou mais precisamente o inode do arquivo ‚Äì √© chamado de page‚Äôs owner.\npraticamente todas as opera√ß√µes read() e write() de arquivos dependem do page cache.\na √∫nica exce√ß√£o ocorre quando um processo abre um arquivo com a flag o_direct definido: neste caso, o cache da p√°gina √© ignorado e as transfer√™ncias de dados de e/s fazem uso de buffers no espa√ßo de endere√ßo do modo de usu√°rio do processo. v√°rias aplica√ß√µes database fazem uso da flag o_direct pra que assim possam faze uso do pr√≥prio algor√≠timo de caching\u0026hellip; os projetistas do kernel implementaram o page cache para atender a dois requisitos principais:\nlocalizar rapidamente um page espec√≠fica contendo dados relativos a um determinado propriet√°rio. para aproveitar ao m√°ximo o cache da p√°gina, pesquis√°-lo deve ser uma opera√ß√£o muito r√°pida. acompanhar como cada page do cache deve ser tratada ao ler ou escrever seu conte√∫do. por exemplo, a leitura de uma page de um arquivo regular, ou de um arquivo de dispositivo de bloco ou de uma √°rea de swap, deve ser realizada de diferentes maneiras, portanto o kernel deve selecionar a opera√ß√£o adequada dependendo do propriet√°rio da p√°gina. a unidade de informa√ß√£o mantida no page cache √©, obviamente, uma p√°gina inteira de dados.\numa p√°gina n√£o cont√©m necessariamente blocos de disco fisicamente adjacentes, portanto ela n√£o pode ser identificada por um n√∫mero de dispositivo e um n√∫mero de bloco. em vez disso, uma p√°gina no page cache √© identificada por um propriet√°rio e por um √≠ndice nos dados do propriet√°rio ‚Äì geralmente, um inode e um offset dentro do arquivo correspondente. a estrutura de dados principal do page cache √© o objeto address_space, uma estrutura de dados incorporada no objeto inode propriet√°rio da page.\nmuitas pages no cache podem referir-se ao mesmo propriet√°rio, portanto, podem estar vinculadas ao mesmo objeto address_space que tamb√©m estabelece uma liga√ß√£o entre a pages do propriet√°rios e um conjunto de m√©todos que operam nessas pages. aqui uma uma exce√ß√£o ocorre para p√°ginas que foram trocadas. essas p√°ginas possuem um objeto address_space comum n√£o inclu√≠do em nenhum inode. cada descritor de p√°gina inclui dois campos chamados mapping e index, que vinculam a page ao page cache\no primeiro campo aponta para o objeto address_space do inode propriet√°rio da page. o segundo campo especifica o offset em unidades de page-size dentro do addres_space! ou seja: a posi√ß√£o dos dados da page dentro do disk image propriet√°rio. esses dois campos s√£o usados ao procurar uma p√°gina no cache de p√°ginas.\nmagit√©cnicamente, o cache de p√°ginas pode conter m√∫ltiplas c√≥pias dos mesmos dados do disco. por exemplo, o mesmo bloco de dados de 4 kb de um arquivo normal pode ser acessado das seguintes maneiras:\nlendo o arquivo; os dados s√£o inclu√≠dos em uma page pertencente ao inode do arquivo normal. lendo o bloco do arquivo do dispositivo (parti√ß√£o do disco) que hospeda o arquivo; os dados s√£o inclu√≠dos em uma page pertencente ao master inode do arquivo do dispositivo de bloco. por isso, os dados de um disco aparecem em duas pages diferentes cada uma referenciada por um objeto address_space diferente\u0026hellip;\nabaixo temos a tabela com os campos de um objeto adress_space\ntype field description struct inode * host pointer to the inode hosting this object, if any struct radix_tree_root page_tree root of radix tree identifying the owner‚Äôs pages spinlock_t tree_lock spin lock protecting the radix tree unsigned int i_mmap_writable number of shared memory mappings in the address space struct prio_tree_root i_mmap root of the radix priority search tree struct list_head i_mmap_nonlinear list of non-linear memory regions in the address space spinlock_t i_mmap_lock spin lock protecting the radix priority search tree unsigned int truncate_count sequence counter used when truncating the file unsigned long nrpages total number of owner‚Äôs pages unsigned long writeback_index page index of the last write-back operation on the owner‚Äôs pages struct address_space_ operations * a_ops methods that operate on the owner‚Äôs pages unsigned long flags error bits and memory allocator flag struct backing_dev_info * backing_dev_info pointer to the backing_dev_info of the block device holding the data of this owner spinlock_t private_lock usually, spin lock used when managing the private_list list struct list head private_list usually, a list of dirty buffers of indirect blocks associated with the inode struct address_space * assoc_mapping usually, pointer to the address_space object of the block device including the indirect blocks se o owner de uma page no page cache for um arquivo, o objeto address_space ser√° inserido no campo i_data de um objeto vfs inode.\no campo i_mapping do inode sempre aponta para o objeto address_space do propriet√°rio das pages que cont√™m os dados do inode. o campo host do objeto address_space aponta para o objeto inode no qual o descriptor est√° embutido\u0026hellip; por isso, se uma page pertence a um arquivo armazenado em um sistema de arquivos ext3,\no propriet√°rio da page √© o inode do arquivo e o objeto address_space correspondente √© armazenado no campo i_data do objeto vfs inode. o campo i_mapping do inode aponta para o campo i_data do mesmo inode, e o campo host do objeto address_space aponta para o mesmo inode\u0026hellip; mas como sempre: a \u0026ldquo;treta\u0026rdquo; est√° sempre presente na ti\u0026hellip; :)\nse uma page cont√©m dados, lidos de um arquivo de dispositivo de bloco(onde est√° o dado bruto(raw)), o objeto address_space √© incorporado no master inode do arquivo no sistema de arquivos especial bdev associado ao dispositivo de bloco.\npor isso, o campo i_mapping de um inode de um arquivo de dispositivo de bloco, aponta para o objeto address_space embutido no master inode da mesma forma, o campo host do objeto address_space aponta tamb√©m para o master idone dessa forma, todas as pages contendo dados lidos de um dispositivo de bloco possuem o mesmo objeto address_space, mesmo que tenham sido acessadas de arquivos de dispositivos de bloco diferentes os campos i_mmap, i_mmap_writable, i_mmap_nonlinear e i_mmap_lock referem-se ao mapeamento de mem√≥ria e ao mapeamento reverso.\no campo backing_dev_info aponta o descritor backing_dev_info associado ao dispositivo de bloco que armazena os dados do propriet√°rio.\na estrutura backing_dev_info geralmente √© incorporada no descritor da fila de solicita√ß√µes do dispositivo de bloco. o campo private_list √© o cabe√ßalho de uma lista gen√©rica que pode ser usada livremente pelo sistema de arquivos para seus prop√≥sitos espec√≠ficos.\no ext2 faz uso desse campo coletar os buffers sujos de blocos ‚Äúindiretos‚Äù associados ao inode. \u0026ldquo;buffers sujos\u0026rdquo; s√£o dados ainda n√£o escritos em disco. quando uma opera√ß√£o for√ßa o inode a ser gravado em disco, o kernel tamb√©m libera todos os buffers nesta lista. um campo crucial do objeto address_space √© a_ops.\nele aponta para uma tabela do tipo address_space_operations contendo os m√©todos que definem como as pages dos propriet√°rios s√£o tratadas. os m√©todos mais importantes s√£o: readpage writepage prepare_write commit_write os m√©todos vinculam os propriet√°rios do objetos inode aos drivers de baixo n√≠vel que acessam os dispositivos f√≠sicos.\npor exemplo: a fun√ß√£o que implementa o m√©todo readpage para um inode de um arquivo regular, sabe localizar as posi√ß√µes no dispositivo de disco f√≠sico dos blocos correspondentes a cada page do arquivo\u0026hellip; abaixo podemos ver a tabela de m√©todos do address_space\nmethod description writepage write operation (from the page to the owner‚Äôs disk image) readpage read operation (from the owner‚Äôs disk image to the page) sync_page start the i/o data transfer of already scheduled operations on owner‚Äôs pages writepages write back to disk a given number of dirty owner‚Äôs pages set_page_dirty set an owner‚Äôs page as dirty readpages read a list of owner‚Äôs pages from disk prepare_write prepare a write operation (used by disk-based filesystems) commit_write complete a write operation (used by disk-based filesystems) bmap get a logical block number from a file block index invalidatepage invalidate owner‚Äôs pages (used when truncating the file) releasepage used by journaling filesystems to prepare the release of a page direct_io direct i/o transfer of the owner‚Äôs pages (bypassing the page cache) [!note] referencias: daniel p. bovet, marco cesati - understanding the linux kernel, third edition-o\u0026rsquo;reilly media | page descriptors - cap 8, block device drivers - cap 14 , the page cache - cap 15, accessing files - cap 16 , page frame reclaiming - cap 17 , the ext2 and ext3 filesystems - cap 18.\nat√© aqui j√° conseguimos entender que o mecanismo de cachear arquivos em mem√≥ria de forma transparente, independente de se estar mapeando algo em mem√≥ria, lendo ou escrevendo em disco, deixam as coisas um pouco mais complicadas para um administrador inexperiente ao tentar obter uma aferi√ß√£o de consumo de mem√≥ria\u0026hellip;\npor isso, vamos tentar algumas abordagens para determinar valores mais pr√≥ximos do real para o consumo de mem√≥ria ram.\nrss e vsz vamos come√ßar tendo como referencia o vsz que √© o tamanho da mem√≥ria virtual que o linux concedeu a um processo. mas n√£o necessariamente o processo est√° usando o valor informado. um dos motivos s√£o programas com fun√ß√µes para realizar determinadas tarefas, mas s√≥ as carregam na ram, quando necess√°rio. bem como tamb√©m a pagina√ß√£o por demanda do linux, que s√≥ carrega p√°ginas na mem√≥ria quando o aplicativo tenta us√°-las\u0026hellip; por isso a leitura que devemos fazer do valor √©: mem√≥ria se carregadas todas as suas fun√ß√µes e bibliotecas na mem√≥ria f√≠sica.\nj√° rss, √© o tamanho do conjunto residente. √© a quantidade de ram que o processo no momento para carregar as suas p√°ginas. ainda assim n√£o podemos tomar essa informa√ß√£o como concreta, devido as bibliotecas compartilhadas torna-se um valor impreciso por superestimativa\u0026hellip;\nprimeiro criamos um processo em um novo cgroup\nrodamos o comanod mtr utilizando o systemd-run para isol√°-lo num cgroup(por que sim\u0026hellip;rs) systemd-run --user -p -t -g --wait mtr 8.8.8.8 em seguida coletamos o seu pid e verificamos os valores de rss e vsz\ncom o comando ps coletamos seu pid e os dados de rss e vsz o pid do processo $ ps -aux |grep -e systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39; 236341 e os dados de rss e vsz $ ps -o rss,vsz,cmd -p $(ps -aux |grep -e systemd-run.*mtr | grep -v grep |awk \u0026#39;{print $2}\u0026#39;) rss vsz cmd 7168 14940 systemd-run --user -p -t -g --wait mtr 8.8.8.8 s√≥ a t√≠tulo de cuiriosidade, segue algumas formas de coverter o valor para megabytes: $ echo $((7168/1024)) 7 ou $ echo $((7168/1024)) |xargs -i printf \u0026#34;%\u0026#39;.1f mb\u0026#34; {} 7.0 mb ou $ numfmt --from=si --to=iec 7168k 6.9m ou $ numfmt --from=si --to-unit=1mi --grouping 7168k 7 podemos ver que o processo est√° consumindo 7168 kilobytes.\nem seguida usamos o procfs para ter mais detalhes desse uso de ram que o rss est√° apontando.\nvamos ver o arquivo smaps_rollup que √© uma soma das √°reas de mem√≥ria do smaps do nosso pid $ cat /proc/236341/smaps_rollup 559517c38000-7ffe5c398000 ---p 00000000 00:00 0 [rollup] rss: 7368 kb pss: 1171 kb pss_dirty: 868 kb pss_anon: 868 kb pss_file: 303 kb pss_shmem: 0 kb shared_clean: 6444 kb shared_dirty: 0 kb private_clean: 56 kb private_dirty: 868 kb referenced: 7368 kb anonymous: 868 kb lazyfree: 0 kb anonhugepages: 0 kb shmempmdmapped: 0 kb filepmdmapped: 0 kb shared_hugetlb: 0 kb private_hugetlb: 0 kb swap: 0 kb swappss: 0 kb locked: 0 kb para as m√©tricas listadas rss que j√° √© nossa conhecida. pss proportional set size √© o compartilhamento proporcional de mem√≥ria do processo. √© a contagem de p√°ginas que ele possui na mem√≥ria, onde cada p√°gina √© dividida pelo n√∫mero de processos que a compartilham. portanto, se um processo tiver 1.000 p√°ginas s√≥ para ele e 1.000 compartilhadas com outro processo, seu pss ser√° 1.500. shared_clean aqui vemos que nosso processo usa cache de p√°gina. e representa o maior uso da mem√≥ria. no arquivo smaps, conseguimos ver todas as bibliotecas compartilhadas que foram abertas com mmap() e residem no page cache. shared_dirty quando o processo grava em arquivos com mmap(), esta linha mostra a quantidade de mem√≥ria suja do cache de p√°gina ainda n√£o salva. referenced √© a quantidade de mem√≥ria referenciada ou acessada at√© o momento. o valor √© sempre igual ou pr√≥ximo rss. anonymous mostra a quantidade de mem√≥ria que n√£o pertence a nenhum arquivo. at√© qui podemos ver que, embora o comando ps e top nos mostre um rss de 7mib, a maior parte de seu rss est√° oculto no cache de p√°gina e que quando ficarem inativas por um tempo, essas p√°ginas, ser√£o removidas da ram pelo kernel.\nnesse artigo do lwn.net temos mais informa√ß√µes direto da fonte ;).\ncontinua em breve\u0026hellip; ","title":"Who Page Cache"},{"date":"2023-11-06","image":"","imageAlt":"","link":"https://0xttfx.github.io/posts/ipdo-awsrds/","summary":"DigitalOcean Kubernetes and AWS RDS Security Group","tags":["AWS","DOK","RDS"],"text":"ipdo-awsrds fun√ß√£o scrip bash para descoberta dos ips wan dos docean droplets e inser√ß√£o em security groups ec2 das inst√¢ncias aws rds.\natualiza√ß√µes v0.4 como intev√°lo m√≠nimo de execu√ß√£o na cron s√£o de 60 segundos! e eu precisava executar por mais vezes por minuto acabei contendo o scrip dentro de um la√ßo wile que o executa por 10 vezes com intervalo de 2 segundos v0.5 removido la√ßo de x execu√ß√µes a cada 60s restruturado algumas conditional statement da inser√ß√£o e remo√ß√£o de ips o diff, antes realizado globalmente, agora √© realizado para cada security group v0.6 implementado o builtin set com as options errtrace, errexit, nounset e pipefail para deixar o script mais criterioso quanto a erros principalmente os de apis 5xx sem a necessidade de fazer testes em fun√ß√µes, condi√ß√µes etc. implementado trap para melhor localiza√ß√£o do momento e local do erro. v0.7 implementado arquivo pid. modificado m√©todo de cria√ß√£o de array\u0026rsquo;s espec√≠ficos para uso mapfile melhorias no filtro diff dos arquivos de ips melhorias nos filtros para cria√ß√£o de array ips modificado no la√ßo aninhado de inser√ß√£o e remo√ß√£o de ip para melhora do parser v0.8 implementado tratativa para cod error diff implementado arquivo de diff tempor√°rio para cada sec. group verificado implementado tratativa para cod error na cria√ß√£o de array usando arquivo diff tempor√°rio implementado remo√ß√£o de arquivos tempor√°rios em cada la√ßo v1.0 agora sim! ipdo-awsrds agora √© ga - disponibilidade geral! vers√£o est√°vel para uso em ambiente produ√ß√£o. depend√™ncias aws cli aws cli ec2 api authorize-security-group-ingress api describe-security-groups rds api describe-db-instances digitalocean cli do cli api compute executando crie diret√≥rio tools e tool/log em /usr/local\nmkdir -p /usr/local/tools/log \u0026amp;\u0026amp; cd /usr/local/tools/ \u0026amp;\u0026amp; \\ git clone git@github.com:0xttfx/ipdo-awsrds.git agora criamos o arquivo path-tools.sh em /etc/profile.d/ para configurar o path para diret√≥rio tools\nsudo \u0026gt; /etc/profile.d/path-tools.sh em seguida adicione o conte√∫do:\n# configurando path para incluir diret√≥rio tools caso exista. if [ -d \u0026#34;/usr/local/tools/ipdo-awsrds\u0026#34; ] ; then path=\u0026#34;$path:/usr/local/tools/ipdo-awsrds\u0026#34; fi eof para execu√ß√£o do script √© necess√°rio declarar o user profile aws cli usando a op√ß√£o -u\nipdo-awsrds -u \u0026lt;nome\u0026gt; automa√ß√£o para automa√ß√£o da execu√ß√£o, adicione a seguinte linha na crontab do usu√°rio(crontab -e) n√£o privil√©giado. devido ao update, adi√ß√£o e remo√ß√£o dos n√≥s dos clusters, o script ser√° executado a cada 1 mintuo!\naltere conforme sua necessidade. * * * * * /usr/bin/bash -x /usr/local/tools/ipdo-awsrds -u nome \u0026gt;\u0026gt; /usr/local/tools/log/ipdo-awsrds-$(date --date=\u0026#34;today\u0026#34; +\\%d\\%m\\%y_\\%h\\%m\\%s).log 2\u0026gt;\u0026amp;1 0 0 * * * /usr/bin/find /usr/local/tools/log/ -type f -mtime +5 -name \u0026#39;exec-*.log\u0026#39; -exec rm {} + ","title":"IP DOK Set or Drop Sec Group AWS EC2 RDS"}]
}

