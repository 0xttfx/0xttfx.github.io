[{"categories":["Linux"],"content":" O wttr.in é um serviço de previsão meteorológica para console que suporta vários métodos de representação de informações, como códigos de escape ANSI orientados a terminais para clientes HTTP de console (curl, httpie ou wget), HTML para navegadores web ou PNG para visualizadores gráficos. Não tem segredo! Basta usar uma tool como Client URL - curl para buscar o conteúdo da URL https://wttr.in Seguindo esse exemplo, a página será renderizada já com os dados de geolocalização do seu IP e a previsão para o dia corrente e os próximos 2: $ curl https://wttr.in Weather report: Belo Horizonte, Brazil _`/\"\".-. Shower in vicinity, thunderstorm in vicinity ,\\_( ). +27(29) °C /(___(__) → 12 km/h ⚡‘‘⚡‘‘ 10 km ‘ ‘ ‘ ‘ 0.4 mm ┌─────────────┐ ┌──────────────────────────────┬───────────────────────┤ Wed 22 Jan ├───────────────────────┬──────────────────────────────┐ │ Morning │ Noon └──────┬──────┘ Evening │ Night │ ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤ │ \\ / Sunny │ \\ / Sunny │ _`/\"\".-. Patchy light r…│ _`/\"\".-. Light rain sho…│ │ .-. +24(26) °C │ .-. +30(32) °C │ ,\\_( ). +27(30) °C │ ,\\_( ). 19 °C │ │ ― ( ) ― ↖ 3 km/h │ ― ( ) ― ↓ 3 km/h │ /(___(__) ↗ 5-8 km/h │ /(___(__) ↖ 15-33 km/h │ │ `-’ 10 km │ `-’ 10 km │ ⚡‘‘⚡‘‘ 10 km │ ‘ ‘ ‘ ‘ 10 km │ │ / \\ 0.0 mm | 0% │ / \\ 0.0 mm | 0% │ ‘ ‘ ‘ ‘ 1.4 mm | 100% │ ‘ ‘ ‘ ‘ 1.3 mm | 100% │ └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘ ┌─────────────┐ ┌──────────────────────────────┬───────────────────────┤ Thu 23 Jan ├───────────────────────┬──────────────────────────────┐ │ Morning │ Noon └──────┬──────┘ Evening │ Night │ ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤ │ \\ / Sunny │ _`/\"\".-. Thundery outbr…│ _`/\"\".-. Patchy light r…│ \\ / Clear │ │ .-. +23(25) °C │ ,\\_( ). +28(30) °C │ ,\\_( ). +28(31) °C │ .-. +23(25) °C │ │ ― ( ) ― ← 6-8 km/h │ /(___(__) ↙ 8-9 km/h │ /(___(__) ← 8-12 km/h │ ― ( ) ― ← 10-21 km/h │ │ `-’ 10 km │ ⚡‘‘⚡‘‘ 9 km │ ⚡‘‘⚡‘‘ 10 km │ `-’ 10 km │ │ / \\ 0.0 mm | 0% │ ‘ ‘ ‘ ‘ 0.0 mm | 76% │ ‘ ‘ ‘ ‘ 0.8 mm | 100% │ / \\ 0.0 mm | 0% │ └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘ ┌─────────────┐ ┌──────────────────────────────┬───────────────────────┤ Fri 24 Jan ├───────────────────────┬──────────────────────────────┐ │ Morning │ Noon └──────┬──────┘ Evening │ Night │ ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤ │ \\ / Sunny │ \\ / Sunny │ \\ / Sunny │ \\ / Clear │ │ .-. 22 °C │ .-. +26(27) °C │ .-. +28(30) °C │ .-. +22(25) °C │ │ ― ( ) ― ← 7-10 km/h │ ― ( ) ― ↙ 9-11 km/h │ ― ( ) ― ↙ 9-11 km/h │ ― ( ) ― ← 7-14 km/h │ │ `-’ 10 km │ `-’ 10 km │ `-’ 10 km │ `-’ 10 km │ │ / \\ 0.0 mm | 0% │ / \\ 0.0 mm | 0% │ / \\ 0.0 mm | 0% │ / \\ 0.0 mm | 0% │ └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘ Você pode especificar: o nome da cidade e quando existir espaços basta usar + e se quiser que o output tenha apenas o dia corrente, use o 1 precedido pelo sinal de interrogação ? que é o delimitador que indica que qualquer coisa logo após, será uma opção de formatação de output… : curl wttr.in/Belo+Horizonte $ curl 'wttr.in/Belo+Horizonte?1' Weather report: Belo+Horizonte _`/\"\".-. Thunderstorm, shower in vicinity ,\\_( ). +23(25) °C /(___(__) ↑ 9 km/h ⚡‘‘⚡‘‘ 10 km ‘ ‘ ‘ ‘ 14.9 mm ┌─────────────┐ ┌──────────────────────────────┬───────────────────────┤ Wed 22 Jan ├───────────────────────┬──────────────────────────────┐ │ Morning │ Noon └──────┬──────┘ Evening │ Night │ ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤ │ \\ / Sunny │ _`/\"\".-. Thundery outbr…│ _`/","date":"2025-01-22","objectID":"/posts/rtfmaleatoriedades-climanoterminal/:0:0","tags":["CURL","Terminal","Bash","Shell","Linux","Basics","Wttr"],"title":"RTFM \u0026 Aleatoriedades - Clima No Terminal","uri":"/posts/rtfmaleatoriedades-climanoterminal/"},{"categories":["Linux"],"content":"Só isso ? Não! RTFM Wttr para muito mais opções! Vou também pode acessar o –help via curl curl wttr.in/:help ","date":"2025-01-22","objectID":"/posts/rtfmaleatoriedades-climanoterminal/:1:0","tags":["CURL","Terminal","Bash","Shell","Linux","Basics","Wttr"],"title":"RTFM \u0026 Aleatoriedades - Clima No Terminal","uri":"/posts/rtfmaleatoriedades-climanoterminal/"},{"categories":["Linux"],"content":"Segue uma sugestão de uso: Aqui estamos criando o arquivo meuip_e_clima.sh no diretório ~/.bashrc.d para que sempre que abrir um novo terminal: seja informado o seu IP de WAN atual. o clima do dia e hora corrente. e a criação de um alias na seção atual de nome clima que irá imprimir a saída padrão para a geolocalização do seu IP atual. cat \u003c\u003cUai\u003e ~/.bashrc.d/meuip_e_clima.sh echo \" .... no! ... ... mno! ... ..... mno!! ...................... mnnoo! ... ..... mmno! ......................... mnnoo!! . .... mnoonnoo! mmmmmmmmmmpppoii! mnno!!!! . ... !o! nno! mmmmmmmmmmmmmpppoooii!! no! .... ...... ! mmmmmmmmmmmmmppppooooiii! ! ... ........ mmmmmmmmmmmmpppppooooooii!! ..... ........ mmmmmooooooppppppppoooomii! ... ....... mmmmm.. oppmmp .,omi! .... ...... mmmm:: o.,opmp,.o ::i!! ... .... nnm:::.,,oopm!p,.::::!! .... .. mmnnnnnoooopmo!!iippo!!o! ..... ... mmmmmnnnnoo:!!:!!ippppoo! .... .. mmmmmnnoommnniiipppoo!! ...... ...... mmmonnmmnnniiioo!.......... ....... mn mommmnnniiiiio! oo .......... ......... mno! iiiiiiiiiii oooo ........... ...... nnn.mno! . o!!!!!!!!!o . oono no! ........ .... mnnnnno! ...ooooooooooo . mmnnon!........ ...... mnnnno! .. ppppppppp .. mmnon!........ ...... oo! ................. on! ....... ................................ \" echo \"\u003e\u003e\u003e Get WAN data \" # usando endpoint = https://github.com/Fire-man-x/Public-IP-address---Gnome-shell-extension/blob/master/src/extension.js curl -s https://ipv4.lookup.test-ipv6.com | jq '{type,ip,asn,asn_name,country}' echo \"- - -\" # Clima obtido pela geolocalização do seu IP wan echo \"\u003e\u003e\u003e Get weather\" curl 'wttr.in?format=\"%l:+%t+%m+%p+%P+%w+%h+%c+%C+%T\\n' # criando alias \"clima\" alias clima=\"curl wttr.in\" echo \"\u003e\u003e\u003e May the force be with you ${USER} ...o/\" Uai ","date":"2025-01-22","objectID":"/posts/rtfmaleatoriedades-climanoterminal/:1:1","tags":["CURL","Terminal","Bash","Shell","Linux","Basics","Wttr"],"title":"RTFM \u0026 Aleatoriedades - Clima No Terminal","uri":"/posts/rtfmaleatoriedades-climanoterminal/"},{"categories":["AI"],"content":" A literacia em IA, ou alfabetização em inteligência artificial, é a capacidade de compreender e interagir com a inteligência artificial (IA) de forma crítica e informada. Ou seja: é ter a capacidade de compreender, interagir e participar de maneira crítica e proficiente no uso e desenvolvimento de tecnologias ou soluções baseadas em IA. Info literacia é a capacidade de saber e produzir conteúdos culturalmente apropriados. Nomeadamente ser capaz de interpretar o que está escrito, de fazer cálculos ou ter a competência para executar uma determinada área de conhecimento. A inteligência artificial (IA) está cada vez mais presente em nossas vidas, desde os assistentes nos smartphones aos produtos e serviços que consumimos. E por isso é imperativo compreender e interagir com essa tecnologia de forma crítica, informada e consciente para que não seja um: simples usuário passivo. Que quando restringido ao mercado profissional traduz-se, sem filtro, como: operador de trabalho de baixa qualificação. ","date":"2025-01-21","objectID":"/posts/rtfmaleatoriedades-literaciaai/:0:0","tags":["Linux","Basics"],"title":"RTFM \u0026 Aleatoriedades - Literacia em IA","uri":"/posts/rtfmaleatoriedades-literaciaai/"},{"categories":["AI"],"content":"O que abrange ? A literacia em IA inclui uma variedade de habilidades e conhecimentos, tais como: Compreender os conceitos básicos da IA compreensão básica de como IA funciona (e.g., algoritmos, dados, treinamento de modelos). diferença entre tipos de IA IA estreita - ANI IA geral - AGI IA Superinteligente - ASI Limitações a incapacidade de “entender” no sentido humano… a execução de tarefas com base em padrões… a dependência de dados de qualidade… pois algoritmos refletem vieses nos dados usados para treiná-los. Habilidades Práticas capacidade de interagir com ferramentas de IA. alcançado a partir do uso de ferramentas e aplicações de IA no dia a dia, seja em casa, na escola ou no trabalho. interpretação crítica de saídas geradas por IA, incluindo dados e previsões. Analisar e avaliar a IA: ser capaz de identificar os pontos fortes e fracos da IA, e entender as suas implicações. Comunicar sobre IA: saber explicar conceitos de IA para outras pessoas e participar em debates sobre o tema. Aprendizagem Contínua: com estudos continuados, cursos e treinamentos sobre IA. com o aprendizado de linguagens comumente usadas com por exemplo: Python. ","date":"2025-01-21","objectID":"/posts/rtfmaleatoriedades-literaciaai/:1:0","tags":["Linux","Basics"],"title":"RTFM \u0026 Aleatoriedades - Literacia em IA","uri":"/posts/rtfmaleatoriedades-literaciaai/"},{"categories":["AI"],"content":"Qual a sua Importância ? Acho que já podemos ponderar bem valor da literacia em tudo na vida! E em IA, podemos apontar algumas razões: Preparar para o futuro a IA está transformando o mundo do trabalho e a sociedade em geral. A literacia em IA ajuda as pessoas a se adaptarem a essas mudanças e a prosperarem num mundo cada vez mais digital. Tomar decisões informadas a IA tem um forte uso nas tomadas de decisões importantes em áreas como saúde, justiça e finanças dentre muitas outras… Por isso o alfabetismo em IA permite que as pessoas compreendam e participem da formulação e construção dessas decisões. Promover a inclusão a IA é uma ferramenta poderosa para promover a inclusão social, mas também irá perpetuar e amplificar as desigualdades existentes. A literacia em IA, ao meu ver, bem como a educação de base: é a única força concreta para a equidade. Desenvolver o pensamento crítico a IA levanta questões complexas sobre a iteração humana no mundo e consequentemente nos desafiando ao nos forçar a desenvolver o pensamento crítico e a refletir sobre as questões que surgem… ","date":"2025-01-21","objectID":"/posts/rtfmaleatoriedades-literaciaai/:2:0","tags":["Linux","Basics"],"title":"RTFM \u0026 Aleatoriedades - Literacia em IA","uri":"/posts/rtfmaleatoriedades-literaciaai/"},{"categories":["AI"],"content":"Como desenvolver a literacia em IA Existem diversas formas de desenvolver o letramento/alfabetização em IA, tais como: Participar em cursos e workshops muitas instituições oferecem cursos e workshops sobre IA para diferentes públicos. Como por exemplo: Elementos de IA: curso introdutório gratuito da Universidade de Helsínquia. Fast.ai: plataforma com cursos gratuitos para aprender a construir aplicações de IA. Coursera: plataforma com cursos de diversas universidades, incluindo cursos sobre IA. edX: plataforma com cursos de diversas universidades, incluindo cursos sobre IA. CS50: compreensão intelectual de ciência da computação e programação CS50: introdução a IA com Python ;) Movimento IA Para Todos: um esforço conjunto da IBM e .StartSe para democratizar o acesso à Inteligência Artificial no país. e muitos outros que você encontrará pesquisando na Internet… Ler livros e artigos existe uma grande quantidade de recursos disponíveis sobre IA, desde livros introdutórios a artigos acadêmicos. Livros de introdução a IA O livro “Superintelligence” de Nick Bostrom O livro “Life 3.0” de Max Tegmark O livro # Inteligência Artificial - Uma Abordagem Moderna de Stuart Russel O livro IA: COMO A INTELIGÊNCIA ARTIFICIAL MUDA O MUNDO, DE PEDRO DOMINGOS Como a Inteligência Artificial Funciona: Da Magia à Ciência de Ronald Kneusel Explorar ferramentas e aplicações de IA experimentar diferentes ferramentas e aplicações de IA é uma ótima forma de aprender na prática. pesquise por ferramentas de IA sobre algum assunto que seja útil nas suas atividades pessoais ou profissionais… Participar em debates e discussões a troca de ideias com outras pessoas é fundamental para o desenvolvimento da literacia em IA. Meetup e muitos outros como: nas redes sociais eventos online Fontes adicionais Literacia em Inteligência Artificial - Crivosoft AI Literacy: uma competência crucial para todas as organizações - triggo.ai O que é alfabetização em IA? Um guia abrangente para iniciantes - DataCamp Um referencial para a literacia em IA - Blogue RBE ","date":"2025-01-21","objectID":"/posts/rtfmaleatoriedades-literaciaai/:3:0","tags":["Linux","Basics"],"title":"RTFM \u0026 Aleatoriedades - Literacia em IA","uri":"/posts/rtfmaleatoriedades-literaciaai/"},{"categories":null,"content":"Analisando E-mail Fishing","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Os e-mails phishing continuam fortes no radar de ameaças no cenário de cibersegurança. Atacantes explorando principalmente anexos ou links maliciosos como descrito em MITRE ATT\u0026CK nas técnicas aplicadas para forjar comunicações legítimas para roubar credenciais, instalar malware ou realizar outros tipos de fraudes; continuam sendo executados com uma alta taxa de sucesso. Apesar do assunto já ter sido amplamente discutido na Internet! Nesse documento eu tento condensar as informações mínimas para um Go Hose um pouco mais descente!rs :) Cada e-mail é composto por dois elementos principais: Cabeçalhos: Contêm informações sobre o envio, como remetente, destinatário e servidores envolvidos. Corpo da mensagem: Inclui o conteúdo propriamente dito, que pode ser texto simples, HTML, links ou anexos. A inspeção dessas partes é fundamental para identificar indícios de phishing e coletar informações úteis para investigações. Porém, na prática, é necessário compreender quais aspectos devemos aferir e como correlacioná-los com os padrões técnicos que regulamentam a troca de e-mails. ","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:0","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Padrões Fundamentais 1. Transporte de Mensagens: SMTP - RFC 5321 O Simple Mail Transfer Protocol (SMTP) é responsável pelo envio e roteamento de e-mails entre servidores. Ele opera como um envelope que contém: MailFrom: O endereço do remetente usado para roteamento. .RcptTo: O endereço do destinatár Os comandos SMTP (HELO, MAIL FROM, RCPT TO, DATA, etc.) são usados para transferir a mensagem de um servidor para outro. E claro a resolução DNS para registros MX (Mail Exchange). 2. Estrutura da Mensagem: IMF - RFC 5322 O Internet Message Format (IMF), define a estrutura interna do e-mail, incluindo: Cabeçalhos principais: From: Endereço do remetente visível ao destinatário. To: Endereço do destinatário. Subject: Assunto do e-mail. Date: Data e hora de envio. Corpo da mensagem: Body: O conteúdo, que pode ser texto simples ou HTML, conter anexos e geralmente codificados em MIME Esses dois padrões (RFC 5321 e RFC 5322) operam em conjunto: o SMTP cuida do transporte da mensagem, enquanto o IMF define como ela é apresentada. 3. Protocolos de Autenticação Para combater fraudes e proteger a integridade das mensagens, protocolos adicionais foram criados: 1. SPF -Sender Policy Framework RFC7208 Verifica se o servidor que enviou o e-mail está autorizado pelo domínio do remetente. Baseia-se em registros DNS TXT, que especificam quais IPs podem enviar e-mails em nome do domínio. 2. DKIM - DomainKeys Identified Mail: RFC6376 Garante que o conteúdo da mensagem (cabeçalhos e corpo) não foi alterado durante o envio. Usa uma assinatura criptográfica (DKIM-Signature), validada com uma chave pública armazenada no DNS. 3. DMARC - Domain-based Message Authentication, Reporting, and Conformance: RFC7489 Alinha os resultados de SPF e DKIM com o endereço visível no cabeçalho From. Define políticas para lidar com mensagens que falham nas validações (ex.: rejeitar ou colocar em quarentena). ","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:1","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"SMTP, IMF e Autenticação Para visualizar melhor como essas partes interagem, considere o seguinte exemplo: Header de envio do e-mail lembrando que em uma análise comum, você não terá acesso a esse cabeçalho! Pois é restrito ao MUA do usuário que fez o envio do e-mail! MIME-Version: 1.0 Date: Sun, 8 Dec 2024 20:03:53 -0300 Message-ID: \u003cCAHExE1hY=_mC8PtrK26nC1EkU059HTBV-wEeQSF-=iq+wOOpqQ@mail.gmail.com\u003e Subject: E o pe? From: \"Thiago T. Faioli\" \u003cthiago.faioli@gmail.com\u003e To: \"thiago.faioli@bsd.com.br\" \u003cthiago.faioli@bsd.com.br\u003e Content-Type: multipart/mixed; boundary=\"0000000000002758590628ca43cc\" --0000000000002758590628ca43cc Content-Type: multipart/alternative; boundary=\"0000000000002758580628ca43ca\" --0000000000002758580628ca43ca Content-Type: text/plain; charset=\"UTF-8\" Opa, Bao! Ja melhorou dos bichos de pe? E nao custa lembrar: cuidado \u003chttps://www.youtube.com/watch?v=DlP3FZbAXgI\u003e! Abraco do amigo Faioli --0000000000002758580628ca43ca Content-Type: text/html; charset=\"UTF-8\" Content-Transfer-Encoding: quoted-printable \u003cdiv dir=3D\"ltr\"\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cdiv\u003eOpa, Bao!\u003c/div\u003e\u003cdiv\u003e\u003cbr\u003e\u003c/div\u003e\u003cdiv\u003eJa melho= rou dos bichos de pe?\u003cbr\u003e\u003c/div\u003e\u003cdiv\u003e\u003cbr\u003e\u003c/div\u003e\u003cdiv\u003eE nao custa lembrar: \u003ca = href=3D\"https://www.youtube.com/watch?v=3DDlP3FZbAXgI\" target=3D\"_blank\"\u003ecu= idado\u003c/a\u003e!\u003cbr\u003e\u003c/div\u003e\u003cdiv\u003e\u003cbr\u003eAbraco do am\u003cfont color=3D\"#444444\"\u003eigo\u003c/font\u003e= \u003c/div\u003e\u003cfont color=3D\"#888888\"\u003e\u003cdiv\u003e\u003cfont color=3D\"#444444\"\u003eFaioli\u003c/font\u003e\u003csp= an style=3D\"color:rgb(0,0,0);font-size:10pt\"\u003e \u003cbr\u003e\u003c/span\u003e\u003c/div\u003e\u003c/font\u003e\u003c/div= \u003e\u003c/div\u003e\u003cdiv\u003e\u003cdiv dir=3D\"ltr\" class=3D\"gmail_signature\" data-smartmail=3D\"gm= ail_signature\"\u003e\u003cdiv dir=3D\"ltr\"\u003e\u003cdiv\u003e\u003cdiv dir=3D\"ltr\"\u003e\u003cdiv dir=3D\"ltr\"\u003e\u003cdiv= dir=3D\"ltr\"\u003e\u003cdiv dir=3D\"ltr\"\u003e\u003cdiv\u003e\u003cdiv style=3D\"font-family:arial\"\u003e\u003cdiv st= yle=3D\"font-size:small\"\u003e\u003cdiv\u003e\u003cbr\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e= \u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e --0000000000002758580628ca43ca-- --0000000000002758590628ca43cc Content-Type: application/pdf; name=\"Anjali Khatri, Vikram Khatri - Mastering Service Mesh_ Enhance, secure, and observe cloud-native applications with Istio, Linkerd, and Consul-Packt Publishing (2020).pdf\" Content-Disposition: attachment; filename=\"Anjali Khatri, Vikram Khatri - Mastering Service Mesh_ Enhance, secure, and observe cloud-native applications with Istio, Linkerd, and Consul-Packt Publishing (2020).pdf\" Content-Transfer-Encoding: base64 X-Attachment-Id: f_m4g7m37i0 Content-ID: \u003cf_m4g7m37i0\u003e --0000000000002758590628ca43cc-- header do e-mail no MUA do usuário que recebeu o e-mail. são esses os dados que teremos para investigação. Delivered-To: thiago.faioli@bsd.com.br Received: by 2002:a05:7110:4344:b0:254:86f7:fd0c with SMTP id g4csp220273gee; Sun, 8 Dec 2024 15:04:28 -0800 (PST) X-Received: by 2002:a17:90b:28d0:b0:2ea:8aac:6aa9 with SMTP id 98e67ed59e1d1-2ef6a6bd802mr15278535a91.21.1733699060421; Sun, 08 Dec 2024 15:04:20 -0800 (PST) ARC-Seal: i=1; a=rsa-sha256; t=1733699060; cv=none; d=google.com; s=arc-20240605; b=EtZYcJUab+vSEdZhsk/uCg1+PyzpSEmw2aXc8YPvdB2K2WWfzf33QfrV9HP6SHMm80 IcCwNYfiPDVwkNc6TWi9UKXY5EBm12qxrS3rLwvE+hNWIbQRhlsDo3lE1YaX4yLXxEsv WQo6rxzGjTXRDTiGap6CeMm5XLbaZ6RkUVe5tkpok2hcgJ/Njn/aRcUJa+Tz/wKcAu6h y9rG56oMa2WZwexukHtHhDbwNn+NZvYYB02WEe8tlNieIzECAjEY+eI14Vt/NJVdf2hR hVeYAOqGDy8CLvGCQuiB6eLkD4trwY8nPQka8W5tKHvUGadDOOQcTHQpFbFfURKrajNr OJUw== ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20240605; h=to:subject:message-id:date:from:mime-version:dkim-signature; bh=AIDAEBlTTt9xgiNB096cNNX1VJAj2rhMPqxYE23Kufo=; fh=Fi9mIQ4POoGfXYmpD5y/vuvHDDd4psKIIeu1RdDwRx4=; b=e6ONX6MjloNz1wQ+QbEkuF1wT36cfEIlCch19xZikBGsRpkDmFpymq1HVx/GTOZEGr 50zYSAIhOoUHWSHytJp0Ges1Z2wtO4PQKG6ZUcGRlzKWCEsh10WG7/wcHbxcuEXZEUJ0 Nx0WmdZjwzLZXZt7H+5ORr7EgG1ai+ZcMmHvxHULJRjkwLTCgyJSpo7yAHGJupvAygxK b43MeJi1tBBN2bIgpU0aZgjkpttMTKzEpT7NZx1LDn4NFiGTmfHWWpOE4Lyz6T4NXAbR 7gTvqZs9CdO5K3Lst5t/etKBGb4ZrTQnndmOKfYl4e2uvkHrUiLDDGkISXdvYTlxYx6g Z1Wg==; dara=google.com ARC-Authentication-Results: i=1; mx.google.com; dkim=pass header.i=@gmail.","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:2","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Visão Segue um diagrama pra conseguirmos tridimensionalizar todos os aspectos que vimos até aqui ","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:3","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Ok! Tudo bonito. Mas e na prática ? Vou tentar demonstrar uma análise prática usando ferramentas Unix\u0026Linux ;) ","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:4","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Inspecionar o Cabeçalho Extraia os cabeçalhos completos do e-mail: Em clientes de e-mail, use as opções para exibir o “código-fonte”, “Mostrar original” ou “cabeçalhos completos” etc… salve em um arquivo normalmente em .eml. Aqui em nosso exemplo será: header_bichodepe.eml. Verifique inconsistências como por exemplo em: From: Analise se o domínio está alinhado com os campos SPF/DKIM. Received: Confirme a origem do servidor e as etapas de entrega. Reply-To: Pode ser usado para redirecionar respostas para um endereço diferente do From. aqui estou fazendo um grep para trazer os dados que mais nos interessa grep -iE \"from:|to:|subject:|received:|spf|dkim|dmarc|authentication-results\" header_bichodepe.eml Delivered-To: thiago.faioli@bsd.com.br Received: by 2002:a05:7110:4344:b0:254:86f7:fd0c with SMTP id g4csp220273gee; X-Received: by 2002:a17:90b:28d0:b0:2ea:8aac:6aa9 with SMTP id 98e67ed59e1d1-2ef6a6bd802mr15278535a91.21.1733699060421; h=to:subject:message-id:date:from:mime-version:dkim-signature; ARC-Authentication-Results: i=1; mx.google.com; dkim=pass header.i=@gmail.com header.s=20230601 header.b=kM+M4SQb; spf=pass (google.com: domain of thiago.faioli@gmail.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=thiago.faioli@gmail.com; dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com; Received: from mail-sor-f41.google.com (mail-sor-f41.google.com. [209.85.220.41]) Received-SPF: pass (google.com: domain of thiago.faioli@gmail.com designates 209.85.220.41 as permitted sender) client-ip=209.85.220.41; Authentication-Results: mx.google.com; dkim=pass header.i=@gmail.com header.s=20230601 header.b=kM+M4SQb; spf=pass (google.com: domain of thiago.faioli@gmail.com designates 209.85.220.41 as permitted sender) smtp.mailfrom=thiago.faioli@gmail.com; dmarc=pass (p=NONE sp=QUARANTINE dis=NONE) header.from=gmail.com; DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; h=to:subject:message-id:date:from:mime-version:from:to:cc:subject X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; h=to:subject:message-id:date:from:mime-version:x-gm-message-state :from:to:cc:subject:date:message-id:reply-to; X-Received: by 2002:a17:90b:53ce:b0:2ee:df70:1ff3 with SMTP id 98e67ed59e1d1-2ef69199134mr18507867a91.0.1733699054597; Sun, 08 Dec 2024 15:04:14 -0800 (PST) From: \"Thiago T. Faioli\" \u003cthiago.faioli@gmail.com\u003e Subject: E o pe? To: \"thiago.faioli@bsd.com.br\" \u003cthiago.faioli@bsd.com.br\u003e 1. Validando roteamento Verificando os campos Received: $ grep -A1 -i ^\"received:\" header_bichodepe.eml Received: by 2002:a05:7110:4344:b0:254:86f7:fd0c with SMTP id g4csp220273gee; Sun, 8 Dec 2024 15:04:28 -0800 (PST) -- Received: from mail-sor-f41.google.com (mail-sor-f41.google.com. [209.85.220.41]) by mx.google.com with SMTPS id 98e67ed59e1d1-2ef7a4c2a11sor3537848a91.6.2024.12.08.15.04.19 Agora verificamos o IP do servidor remetente Que deve resolver para mail-sor-f41.google.com $ host 209.85.220.41 41.220.85.209.in-addr.arpa domain name pointer mail-sor-f41.google.com. Aqui validamos que o IP resolve para o domain esperado! Tudo ok! 2. Validar SPF Validando campo Received-SPF $ grep -i received-spf header_bichodepe.eml Received-SPF: pass (google.com: domain of thiago.faioli@gmail.com designates 209.85.220.41 as permitted sender) client-ip=209.85.220.41; Aqui validação do remetente gmail.com para o servidor de envio designado é PASS. Tudo ok! Localize o include do registro SPF do domínio remetente (DNS TXT) Nós queremos validar o domínio do remetente (gmail.com) e o IP (209.85.220.41) vamos então procurar pelo IP do servidor de envio na lista do registro SPF e se essa validação falhar: é um potencial spoofing. Extraindo dados $ dig gmail.com TXT +noall +answer |grep spf gmail.com. 281 IN TXT \"v=spf1 redirect=_spf.google.com\" Identificamos que o registro SPF do gmail.com é um redirect para google.com. redirect é um ponteiro para outro nome de domínio que hospeda uma política SPF. Consultando o registro $ dig _spf.google.com TXT +","date":"2024-12-08","objectID":"/posts/rtfmaleatoriedades-emailphishing/:0:5","tags":["Linux","Cybersecurity","Pishing","Email","SMTP","IMF","SPF","DKIM"],"title":"RTFM \u0026 Aleatoriedades - Email Phishing","uri":"/posts/rtfmaleatoriedades-emailphishing/"},{"categories":null,"content":"Desc Text.","date":"2024-11-27","objectID":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/","tags":["Linux","DevOps","SRE","Observabilidade","Prometheus","PromQL","Alertmanager"],"title":"RTFM \u0026 Aleatoriedades - Função  predict_linear() do Prometheus","uri":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/"},{"categories":null,"content":"A função predict_linear() do Prometheus permite prever o valor futuro de uma série temporal com base em uma regressão linear simples dos dados históricos. Isso é especialmente útil para antecipar tendências e comportamentos futuros de métricas monitoradas, auxiliando na detecção proativa de possíveis problemas. Tips predict_linear() deve ser usado somente com medidores predict_linear(v range-vector, t scalar) prevê o valor das séries temporais t segundos a partir de agora, com base no vetor de intervalo v, usando regressão linear simples. O vetor de intervalo deve ter pelo menos duas amostras para realizar o Cálculo. Quando +Infou a -Infsão encontrados no vetor da faixa, o valor de inclinação e deslocamento calculado será NaN Em estatística, a regressão linear simples (SLR) é um modelo de regressão linear com uma única variável explicativa. Ou seja, diz respeito a pontos amostrais bidimensionais com uma variável independente e uma variável dependente (convencionalmente, as coordenadas x e y em um sistema de coordenadas cartesianas) e encontra uma função linear (uma linha reta não vertical) que, tão precisamente quanto possível, prevê os valores das variáveis dependentes como uma função da variável independente. ","date":"2024-11-27","objectID":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/:0:0","tags":["Linux","DevOps","SRE","Observabilidade","Prometheus","PromQL","Alertmanager"],"title":"RTFM \u0026 Aleatoriedades - Função  predict_linear() do Prometheus","uri":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/"},{"categories":null,"content":"Tá, mas e na prática? Deixa eu tentar explicar de forma pratica essa paradinha Essa é a sintaxe que precisamos ter em mente: predict_linear(vetor_intervalo, tempo_futuro_em_segundos) Onde: vetor_intervalo é um range vector que representa a time series ao longo de um intervalo de tempo específico. tempo_futuro_em_segundos é o escalar que indica quantos segundos no futuro você deseja prever o valor. Agora suponha uma situação na qual seja necessário prever quando o espaço livre em um sistema de arquivos de um host servidor se esgotará, com base no fluxo de dados das últimas horas. Agora que temos uma caso de uso, vamos criar uma 2 expressões que antecipe esse momento, com a intenção de ter tempo hábil para ações preventivas antes que o problema pata na nossa porta… 1 expressão: a predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10737418240 b predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10 * 10^9 c predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10 * 1024^3 2 expressão: predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10 Onde: node_filesystem_free_bytes[1h] obtém os dados de espaço livre no disco nos últimos 60 minutos. 4 * 3600 define o intervalo de 4 horas (4 * 3600 segundos). 10 * 1024^3 ou 10 * 10^9 definem o limite de 10 GB ou \u003c 10 que define o limite de 10 bytes Para representar o valor mínimo de 10 GB na expressão PromQL, deve-se usar bytes como unidade base. E como 1 GB equivale a 1.073.741.824 bytes, para um valor mínimo de 10 gigabytes (GB), seria: para a unidade padrão 10737418240 (10 * 1.073.741.824 = 10.737.418.240 bytes) para a unidade simplificada: 10 * 1024^3 resultando em: 10.737.418.240 bytes (1 GB como 1024^3 bytes). para a unidade simplificada, caso seja preciso uma valor mai exato: 10 * 10^9 resultando em: 10.000.000.000 10^9 bytes (1 GB = 1.000.000.000 bytes). para representar uma valor minimo menor de 10 bytes \u003c 10 Com essas expressões estamos verificando se a previsão do espaço livre no disco será menor que 10 GB ou 10 bytes dentro de 4 horas. E sendo verdade, com base na tendência atual da aferição, um alerta será acionado, informando que o espaço livre em disco estará abaixo do limite de 10 GB ou 10 bytes no futuro próximo de 4 horas… Dando continuidade com o nosso cenário suposto. Vamos implementar um alarme usando nossas expressões Alarme para quando menor que10 GB lembrando que podemos usar \u003c 10 * 1024^3 ou \u003c 10737418240 ou \u003c 10 * 10^9 conforme nossa necessidade de assertividade… groups: - name: disk_alerts rules: - alert: SistemaDeArquivosCriticamenteBaixoEm4Horas expr: predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10 * 1024^3 for: 10m labels: severity: warning annotations: summary: \"A treta vai ser doida em 4 horas\" description: \"O sistema de arquivos no servidor {{ $labels.instance }} terá menos de 10 GBytes disponíveis em 4 horas.\" Alarme para quando menor que 10 bytes groups: - name: disk_alerts rules: - alert: SistemaDeArquivosCriticamenteBaixoEm4Horas expr: predict_linear(node_filesystem_free_bytes[1h], 4 * 3600) \u003c 10 for: 10m labels: severity: warning annotations: summary: \"A treta vai ser criticamente doida em 4 horas\" description: \"O sistema de arquivos no servidor {{ $labels.instance }} terá menos de 10 bytes disponíveis em 4 horas.\" Onde: alert: nome do alerta. expr: expressão que utiliza predict_linear() para prever o esgotamento do espaço em disco. for: período durante o qual a condição deve ser verdadeira antes de acionar o alerta, para evitar falsos positivos. labels: rótulos adicionais para categorizar o alerta. annotations: informações adicionais que podem ser incluídas na notificação do alerta. Essa e o método que me permitiu sair dos alarmes de limiares fixos que não atendem de maneira satisfatória crescimentos tão velozes que, no momento do disparo do do alerta, o tempo é tao curto ou tarde demais para uma atuação técnica… ","date":"2024-11-27","objectID":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/:1:0","tags":["Linux","DevOps","SRE","Observabilidade","Prometheus","PromQL","Alertmanager"],"title":"RTFM \u0026 Aleatoriedades - Função  predict_linear() do Prometheus","uri":"/posts/rtfmaleatoriedades-funcaopredict_linearprometheus/"},{"categories":null,"content":"Solving the need to download an unexpectedly large amount of logs","date":"2024-11-24","objectID":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/","tags":["Linux","Loki","SRE","DevOps","Observability","Grafana"],"title":"RTFM \u0026 Randomness Loki K8s - Fetching Large Logs","uri":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/"},{"categories":null,"content":"There are several reasons why Grafana may not be configured to break the 5000 line limit when exploring logs… It is also known that we can export in several other ways. But here I will focus on solving the need to download an unexpectedly large amount of logs… And for that we will make use of LogCLI: the command line interface for Grafana Loki that makes it easy to run LogQL queries on a Loki instance. ","date":"2024-11-24","objectID":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/:0:0","tags":["Linux","Loki","SRE","DevOps","Observability","Grafana"],"title":"RTFM \u0026 Randomness Loki K8s - Fetching Large Logs","uri":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/"},{"categories":null,"content":"Download binary Download the logcli binary from the Loki releases page. loki-3.3.0.x86_64.rpm logcli_3.3.0_arm64.deb ","date":"2024-11-24","objectID":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/:0:1","tags":["Linux","Loki","SRE","DevOps","Observability","Grafana"],"title":"RTFM \u0026 Randomness Loki K8s - Fetching Large Logs","uri":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/"},{"categories":null,"content":"Install sudo dnf isntall https://github.com/grafana/loki/releases/download/v3.3.0/logcli-3.3.0.x86_64.rpm ","date":"2024-11-24","objectID":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/:0:2","tags":["Linux","Loki","SRE","DevOps","Observability","Grafana"],"title":"RTFM \u0026 Randomness Loki K8s - Fetching Large Logs","uri":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/"},{"categories":null,"content":"Bash completion add this to your ~/.bashrc.d file cat \u003c\u003c EoF \u003e\u003e ~/.bashrc.d/var_loki # Set up command completion eval \"$(logcli --completion-script-bash)\" EoF If you have questions about the query that needs to be made, access the Explorer in Grafana Go to Grafana \u003e Explore Apply the necessary label to filter logs … In this example, I’m looking for the last 7 days of logs from the NGINX Ingress which is processing approximately 8.8 GiB. {app=\"ingress-nginx\"} |= `` Then, to allow local access, forward a local port to the Loki pod kubectl --namespace loki port-forward svc/loki-gateway 8080:80 Configure the LogCli environment variable export LOKI_ADDR=http://localhost:8080 And using the query we checked, we can finally extract the log to a local file $ logcli query '{app=\"ingress-nginx\"} |= ``' --limit=9000000 --since=168h -o default,raw or jsonl \u003e /tmp/log_ingres-nginx.log --limit here I try to set a very high value to ensure that all logs from the 7 days are captured. --since I set 168h time range. ","date":"2024-11-24","objectID":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/:0:3","tags":["Linux","Loki","SRE","DevOps","Observability","Grafana"],"title":"RTFM \u0026 Randomness Loki K8s - Fetching Large Logs","uri":"/posts/rtfmrandomness-lokik8s-fetchinglargelogs/"},{"categories":null,"content":"Requisitos mínimos para um firewall profissional.","date":"2024-11-12","objectID":"/posts/rtfmaleatoriedades-firewall/","tags":["PF","OpenBSD","Firewall","DoS","DDoS","SegInfo"],"title":"RTFM \u0026 Aleatoriedades - Firewall","uri":"/posts/rtfmaleatoriedades-firewall/"},{"categories":null,"content":"Firewall Em 2016 eu participei do curso FreeBSD S.S.A na FreeBSD brasil que sem sombra de dúvidas foi um dos raros treinamentos que de fato entregou conhecimento e me fez avançar de diversas formas no gerenciamento de redes, roteamento e segurança complexos de forma KISS. Tip SSA - Server and System Systems Administration. December 2016. FreeBSD Brasil LTDA. Certificado Número: 011245. Como reflexo do conhecimento adquirido. A atenção aos requisitos mínimos, necessários para conceber um firewall tecnicamente descente, profissional e em conformidade com os requisitos do projeto: tornaram-se mandatórios! E para esse fim, como apoio e referência NIST SP 800-41 Rev 1 - Guidelines on Firewalls and Firewall Policy. NIST Cybersecurity Framework - CSF NIST SP 800-53 Rev 5 - Diretrizes sobre firewalls e política de firewall E para melhor embasamento, e expansão do próprio conhecimento sobre as possibilidades e o mais importante: no processo cognitivo para a solução de problemas. Indico fortemente conhecer padrões de conformidade em segurança que fazem uso do NIST: HIPAANIST é uma Lei de Portabilidade e Responsabilidade de Seguros de Saúde dos EUA (HIPAA) que regula como as informações de saúde são tratadas e protegidas para garantir a proteção das informações de saúde através de controles e práticas de segurança para informações eletrônicas de saúde. E que regulamenta organizações: covered entities - provedores de saúde, planos de saúde e câmaras de compensação de saúde; business associates - empresas de cobrança, fornecedores de registro eletrônico de saúde (RES), consultores ou provedores de TI. Personally Identifiable Information - PII que são quaisquer dados que possam ser usados para identificar alguém e que direta ou indiretamente se vinculam a uma pessoa. Qual empresa não coleta, armazena e processa PII nos dias de hoje? É claro que é uma definição americana! A GPDR UE tem outra definição: dados pessoais. Mas o importante é o arcabouço cognitivo de estar atendo ao métodos de proteger esses dados pessoais etc. Payment Card Industry - PCI NIST é um conjunto de políticas de segurança para os dados do portador do cartão. Organizações que processam transações financeiras com cartões de crédito, débito e pré-pago estão sujeitas aos requisitos de conformidade com PCI. Federal Information Security Modernization Act - FISMA NIST é uma legislação dos Estados Unidos que define uma estrutura de diretrizes e padrões de segurança para proteger as operações de tecnologia da informação do governo contra ameaças cibernéticas. Essa estrutura de gerenciamento de risco foi assinada como lei como parte do Electronic Government Act de 2002, posteriormente atualizadas e alteradas em 2014. Ela exige de agências federais o desenvolvimento, documentação e implementação de programas de infosec para proteger informações sensíveis e confidenciais. O ato também descreve as responsabilidades do National Institute of Standards and Technology - NIST e do Office of Management and Budget (OMB). ISO/IEC 27001:2022 é um norma de segurança de informações reconhecida internacionalmente, desenvolvida pelo órgão de certificação Organização Internacional de Padronização - ISO e a Comissão Eletrotécnica Internacional - CEI. A sua versão mais recente é: ISO/IEC 27001:2022. [equivalência: SP 800-53]. ISO/IEC 27002:2022 guia de melhores práticas para a implementação de controles de segurança da informação, aplicado aos controles da norma ISSO 27001:2022. [equivalência: Cybersecurity Framework - CSF e SP 800-53] ","date":"2024-11-12","objectID":"/posts/rtfmaleatoriedades-firewall/:1:0","tags":["PF","OpenBSD","Firewall","DoS","DDoS","SegInfo"],"title":"RTFM \u0026 Aleatoriedades - Firewall","uri":"/posts/rtfmaleatoriedades-firewall/"},{"categories":null,"content":"NIST Special Publications Estou usando como referência principal, a coleção de recomendações da subsérie de especificações técnicas SP 800 - Computer security da NIST Special Publications. O NIST SP 800-53 Rev 5 que também faz referência ao SP 800-41 Rev 1 como um documento para atingir conformidade em um firewall. Tem várias referências a firewall no terceiro capítulo e seguintes seções: Terceiro capítulo, The Controls - SECURITY AND PRIVACY CONTROLS AND CONTROL ENHANCEMENTS. 3.1 Access Control: AC-3 ACCESS ENFORCEMENT AC-4 INFORMATION FLOW ENFORCEMENT AC-6 LEAST PRIVILEGE 3.5 CONFIGURATION MANAGEMENT CM-7 LEAST FUNCTIONALITY 3.8 INCIDENT RESPONSE IR-4 INCIDENT HANDLING 3.16 RISK ASSESSMENT RA-10 THREAT HUNTING 3.17 SYSTEM AND SERVICES ACQUISITION SA-9 EXTERNAL SYSTEM SERVICES 3.18 SYSTEM AND COMMUNICATIONS PROTECTION SC-7 BOUNDARY PROTECTION SC-28 PROTECTION OF INFORMATION AT REST 3.19 SYSTEM AND INFORMATION INTEGRITY SI-3 MALICIOUS CODE PROTECTION SI-4 SYSTEM MONITORING SI-7 SOFTWARE, FIRMWARE, AND INFORMATION INTEGRITY SI-8 SPAM PROTECTION O guia SP 800-41 Revision 1 - Guidelines on Firewalls and Firewall Policy é a minha principal referência de recomendações para garantir as melhores práticas na segurança e controle de tráfego em um firewall. Seção 2 - Overview of Firewall Technologies Nessa seção temos a definição de diferentes tipos de Firewalls e arquitetura nas quais são melhor empregados para o controle do fluxo de tráfego de rede entre redes ou hosts que empregam diferentes posturas de segurança. Inicialmente, podemos tomar como ponto de atenção. O seguinte resumo de recomendações: O uso de NAT deve ser considerado uma forma de roteamento, não um tipo de firewall. cuidado! Seu entendimento sobre DMZ pode ser um problema! As organizações devem permitir apenas tráfego de saída que use os endereços IP de origem em uso pela organização. esteja atento aos requisitos de segurança da arquitetura de redes. A verificação de conformidade só é útil em um firewall quando pode bloquear a comunicação que pode ser prejudicial aos sistemas protegidos. o firewall deve se basear na segurança do layout de redes sem perder flexibilidade: permitindo assim a evolução da infraestrutura. Ao escolher o tipo de firewall a ser implantado, é importante decidir se o firewall precisa atuar como um proxy de aplicativo. esteja atento a qual tecnologia de firewall usar observando suas capacidades de lidar com as camadas TCP/IP. O gerenciamento de firewalls pessoais deve ser centralizado para ajudar a criar, distribuir e aplicar políticas de forma eficiente para todos os usuários e grupos. a sobreposição de firewalls sempre gerará carga operacional e complexidade. Seção 3 - Firewalls and Network Architectures Esta seção se concentra em firewalls de rede porque os outros tipos geralmente não estão relacionados a problemas de topologia de rede. Em geral, um firewall deve se encaixar no layout de uma rede atual. No entanto, uma organização pode alterar sua arquitetura de rede ao mesmo tempo em que implanta um firewall como parte de uma atualização geral de segurança. Diferentes arquiteturas de rede comuns levam a escolhas muito diferentes sobre onde colocar um firewall, então uma organização deve avaliar qual arquitetura funciona melhor para seus objetivos de segurança. Se um firewall de borda tiver uma DMZ, considere quais serviços voltados para fora devem ser executados a partir da DMZ e quais devem permanecer na rede interna. Não confie em NATs para fornecer os benefícios dos firewalls. Em alguns ambientes, colocar um firewall atrás de outro pode levar a um objetivo de segurança desejado, mas, em geral, essas múltiplas camadas de firewalls podem ser problemáticas. Seção 4 - Firewall Policy 4.1 - Policies based on IP Address and Protocol 4.2 - Policies Based on Applications 4.3 - Policies Based on User Identity 4.4 - Policies Based on Network Activity Seção 5 - Firewall Planning and Implementation 5.2.1 - Hardware and Software Installation 5.2.3 - Lo","date":"2024-11-12","objectID":"/posts/rtfmaleatoriedades-firewall/:2:0","tags":["PF","OpenBSD","Firewall","DoS","DDoS","SegInfo"],"title":"RTFM \u0026 Aleatoriedades - Firewall","uri":"/posts/rtfmaleatoriedades-firewall/"},{"categories":null,"content":"Ambiente Ambiente de teste: Aplicações httpd daemon, OpenSSH, Wireguard, Prometheus Node Exporter, Tor relay obfs4 bridge. servidor VPS VULTR Regular Cloud Compute. 1 vCPU, 1024 MB RAM, 25 GB SSD, 1.00 TB Transfer. OpenBSD 7.4 (GENERIC.MP) #1396: Sun Oct 8 09:20:40 MDT 2023. Requisitos Políticas de segurança baseadas em endereço IP e protocolo tratar tráfego loopback e pseudo interfaces, tratar anomalias IP e por protocolo, criar limites de fluxo IP, tratar transformações e validações de pacotes, criar políticas por protocolo, serviço, host e redes, aplicar técnicas para mitigar DoS e DDoS, considerar o esgotamento de recursos computacionais. ","date":"2024-11-12","objectID":"/posts/rtfmaleatoriedades-firewall/:3:0","tags":["PF","OpenBSD","Firewall","DoS","DDoS","SegInfo"],"title":"RTFM \u0026 Aleatoriedades - Firewall","uri":"/posts/rtfmaleatoriedades-firewall/"},{"categories":null,"content":"Ruleset Segue abaixo, uma sugestão de conjunto de regras de firewall OpenBSD PF - Packet Filtering. /etc/pf.conf # Definições de interfaces ext_if = \"vio0\" # Interface externa (WAN) int_if = \"vio1\" # Interface interna (LAN) lo_if = \"lo0\" # Interface loopback wg_if = \"wg0\" # Interface VPN WireGuard # Endereços IP e redes server_ip = \"215.230.100.124\" # IP do servidor de aplicação lan_net = \"10.42.95.0/20\" # Rede interna (LAN) vpn_net = \"10.0.0.0/24\" # Rede da VPN WireGuard srv_monit_ip = \"0.0.0.0\"# IP do servidor de monitoramento # Portas Permitidas (HTTP, HTTPS, SSH, WireGuard, Prometheus) allowed_ports_tcp = \"{ 22, 80, 443, 9100, 51820, 9001, 9003 }\" allowed_ports_udp = \"{ domain }\" # ICMP # https://man.openbsd.org/icmp icmp_types = \"{ echoreq, echorep, unreach, timex, trace }\" # non_routable = \"{ 127.0.0.0/8, 192.168.0.0/16, 172.16.0.0/12, 10.0.0.0/8 , fd00::/8, fe80::/10 }\" # LOG pflog_logfile=\"/var/log/pflog\" # Criando tabelas # https://www.openbsd.org/faq/pf/tables.html table \u003ctrusted_admins\u003e persist file \"/etc/trusted_admins\" table \u003cblocked_hosts\u003e persist table \u003cblocked_bforce\u003e persist # Política de Bloqueio Padrão e de Limites de Estado e Fragmentação # Bloqueio de todo o tráfego por padrão, com permissões específicas para tráfego necessário. # https://www.openbsd.org/faq/pf/options.html # Política de segurança mínima - \"deny all\". Alinhado com o NIST SP 800-41 Revision 1, Seção 4 - Firewall Policy set block-policy drop # Define o comportamento padrão para regras de filtro: drop - packet is silently dropped set loginterface $ext_if # Loga tráfego na interface externa para auditoria set skip on $lo_if # Ignora tráfego na interface loopback para desempenho # Limita o número de estados de conexão e fragmentos permitidos para prevenir ataques DoS. # NIST SP 800-41, Seção 4.4 - Policies Based on Network Activity # https://www.openbsd.org/faq/pf/options.html # Estabelendo limites na operação do Pf. Configurações atuais: `pfctl -s memory`. set limit { states 10000, frags 5000 } # frags - número máximo de entradas no pool de memória usado para remontagem de pacotes (scrub rules). O padrão é de 5000. states - número máximo de entradas no pool de memória usado para entradas de tabela de estado (regras de filtro que especificam o keep state). O padrão é 100000. set optimization normal # Configuração otimizada para tráfego em ambiente de rede: normal - adequado para quase todas as redes. # Alinhado com a prática de \"deny-all\" na entrada e saída: exceto o permitido explicitamente. # https://www.openbsd.org/faq/pf/tagging.html#policy # https://www.openbsd.org/faq/pf/filter.html#defdeny # Conforme NIST SP 800-41, Seção 4.1 (Política padrão de bloqueio) block in log all # bloqueará o tráfego de entrada em todas as interfaces em qualquer direção de qualquer lugar para qualquer lugar. block out log all # bloqueará o tráfego de saida em todas as interfaces em qualquer direção de qualquer lugar para qualquer lugar. # Prevenção de Anomalias IP # Previne spoofing e anomalias de IP usando a diretiva `antispoof`. # https://www.openbsd.org/faq/pf/filter.html#antispoof # Conforme NIST SP 800-41, seção 4.1.1 - IP Addresses and Other IP Characteristics antispoof quick for { $ext_if $int_if $wg_if } # Bloqueio de endereços IP não roteáveis. # Conforme NIST SP 800-41, Seção 4.1.1 - IP Addresses and Other IP Characteristics block drop in quick on $ext_if from any to $non_routable # Bloqueia loopback na interface externa block drop in quick on $ext_if from any to 255.255.255.255 # Bloqueia broadcast global # Loopback e Pseudo-Interfaces. Permitindo tráfego local na interface loopback para evitar tretas. # Alinhamento com NIST SP 800-41, Seção 4.1 - Policies Based on IP Addresses and Protocols pass quick on $lo_if # Validação e Transformação de Pacotes (scrubbing) # Reassembla pacotes fragmentados e randomiza IDs de pacotes para prevenir ataques que exploram fragmentação. # https://home.nuug.no/~peter/pf/en/scrub.html # https://man.openbsd.org/pf.conf.","date":"2024-11-12","objectID":"/posts/rtfmaleatoriedades-firewall/:4:0","tags":["PF","OpenBSD","Firewall","DoS","DDoS","SegInfo"],"title":"RTFM \u0026 Aleatoriedades - Firewall","uri":"/posts/rtfmaleatoriedades-firewall/"},{"categories":null,"content":"Configurando UDEV Para Keyboard Keychron","date":"2024-09-21","objectID":"/posts/rtfmaleatoriedades-udev_keychron/","tags":["Linux","UDEV","KEYCHRON","Keyboard"],"title":"RTFM \u0026 Aleatoriedades - UDEV_Keychron","uri":"/posts/rtfmaleatoriedades-udev_keychron/"},{"categories":null,"content":"Para explorar as features do teclado V10 é utilizado o software usevia.app diretamente pelo navegador! E a parte boa é a sua compatibilidade com Linux. meu cenário: Fedora release 40 (Forty) Google Chrome Basta acessar o link do aplicativo usevia.app e clicar em Authorize device Warning Porem ao tentar fazer a autorizacão do dispositivo! Ocorre o erro de permissão de acesso Note é preciso criar uma regra udev para o driver Linux hidraw que é utilizado para comunicacão com o teclado. ","date":"2024-09-21","objectID":"/posts/rtfmaleatoriedades-udev_keychron/:0:0","tags":["Linux","UDEV","KEYCHRON","Keyboard"],"title":"RTFM \u0026 Aleatoriedades - UDEV_Keychron","uri":"/posts/rtfmaleatoriedades-udev_keychron/"},{"categories":null,"content":"Solucão Primeiro liste as infos do barramento USB pra coletar os dados do device lsusb ou udevadm Obtendo os dados lsusb Sem rodeios $ lsusb ... ... Bus 001 Device 005: ID 3434:03a1 Keychron Keychron V10 ... Tip lsusb -D /dev/bus/usb/001/005 udevadm Com o udevadm monitore o sistema UDEV monitor --property remova o teclado inicie o monitoramento conecte o teclado $ sudo udevadm monitor -up |grep -E \"ID_VENDOR_ID|ID_MODEL_ID|DEVNAME\" ... DEVNAME=/dev/bus/usb/001/005 ID_MODEL_ID=03a1 ID_VENDOR_ID=3434 Com o path do device em mãos, também podemos obter dados com o comando udevadm usando a opcão info nos interessa os campos: ID_MODEL_ID ID_VENDOR_ID Tip $ sudo udevadm info /dev/bus/usb/001/005 |grep -E “ID_VENDOR_ID|ID_MODEL_ID” Sabemos que: o barramento é: 001 o dispositivo é: 005 o ID do vendor Keychron é: 3434 o ID do produto Keychron V10 é: 03a1 ","date":"2024-09-21","objectID":"/posts/rtfmaleatoriedades-udev_keychron/:1:0","tags":["Linux","UDEV","KEYCHRON","Keyboard"],"title":"RTFM \u0026 Aleatoriedades - UDEV_Keychron","uri":"/posts/rtfmaleatoriedades-udev_keychron/"},{"categories":null,"content":"Regra UDEV Específica para o device hidraw primeiro crie uma variável com o group id do usuário meu usuário é 0xttfx export USER_GID=`id -g 0xttfx` enfim a regra: $ sudo --preserve-env=USER_GID sh -c 'cat \u003c\u003cEOF \u003e /etc/udev/rules.d/via.rules # Keychron_V10 KERNEL==\"hidraw*\", SUBSYSTEM==\"hidraw\", ATTRS{idVendor}==\"3434\", ATTRS{idProduct}==\"03a1\", MODE=\"0660\", GROUP=\"${USER_GID}\", TAG+=\"uaccess\", TAG+=\"udev-acl\" EOF' Em seguida recarregue as regras UDEV sudo sh -c 'udevadm control --reload-rules \u0026\u0026 udevadm trigger' Funfando :) ","date":"2024-09-21","objectID":"/posts/rtfmaleatoriedades-udev_keychron/:2:0","tags":["Linux","UDEV","KEYCHRON","Keyboard"],"title":"RTFM \u0026 Aleatoriedades - UDEV_Keychron","uri":"/posts/rtfmaleatoriedades-udev_keychron/"},{"categories":null,"content":"PAM_exec","date":"2024-09-20","objectID":"/posts/rtfmaleatoriedades-pam_exec/","tags":["Linux"],"title":"RTFM\u0026 A leatoriedades - PAM_exec","uri":"/posts/rtfmaleatoriedades-pam_exec/"},{"categories":null,"content":"PAM - módulo pam_exec para execução de comando externo Estou participando de um projeto, onde sou o ponto focal para Infra, de uma equipe composta por profissionais de países e empresas diferentes! E fui abordado por um Dev, com o seguinte pedido: Você consegue criar uma forma de, eu mesmo, fazer o restart da instância secundária do PGSQL do ambiente stage ? Sem me dar acesso ao servidor Linux para rodar um comando! E que seja simples para não gerar uma demanda de projeto para Infra etc… Naturalmente: perguntei o motivo! E prefiro não entrar na questão… Em detrimento do projeto e ambiente: minha diretiva principal também é apoiar com soluções que resolvam bloqueios da equipe! Dito isso! Veio de imediato em minha mente: posso criar um conta de sistema! Dessa forma não há um shell válido para login com diretório home apenas para o subdiretório ~/.ssh, para armazenar o authorized_keys com a chaves públicas e numa tentativa de login via ssh, onde a chave pública for validada: um systemctl restart ... é então executado. seguido a ideia, de usar ssh, acho que é possível duas abordagens: usando o módulo pam_exec do PAM! Configurado no arquivo de configuração PAM para o SSH: /etc/pam.d/sshd usando o bloco condicional Match do SSHD para usar o ForceCommand Como há muito tempo não brinco com o PAM. Optei por ele! porém, deixo claro que: não me veio nenhuma outra ideia de como aplicar tecnicamente no Linux! Então, é um favor que você me faz, criticar o que proponho aqui! ;) Conta de sistema Criando uma conta de sistema que será de uso compartilhado, caso algum outro Dev queira fazer uso também. Para tanto, criaremos também o diretório home para armazenar o subdiretório ~/.ssh para armazenar as chaves públicas SSH. useradd -r -s /usr/sbin/nologin -m -c 'user para restart pgsql' restartpg \u0026\u0026 getent passwd restartpg restartpg:x:995:986:user para restart pgsql:/home/restartpg:/usr/sbin/nologin /etc/ssh/sshd_config Porque não precaver… cp /etc/ssh/sshd_config{,.BKP} Garanta que o PAM esteja habilitado! # Set this to 'yes' to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the KbdInteractiveAuthentication and # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication via KbdInteractiveAuthentication may bypass # the setting of \"PermitRootLogin yes # If you just want the PAM account and session checks to run without # PAM authentication, then enable this but set PasswordAuthentication # and KbdInteractiveAuthentication to 'no'. UsePAM yes /etc/pam.d/sshd Não custa nada fazer um backup do arquivo ;) cp /etc/pam.d/sshd{,.BKP} Em seguida inserimos nossa configuração cat \u003c\u003cEoF \u003e\u003e /etc/pam.d/sshd # TCPIP ME - @faioli 10/09/24 # reboot postgresql by specific user session optional pam_exec.so type=open_session debug log=/var/log/sshpamexec.sh.log seteuid /usr/local/bin/sshpamexec.sh EoF /usr/local/bin/sshpamexec.sh #!/usr/bin/env bash ## # Autor: Thiago Torres Faioli - A.K.A: 0xttfx - thiago@tcpip.net.br # Função: reiniciar instância PGSQL usando conta de sistema sem shell # válido que numa tentativa de login via ssh, onde a chave pública for # validada o comando `systemctl restart ...` é então executado. ## # Versão: 0.1 # Data: 10 de Setembro de 2024 # Licença: SPDX-License-Identifier: BSD-3-Clause ##################################################################### # funcao para log _log_msg() { local msg=\"$1\" local tstamp=$(date +\"%d-%m-%Y %H:%M:%S\") echo \"[${tstamp}] ${msg}\" \u003e\u003e /var/log/sshpamexec.log } # funcão de restart e status do pgsql _restartpg (){ /usr/bin/systemctl restart postgresql@16-main.service _log_msg \"$(/usr/bin/systemctl status postgresql@16-main.service --no-pager)\" } # variável com parser do fingerprint associado ao último login ssh do usuário restartpg fprint=\"$(cat /var/log/auth.log |grep -iA1 \"accepted publickey\"|grep -B1 restartpg |grep -oE SHA.*$|/usr/bin/tail -n1)\" # varoável com arquivo temporário criado p","date":"2024-09-20","objectID":"/posts/rtfmaleatoriedades-pam_exec/:1:0","tags":["Linux"],"title":"RTFM\u0026 A leatoriedades - PAM_exec","uri":"/posts/rtfmaleatoriedades-pam_exec/"},{"categories":null,"content":"Desc Text.","date":"2024-06-07","objectID":"/pages/about/","tags":null,"title":"About","uri":"/pages/about/"},{"categories":null,"content":"🖖 Hey! I’m Faioli, aka 0xttfx 🏴‍☠️ Enthusiast of geek and hacker culture! With over 25 years of experience in the job market, I have learned a lot from many people I have met along the way! And I am very grateful to everyone who gave me good and bad examples, who shared knowledge, who tried to bring me down, who discredited me… It was, and still is: a great school where I continue to improve my skills in IT infrastructure, network troubleshooting, Unix and Linux, telecom, systems administration, virtualization, SND\u0026NFV, cloud computing and, in recent years, in infrastructure as code, provisioning automation, continuous integrations, platform engineering and cybersecurity.\" Basic observations have become natural guidelines Don’t try to be someone you are not Don’t expect anything from anyone. Don’t be ashamed of being ridiculed when asking questions. Express ideas and don’t impute them. Accept criticism. Deal with “Ad hominem” attacks with silence: let the biped’s ego shine in its spectrum: poor thing, he needs it! Treat everyone with respect! Even when you disagree. There is a time to complain! First, shake off the dust, breathe and solve the problem. Accept your mistakes and update yourself. And studying without practicing is not the best way… Especially if you have ADHD… lol About social engineering, the only practice, compelled as an organic side effect of my disinterest in certain social interactions engendered by narcissistic intellectual profiles: give the contemptuous eyes that judge you, the food they want! It is instructive to observe being defined by the latent obtuseness of myopic pride. But in my case it is based as the colloquial antidote that goes beyond! Because it strengthens positions that support essential fiduciary narratives of self-defense. Enlightenment is man’s emergence from his self-imposed immaturity. Immaturity is the inability to use one’s understanding without guidance from another. This immaturity is self-imposed when its cause lies not in lack of understanding, but in lack of resolve and courage to use it without guidance from another. Sapere Aude! [dare to know] “Have courage to use your own understanding!” — that is the motto of enlightenment. Immanuel Kant [a piece the text: “What is Enlightenment?” - Konigsberg in Prussia, 30 September 1784] This site is about me, unix, linux, infrastructure, cyber security, hacker culture and what I feel like talking about :) Have fun at this place and get in touch if you want… ","date":"2024-06-07","objectID":"/pages/about/:0:0","tags":null,"title":"About","uri":"/pages/about/"},{"categories":null,"content":"Um ataque DDoS UDP flood é uma forma de ataque distribuído de negação de serviço que explora serviços vulneráveis na Internet que utilizam o protocolo UDP - User Datagram Protocol para inundar um alvo com uma grande quantidade de tráfego de pacotes UDP. E como cada novo pacote UDP recebido pelo servidor, consome recursos computacionais, rapidamente o servidor vai consumindo seus recursos devido a sobrecarga até exaurir o poder computacional o impedindo de processar e responder requisições normais dos usuários, ficando indisponível. ","date":"2024-05-09","objectID":"/posts/cybersecurity-dos-ddos-udp-flood/:0:0","tags":["linux","openbsd","freebsd","ipfw","pf","nftables","iptables","cybersecurity","ddos","dos","engineering","firewall"],"title":"Cybersecurity DoS DDoS UDP Flood","uri":"/posts/cybersecurity-dos-ddos-udp-flood/"},{"categories":null,"content":"Funcionamento Inundação UDP: o atacante fazendo uso de uma botnet envia uma grande quantidade de pacotes UDP contra um alvo. IP Spoofing: o endereço IP de origem dos pacotes UDP são falsificados para impedir a identificação da origem do ataque. Amplificação de tráfego: também é aplicado a técnica de amplificação para aumentar o impacto do ataque. Dependendo do serviço vulnerável na Internet, usado pelo atacante, uma pequena requisição UDP irá gerar um resposta com grande quantidade de dados que será encaminhado para o alvo, aumentando ainda mais a sobrecarga na infraestrutura. Sobrecarga dos recursos: devido a arquitetura do protocolo, a infraestrutura do alvo fica rapidamente sobrecarregada com a quantidade massiva de pacotes UDP recebidos, gerando assim indisponibilidade do serviço para usuários legítimos. ","date":"2024-05-09","objectID":"/posts/cybersecurity-dos-ddos-udp-flood/:0:1","tags":["linux","openbsd","freebsd","ipfw","pf","nftables","iptables","cybersecurity","ddos","dos","engineering","firewall"],"title":"Cybersecurity DoS DDoS UDP Flood","uri":"/posts/cybersecurity-dos-ddos-udp-flood/"},{"categories":null,"content":"Características Poder do ataque: o ataque é relativamente simples de ser realizado e requer poucos recursos do lado do atacante, já que é apenas uma questão de enviar uma grande quantidade de pacotes falsificados. Dificuldade de Rastreamento: devido ao IP spoofing, rastrear a origem do ataque e aplicar mitigação direcionada fica bem difícil. Impacto na disponibilidade: é o objetivo do ataque torná-lo inacessível para usuários legítimos. ","date":"2024-05-09","objectID":"/posts/cybersecurity-dos-ddos-udp-flood/:0:2","tags":["linux","openbsd","freebsd","ipfw","pf","nftables","iptables","cybersecurity","ddos","dos","engineering","firewall"],"title":"Cybersecurity DoS DDoS UDP Flood","uri":"/posts/cybersecurity-dos-ddos-udp-flood/"},{"categories":null,"content":"Mitigação Filtragem de pacotes: implementar filtros de pacotes para bloquear ou limitar o tráfego UDP suspeito. Detecção de Amplificação: identificar e corrigir vulnerabilidades em serviços que podem ser explorados para amplificar tráfego. Implementação de limites de taxa: configurar limites de taxa para o tráfego UDP. Análise de tráfego: monitorar o tráfego de rede para identificar padrões suspeitos de tráfego UDP para medidas de mitigação proativas. Serviços de proteção DDoS: considerar o uso de serviços de proteção DDoS de provedores CDN e segurança que podem detectar e mitigar ataques em tempo real. Atualização e patches de segurança: manter sistemas e serviços atualizados com as últimas correções de segurança para mitigar vulnerabilidades conhecidas que podem ser exploradas em ataques. Os ataques DDoS UDP flood representam uma ameaça significativa para a disponibilidade de serviços online e podem ser difíceis de mitigar devido à sua natureza distribuída e à facilidade de execução. A implementação de uma combinação de técnicas de mitigação ainda é a melhor forma de reduzir o impacto desses ataques e manter a disponibilidade dos serviços. Firewalls. Algumas técnicas possíveis nftables Limitação de taxa de pacotes Limitar a taxa de pacotes UDP por origem ou destino reduz a intensidade do ataque. nft add table ip filter nft add chain ip filter input { type filter hook input priority 0 \\; } nft add rule ip filter input udp limit rate 50/second burst 100 packets accept nft add rule ip filter input udp limit rate over 50/second drop add table ip filter: cria uma tabela chamada “filter” de família de endereço “ip”. add chain ip filter input { type filter hook input priority 0 \\; }: adiciona a cadeia base “input” na tabela “filter” fazemos um filtro no gancho input com prioridade 0. add rule ip filter input ip protocol udp limit rate 50/second burst 100 packets accept: serão aceitos pacotes com taxa abaixo de 50 por segundo com um burst(pico) de 100 pacotes. add rule ip filter input ip protocol udp limit rate over 50/second burst 100 packets drop: pacotes acima do limite de taxa serão descartados. Filtragem de portas e pacotes Bloquear portas incomuns. nft add rule ip filter input ip protocol udp dport 0-1023 drop udp dport 0-1023 drop: descarta pacotes destinados ao intervalo de portas (aqui como exemplo usamos as reservadas). Rastreamento de conexão O rastreamento de conexão ajuda a identificar e bloquear pacotes que não fazem parte de um padrão esperado. Apesar do UTP não ser orientado a conexão, o sistema “ct” trata a transação como uma única conexão rastreada baseada na origem+destino de endereço IP e portas enquanto ela passa pelas funções hook do ct. Por exemplo: o comando host dispara uma query para um servidor DNS criando o “ctinfo” “IP_CT_NEW”! E e quando o pacotes alcança a função hook “help+config” o status é “IPS_CONFIRMED” e o timeout de 30s e o rastreamento da conexão é adicionado na tabela ct… Quando o servidor DNS responde a query o sistema reconhece que as características desses pacotes coincidem com a conexão salva na tabela e que ainda está dentro do timeout configurado e então o “ctinfo” é configurado para “IP_CT_ESTABLISHED_REPLY” e o “status” para “IPS_SEEN_REPLY” e o timeout é configurado para 30s novamente e se não ocorrer mais nenhum pacote de ambos os hosts, o “status” é configurado para “IPS_DYING” nft add rule ip filter input ip protocol udp ct state new,established accept nft add rule ip filter input ip protocol udp ct state invalid drop udp ct state new,established accept: aceita conexões novas e estabelecidas. udp ct state invalid drop: descarta pacotes considerados inválidos. Filtragem de pacotes anômalos e fragmentados Pacotes com cabeçalhos ou tamanho inconsistentes podem indicar um ataque. nft add rule ip filter input ip protocol udp ip length 0 drop nft add rule ip filter input ip protocol udp ip length 512-65535 drop nft add rule ip filter input ip frag-off != 0 ip protocol udp drop udp ip len","date":"2024-05-09","objectID":"/posts/cybersecurity-dos-ddos-udp-flood/:0:3","tags":["linux","openbsd","freebsd","ipfw","pf","nftables","iptables","cybersecurity","ddos","dos","engineering","firewall"],"title":"Cybersecurity DoS DDoS UDP Flood","uri":"/posts/cybersecurity-dos-ddos-udp-flood/"},{"categories":null,"content":"Princípios Important O DevOps é mais do que apenas equipes de desenvolvimento e operações trabalhando juntas. É mais do que ferramentas e práticas. O DevOps é uma forma de pensar, uma mudança cultural, em que as equipes adotam novas formas de trabalhar. Na cultura de DevOps, os desenvolvedores se aproximam dos usuários, obtendo uma compreensão melhor dos requisitos e necessidades deles. As equipes de operações se envolvem no processo de desenvolvimento e adicionam requisitos de manutenção e necessidades do cliente. Ela também envolve aderir aos princípios essenciais a seguir, que ajudam as equipes a oferecer aplicativos e serviços: em um ritmo mais rápido com maior qualidade de código e melhor qualidade de vida ;) São 5 os princípios fundamentais do modelo DevOps Colaboração A principal premissa por trás do DevOps é a colaboração. As equipes de desenvolvimento e operações se unem em uma equipe funcional que se comunica, compartilha feedback e colabora durante todo o ciclo de desenvolvimento e implementação. Muitas vezes, quer dizer que as equipes de desenvolvimento e operações se fundem em uma única equipe que trabalha em todo o ciclo de vida do aplicativo. Os membros de uma equipe de DevOps são responsáveis por garantir entregas de qualidade em cada faceta do produto, levando a um desenvolvimento mais “full stack”, em que as equipes têm as responsabilidades completas de back-end e front-end de um recurso ou produto. As equipes vão ser as donas de um recurso ou projeto durante todo o ciclo de vida, da ideia até a entrega. O nível aprimorado de investimento e atenção da equipe leva a uma produção de maior qualidade. Automação Uma prática essencial do DevOps é automatizar o máximo possível o ciclo de vida do desenvolvimento do software, dando aos desenvolvedores mais tempo para escrever código e desenvolver novos recursos. A automação é um elemento crucial de um pipeline de IC/CD e ajuda a reduzir erros humanos e aumentar a produtividade da equipe. Com processos automatizados, as equipes obtêm melhoria contínua com tempos de iteração curtos, o que permite responder com mais rapidez aos comentários dos clientes. Implementação contínua A melhoria contínua foi estabelecida como um elemento básico das práticas ágeis, bem como da fabricação lean e Kata de melhoria. É a prática de se concentrar na experimentação, minimizar o desperdício e otimizar a velocidade, o custo e a facilidade de entrega. A melhoria contínua também está ligada à entrega contínua, permitindo que as equipes de DevOps enviem atualizações constantes que melhoram a eficiência dos sistemas de software. O pipeline constante de novas versões significa que as equipes promovem com consistência mudanças de código que eliminam o desperdício, melhoram a eficiência do desenvolvimento e trazem mais valor ao cliente. Ação voltada ao cliente As equipes de DevOps usam ciclos curtos de feedback com clientes e usuários finais para desenvolver produtos e serviços centrados nas necessidades do usuário. As práticas de DevOps permitem coleta e resposta rápidas ao feedback do usuário por meio do uso de monitoramento em tempo real e implementação rápida. As equipes obtêm visibilidade imediata de como os usuários ativos interagem com um sistema de software e usam os dados para desenvolver melhorias adicionais. Criar com o final em mente Esse princípio envolve entender as necessidades dos clientes e criar produtos ou serviços que resolvam problemas reais. As equipes não devem “criar uma bolha” ou um software com base em suposições sobre como os consumidores vão usar o software. Como alternativa, as equipes de DevOps devem ter uma compreensão holística do produto, da criação à implementação. ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:1:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"História O movimento do DevOps começou por volta de 2007 Foi num momento em que as operações de TI e comunidades de desenvolvimento de software levantaram preocupações sobre: Um modelo de desenvolvimento de software além do tradicional! O fato de que mesmo as metodologias ágeis terem sido adotadas para melhorar a colaboração: as melhorias ficaram restritas somente nas equipes de desenvolvimento. E ao fato de que mesmo a infraestrutura sempre apoiando os desenvolvedores em fases necessárias as equipes Infra/Operação e Produto/Dev não tinha alinhamentos trabalhando assim de forma ineficientes Dessa forma a solução dada foi o modelo DevOps Que na prática é a evolução dos métodos Ágeis, mas com a crucial evolução: A conexão das equipes de Operação e Desenvolvimento O DevOps reúne as habilidades, os processos e as ferramentas das equipes de desenvolvimento e operações para que trabalhem em conjunto! ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:2:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Benefícios Podemos simplificar de forma bem clara 3 benefícios centrais do DevOps: benefícios técnicos, Complexidade reduzida, entrega contínua e Resolução de problemas mais ágeis! Além de código de alta qualidade com mais rapidez com muito menos stress das equipes ;) benefícios culturais Equipes mais produtivas e eficientes devido a melhor qualidade de vida e usuários/clientes mais satisfeitos como consequência natural benefícios de negócios. Melhor colaboração e maior confiança entre os membros das equipes, resultando assim em entregas mais ágeis num ambiente operacional mais estável ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:3:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Cultura O DevOps traz uma mudança cultural muito forte onde as equipes trabalham amparadas por métodos de: engenharia de software, fluxo de trabalho conjunto de ferramentas O que de forma operacional coloca num único nível de importância: arquitetura, design e desenvolvimento! As equipes passam a ter uma maior compreensão dos requisitos e necessidades dos usuários. Os valores da transparência, comunicação e colaboração se elevam consideravelmente entre as equipes. ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:4:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Estrutura DevOps ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:5:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Framework CALMS CALMS foi compartilhado pela primeira vez por Jez Humble no The DevOps Handbook. E o significado da sigla é: Cultura Automação Simplicidade Medição Compartilhamento ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:6:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Topologias de equipe No livro, “Team Topologies”, Matthew Skelton e Manuel Pais definem quatro tipos fundamentais de equipes e o conceito de “mudança de fluxo”. Entendendo o conceito do livro fica fácil entender porque não funciona colocar “DevOps” no nome da equipe ou no cargo para criar uma “Equipe de DevOps” ou um “Engenheiro de DevOps”. Mas sim, em vez disso, as topologias de equipe ajudam a entender como suas práticas e ferramentas que se encaixam no quadro geral. Por isso primeiro passo para uma transformação de DevOps é identificar a estrutura organizacional em vigor e a partir dela idealizar a implementação do modelo DevOps. ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:7:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Métricas DORA Os profissionais confiam em quatro métricas principais, desenvolvidas pela DORA, para medir a eficácia das práticas de DevOps. Tempo de espera para alterações: qual é o tempo de espera para alterações de código desde o momento em que o código é verificado até o ponto em que ele é liberado para produção? Frequência de implementação: com que frequência e com que rapidez você lança para produção? Tempo de restauração do serviço: quando um incidente é detectado, quanto tempo leva para corrigir e restaurar o serviço? Taxa de falha de alteração: com que frequência ocorrem falhas de implementação na produção que exigem correção ou rollback imediatos? No projeto DORA, existe uma check rápido para medir o desempenho de entrega de software de equipe em menos de um minuto! E pode apoiar na implementação das métricas DORA ao comparar o resultado com de outras empresas no setor … DORA | DevOps Quick Check DevOps Research and Assessment (DORA) is a long running research program that seeks to understand the capabilities that drive software delivery and operations performance. https://dora.dev/quickcheck/ A equipe de pesquisa DORA, também criou o Four Keys que permite coletar dados de seu ambiente de desenvolvimento (como GitHub ou GitLab) e compilá-los em um painel que exibe essas métricas principais Ele é desenhado para funcionar sem modificações em cloud GCP! Porém podemos fazer algumas modificações para fazer uso com outros fornecedores… https://github.com/dora-team/fourkeys DORA 2022 Accelerate State of DevOps Report now out | Google Cloud Blog Security-enhancing DevOps practices are broadly adopted, this year’s DORA Accelerate State of DevOps Report found, but that’s not the whole story. https://cloud.google.com/blog/products/devops-sre/dora-2022-accelerate-state-of-devops-report-now-out Use Four Keys metrics like change failure rate to measure your DevOps performance | Google Cloud Blog Learn how the Four Keys open source project lets you gauge your DevOps performance according to DORA metrics. https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance Medição do DevOps: recursos de gerenciamento visual | Recursos de DevOps | Google Cloud https://cloud.google.com/architecture/devops/devops-measurement-visual-management?hl=pt-br ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:8:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"livros O Projeto Fênix POR KEVIN BEHR, GENE KIM E GEORGE SPAFFORD Criado por alguns dos nomes mais influentes do DevOps, este livro conta a história familiar de uma equipe de TI trabalhando com outras equipes da empresa para agregar valor. Saiba mais O Projeto Unicórnio POR GENE KIM* A sequência de “The Phoenix Project”, este livro conta a história de fazer o trabalho da perspectiva de um desenvolvedor de software. Saiba mais O Manual do DevOps POR GENE KIM, PATRICK DEBOIS, JOHN WILLIS E JEZ HUMBLE Como uma continuação dos livros orientados por narrativas, “O Projeto Fênix” e “O Projeto Unicórnio”, este livro oferece conselhos mais práticos para alcançar agilidade, confiabilidade e segurança de qualidade internacional em empresas de tecnologia. Saiba mais Accelerate POR NICOLE FORSGREN, JEZ HUMBLE E GENE KIM Os autores apresentam os resultados da pesquisa com análises rigorosas sobre a construção e o dimensionamento de empresas de tecnologia de alto desempenho. Saiba mais Effective DevOps POR JENNIFER DAVIS E RYN DANIELS Muitas empresas se concentram em trazer mais ferramentas para impulsionar a transformação de DevOps, mas o “DevOps eficaz” vai além das ferramentas para lidar com a transformação cultural necessária para impulsionar a adoção. Saiba mais Project to Product POR MIK KERSTEN Para sobreviver e prosperar no clima atual, as empresas devem se destacar na entrega de software em larga escala. O Dr. Mik Kersten apresenta o Flow Framework para ajudar as empresas a se tornarem inovadoras centradas em produtos. Saiba mais ","date":"2024-05-07","objectID":"/posts/devops-fundamentos/:9:0","tags":null,"title":"DevOps Fundamentos","uri":"/posts/devops-fundamentos/"},{"categories":null,"content":"Novu self-hosted","date":"2024-03-23","objectID":"/posts/rtfmrandomness-novuselfhosting/","tags":["Linux","open-source","notification","infrastructure","engineering","NGINX"],"title":"RTFM \u0026 Randomness - Novu Self-hosting","uri":"/posts/rtfmrandomness-novuselfhosting/"},{"categories":null,"content":"Novu - The open-source notification infrastructure for developers. The objective here is to show the configuration of the .env file and the NGINX reverse proxy, which was my biggest difficulty due to the lack of essential details in the project documentation for this purpose. ","date":"2024-03-23","objectID":"/posts/rtfmrandomness-novuselfhosting/:1:0","tags":["Linux","open-source","notification","infrastructure","engineering","NGINX"],"title":"RTFM \u0026 Randomness - Novu Self-hosting","uri":"/posts/rtfmrandomness-novuselfhosting/"},{"categories":null,"content":"How Does Novu Work? Novu is based on two components An API for data exchange A panel to design notifications and their logical rules ","date":"2024-03-23","objectID":"/posts/rtfmrandomness-novuselfhosting/:2:0","tags":["Linux","open-source","notification","infrastructure","engineering","NGINX"],"title":"RTFM \u0026 Randomness - Novu Self-hosting","uri":"/posts/rtfmrandomness-novuselfhosting/"},{"categories":null,"content":"Architecture Novu’s Object Communication Layer - OCL is a framework that separates communication tasks into specialized components, similar to microservices, that handle specific functions, such as messaging and data management. ","date":"2024-03-23","objectID":"/posts/rtfmrandomness-novuselfhosting/:2:1","tags":["Linux","open-source","notification","infrastructure","engineering","NGINX"],"title":"RTFM \u0026 Randomness - Novu Self-hosting","uri":"/posts/rtfmrandomness-novuselfhosting/"},{"categories":null,"content":"Let’s go Clone Novu repo # Go to source folder cd /usr/local/src # Get the code git clone --depth 1 https://github.com/novuhq/novu # Go to the docker folder cd novu/docker # Copy the example env file cp .env.example ./local/deployment/.env .env # Secrets # YOU MUST CHANGE THESE BEFORE GOING INTO PRODUCTION # used as a secret to verify the JWT token signature JWT_SECRET=\u003csecret\u003e # used to encrypt/decrypt the provider credentials STORE_ENCRYPTION_KEY=\u003ckey\u003e # Host HOST_NAME=https://novu.yourdns.com.br # General # available values 'dev', 'test', 'production', 'ci', 'local' NODE_ENV=local MONGO_MAX_POOL_SIZE=500 MONGO_MIN_POOL_SIZE=100 # MONGO USER MONGO_INITDB_ROOT_USERNAME=root # MONGO PASSWORD MONGO_INITDB_ROOT_PASSWORD=\u003cpassword\u003e MONGO_URL=mongodb://root:\u003cpassword\u003e@mongodb:27017/novu-db?authSource=admin REDIS_HOST=redis REDIS_PASSWORD=\u003cpassword\u003e REDIS_CACHE_SERVICE_HOST=redis # AWS S3_LOCAL_STACK=$HOST_NAME:4566 S3_BUCKET_NAME=novu-local S3_REGION=us-east-1 AWS_ACCESS_KEY_ID=test AWS_SECRET_ACCESS_KEY=test # Ports API_PORT=3000 REDIS_PORT=6379 REDIS_CACHE_SERVICE_PORT=6379 WS_PORT=3002 # Root URL REACT_APP_WS_URL=$HOST_NAME/ws # Uncomment this one when deploying Novu in the local environment # as Web app local Dockerfile will have to load this to be used. # Deployment version doesn't need as we inject it with API_ROOT_URL value. #REACT_APP_API_URL=$HOST_NAME:3000 API_ROOT_URL=$HOST_NAME/api DISABLE_USER_REGISTRATION=false FRONT_BASE_URL=$HOST_NAME:4200 WIDGET_EMBED_PATH=$HOST_NAME:4701/embed.umd.min.js WIDGET_URL=$HOST_NAME/widget # Context Paths for reverse-proxies GLOBAL_CONTEXT_PATH= WEB_CONTEXT_PATH= API_CONTEXT_PATH=api WS_CONTEXT_PATH=ws WIDGET_CONTEXT_PATH=widget # Analytics SENTRY_DSN= # change these values NEW_RELIC_APP_NAME= NEW_RELIC_LICENSE_KEY= DISABLE_USER_REGISTRATION= NGINX configuration server { listen 80; client_max_body_size 20M; server_name yourdns.com.br xxx.xxx.xxx.xxx; access_log /var/log/nginx/novu_access.log; error_log /var/log/nginx/novu_error.log; location / { proxy_pass http://localhost:4200; proxy_http_version 1.1; if ($request_method = OPTIONS) { add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE'; add_header 'Access-Control-Allow-Headers' 'Content-Type, Authorization'; return 200; } proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location /api { proxy_pass http://localhost:3000/api; proxy_http_version 1.1; add_header 'Access-Control-Allow-Origin' '*'; add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE'; add_header 'Access-Control-Allow-Headers' 'Content-Type, Authorization'; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location /ws { proxy_pass http://localhost:3002/ws; proxy_http_version 1.1; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location /widget { proxy_pass http://localhost:4500/widget; proxy_http_version 1.1; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location /socket.io/ { proxy_pass http://localhost:3002; proxy_http_version 1.1; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } # proxy_headers_hash_max_size 512; # proxy_headers_hash_bucket_size 128; } Now just be happy :) ","date":"2024-03-23","objectID":"/posts/rtfmrandomness-novuselfhosting/:3:0","tags":["Linux","open-source","notification","infrastructure","engineering","NGINX"],"title":"RTFM \u0026 Randomness - Novu Self-hosting","uri":"/posts/rtfmrandomness-novuselfhosting/"},{"categories":null,"content":"Aqui temos uma abordagem simples de identificação de causa raiz para troubleshooting em ambientes Microsoft Windows Server. Como exemplo estou usando um problema, que a equipe Microsoft de uma multinacional, enfrentou com um produto de mercado que estava causando um alto uso de Non-Paged Pool Memory(memory leak). E que causou, durante uma rotina de madrugada, o travamento de +500 servidores… eu era de uma equipe multidiciplinar. responsável por virtualização, storage, backup, Unix e Linux e acabei me envolvendo pois as equipes de Segurança e Microsoft estavam apenas trocando acusações e ainda não identificado a causa raiz… ","date":"2024-01-23","objectID":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/:0:0","tags":["Server","Troubleshooting","Microsoft"],"title":"RTFM \u0026 Aleatoriedades - Windows Server Troubleshooting","uri":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/"},{"categories":null,"content":"Problema Verificado que o non-paged pool está com tamanho anormal Conforme documentação da Microsoft, o Non-paged pool, pode ocupar até 75% da memória física. Porém não deve ser considerado como “normal” o grande uso da mesma, principalmente sem uma investigação etc… O Non-paged Pool são dados na RAM do computador usados ​​pelo kernel e pelos drivers do sistema operacional. Non-paged pool nunca é enviado para o disco (Page Cache)! Sempre ficará armazenado na memória física. Conforme a minha vivência, leak de memória, é quando um programa que armazena dados no pool de memória não paginável do sistema faz “merda”. Simples assim! ","date":"2024-01-23","objectID":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/:1:0","tags":["Server","Troubleshooting","Microsoft"],"title":"RTFM \u0026 Aleatoriedades - Windows Server Troubleshooting","uri":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/"},{"categories":null,"content":"Investigação Identificando o que está utilizando os Pools Memory no servidor Windão. Para o troubleshooting de Pool Memory é usada a ferramenta PoolMon que é um monitor que exibe dados que o Windão coleta sobre alocações de memória dos pools de kernel paginados e não paginados do sistema… Os dados são agrupados por marca de alocação de pool que evidencia as tags que identificam o software etc… Chega de conversa! Para tanto abra o command ou power shell e navegue até a pasta em que o executável “poolmon.exe” está localizado: Pode-se executar a ferramenta para que seja gerado um log: C:\\Temp\\Windows Kits\\10\\Tools\\x64\u003e poolmon -b -n C:\\Temp\\log_poolmon.txt Ou imprimir na STDOUT: C:\\Temp\\Windows Kits\\10\\Tools\\x64\u003e poolmon -b “-b” executa o aplicativo e organiza os processos em ordem de consumo. Aqui conseguimos ver que no topo da lista, temos o processo com maior consumo de RAM “5053046496” Bytes e sua Tag é “NFeS”. a TAG é um valor único e que é dado pela fabricante do driver. 5053046496 / 1024 = 4.934.615,... / 1024 = 4.818,... / 1024 = 4,7...GB Com a tag em mãos, deve-se usar a ferramenta findstr que procura por cadeia de caracteres! Dessa forma vamos tentar localizar o arquivo que possui a tag em seu conteúdo… Vamos em seguida acessar o diretório de drives no Windows: path: c:\\windows\\system32\\drivers C:\\\u003e cd c:\\windows\\system32\\drivers E executar a tool para a busca da tag C:\\Windows\\System32\\drivers\\\u003e findstr /m /l /s NFeS *.sys C:\\Windows\\System32\\drivers\\mfeavfk.sys /l: pesquisa por caracteres literais /m: lista apenas resultados correspondentes /s: pesquisa recursiva Bingo….\\o/! Identificamos com sucesso um aquivo que possui a tag: “mfeavfk.sys”! Agora para tentar identificar o programa que está usando esse driver. Vamos usar a ferramenta sigcheck que mostra metadados como, por exemplo: o número da versão do arquivo, carimbo de data/hora e detalhes da assinatura digital etc… C:\\\u003e sigcheck c:\\Windows\\System32\\drivers\\mfeavfk.sys Assim identificamos que o proprietário é o Anti-vírus McAfee. ","date":"2024-01-23","objectID":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/:2:0","tags":["Server","Troubleshooting","Microsoft"],"title":"RTFM \u0026 Aleatoriedades - Windows Server Troubleshooting","uri":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/"},{"categories":null,"content":"Sobre o Arquivo e Driver Identificado Dados do Host afetado Host: Windows Server Versão: Windows Server Enterprise 2012 R2 x64 Versões do produto MCAfee: McAfee Agent - version: 5.6.2.209 McAfee Endpoint Security Plataform - version: 10.6.11910 McAfee Endpoint Security Threat Prevention - version: 10.6.11910 ","date":"2024-01-23","objectID":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/:3:0","tags":["Server","Troubleshooting","Microsoft"],"title":"RTFM \u0026 Aleatoriedades - Windows Server Troubleshooting","uri":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/"},{"categories":null,"content":"Informações relevantes Dos processos iniciados e drivers utilizados pelo Virus Scan Enterprise no Windão: O driver mfeavfk: é um filtro para verificação de arquivos de sistema e para manter um cache desses arquivos aferidos. O arquivo mfeavfk.sys: é um componente de software do SYSCORE da McAfee que opera como Anti-Virus Filter Link para os produtos de segurança do McAfee. O VSE( VirusScan Enterprise) através do driver mfeavfk que opera a nível de kernel, juntamente com o Microsoft Filter Manager, consegue verificar o vírus em tempo real e de forma autônoma quando arquivos são abertos ou fechados. Basicamente é assim que a McAfee identifica um vírus manipulando arquivos etc… MFEAVFK é um acrônimo para = McAfee For Enterprise Anti-Virus File Link Filter Driver Características Mfeavfk.sys não é essencial para SO e por não ser nativo do sistema causa relativamente poucos problemas. Mfeavfk.sys está localizado na pasta C:\\Windows\\System32\\drivers O tamanho do arquivo no Windão tem em média 91.672 bytes. O driver pode ser iniciado ou parado quando feito de forma canônica. O programa não está visível no task manager. É assinado pela Verisign. Não há descrição detalhada do serviço. mfeavfk.sys parece ser um arquivo compactado. Portanto, a classificação de segurança técnica é 0% perigosa; no entanto: ao pesquisar reviews da comunidade a quantidade de problemas relacionados são incontáveis… :( Pesquisando na documentação técnica do produto, é informado pelo fabricante, que programas de backup e criptografia também usam o mesmo mecanismo: Por isso, conflitos e até mesmo corrompimentos de arquivos, podem ocorrer. Até mesmo quando um vírus, que possui mecanismo de proteção contra o driver “mfeavfk”, pode gerar problemas críticos ao tentar matar o processo que faz uso do driver etc… Continuando com a pesquisa, mas agora, tentando cruzar ocorrências do driver “mfeavfk.sys” e leaks de “Non-Paged Pool” na base de conhecimento McAfee e Internet: O primeiro matching foi certeiro! Encontrei diversos casos conhecidos pela McAfee do problema que estamos enfrentando e justamente com a mesma versão de SO e Anti-Vírus 😉 Segue link onde o assunto é extensivamente tratado entre clientes e suporte McAfee Link original está quebrado! Egraçado como as fabricantes desaparecem com alguns dados … Mas a WayBackMachine salvou uma cópia para a posteridade 😉 Logo em seguida, repassei essa investigação para as equipes de SegInfo e Microfofy para continuidade do troubleshooting… Referências https://kc.mcafee.com/corporate/index?page=content\u0026id=KB65784 https://www.file.net/process/mfeavfk.sys.html https://support.microsoft.com/pt-br/help/177415/how-to-use-memory-pool-monitor-poolmon-exe-to-troubleshoot-kernel-mode https://developer.microsoft.com/pt-br/windows/hardware https://docs.microsoft.com/en-us/sysinternals/downloads/sigcheck https://community.mcafee.com/t5/Endpoint-Security-ENS/Nonpaged-pool-memory-leak-mfeavfk-sys-on-multiple-windows-server/td-p/617169 https://docs.microsoft.com/en-us/windows-hardware/drivers/ifs/filter-manager-concepts ","date":"2024-01-23","objectID":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/:3:1","tags":["Server","Troubleshooting","Microsoft"],"title":"RTFM \u0026 Aleatoriedades - Windows Server Troubleshooting","uri":"/posts/rtfmaleatoriedades-windowsservertroubleshooting/"},{"categories":null,"content":"OSCP Stapling é o servidor Web (e não o navegador) obtendo resposta OCSP com status do certificado armazenando-o em cache, e esses dados são incluídos nas respostas HTTPS junto com o certificado… O OCSP - Online Certificate Status Protocol, descrita na RFC 2560, é um protocolo útil para determinar o status de um certificado digital X.509 RFC5280 sem exigir CRL - Certificate Revocation Lists descrita na RFC 2560 ou como complemento, pois fornece informações oportunas sobre o status de revogação de um certificado (RFC2459 Seção 3.3) que são utilizados por exemplo por transferências de fundos de alto valor ou grandes negociações de ações. O cliente OCSP emite uma solicitação de status para um OCSP responder e suspende a aceitação do certificado em questão até que o responder forneça uma resposta. Uma OCSP request contém os seguintes dados versão do protocolo requisição de serviço identificador do certificado de destino extensões opcionais que PODEM ser processadas pelo OCSP Responder $ openssl s_client -status -connect 0xttfx.github.io:443 CONNECTED(00000003) depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA verify return:1 depth=1 C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1 verify return:1 depth=0 C = US, ST = California, L = San Francisco, O = \"GitHub, Inc.\", CN = *.github.io verify return:1 OCSP response: ====================================== OCSP Response Data: OCSP Response Status: successful (0x0) Response Type: Basic OCSP Response Version: 1 (0x0) Responder Id: B76BA2EAA8AA848C79EAB4DA0F98B2C59576B9F4 Produced At: Jan 11 12:13:07 2024 GMT Responses: Certificate ID: Hash Algorithm: sha1 Issuer Name Hash: E4E395A229D3D4C1C31FF0980C0B4EC0098AABD8 Issuer Key Hash: B76BA2EAA8AA848C79EAB4DA0F98B2C59576B9F4 Serial Number: 044D72D77CDDA702DD5A67F2A23BBDD9 Cert Status: good This Update: Jan 11 11:57:01 2024 GMT Next Update: Jan 18 10:57:01 2024 GMT Signature Algorithm: sha256WithRSAEncryption Signature Value: 15:e9:8c:5a:f3:19:e5:22:9a:a1:63:7c:c6:f1:fd:18:34:f3: ea:20:2b:8c:93:63:50:29:17:99:a4:45:72:77:6b:56:8f:68: f4:78:2b:b6:b2:9d:de:09:ac:1f:df:e4:fb:7d:03:9e:7b:aa: 77:ca:58:bf:4b:0a:2d:08:08:ff:ed:7a:49:03:3c:87:08:08: df:1b:be:bc:62:5a:42:fc:32:be:bb:46:7e:1b:ac:6d:a1:e8: f8:38:da:7d:bc:dd:e4:bb:1b:09:ce:e5:1e:4a:97:92:01:f4: 4b:ac:2b:d0:2c:5b:14:d2:29:26:2b:a7:9d:a7:10:93:22:cc: f4:b8:11:66:a4:34:5e:35:c3:2e:0d:e7:38:0c:ae:c1:15:2f: 32:f3:73:59:fb:9c:9c:6d:24:63:e5:7d:54:24:60:ed:a6:bc: 6a:a1:95:49:f1:fc:29:bf:1a:92:9d:a4:a0:0d:e3:df:fd:79: 76:21:76:c1:cf:cd:8e:fa:3d:89:d9:1f:be:39:1a:44:5a:1b: 89:c1:ff:27:ec:37:f2:8b:ae:b2:e7:08:dd:ee:ca:c0:28:ca: 9a:5b:a9:fe:df:fe:9c:94:dd:fb:1f:44:b2:6b:b3:6e:ac:c3: 24:ef:1a:63:e7:3b:dd:1e:6f:29:21:a3:c0:a7:9e:c3:6a:6a: fd:a8:e1:21 ====================================== --- Certificate chain 0 s:C = US, ST = California, L = San Francisco, O = \"GitHub, Inc.\", CN = *.github.io i:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1 a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256 v:NotBefore: Feb 21 00:00:00 2023 GMT; NotAfter: Mar 20 23:59:59 2024 GMT 1 s:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1 i:C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256 v:NotBefore: Apr 14 00:00:00 2021 GMT; NotAfter: Apr 13 23:59:59 2031 GMT --- Server certificate -----BEGIN CERTIFICATE----- MIIHEjCCBfqgAwIBAgIQBE1y13zdpwLdWmfyoju92TANBgkqhkiG9w0BAQsFADBP MQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMSkwJwYDVQQDEyBE aWdpQ2VydCBUTFMgUlNBIFNIQTI1NiAyMDIwIENBMTAeFw0yMzAyMjEwMDAwMDBa Fw0yNDAzMjAyMzU5NTlaMGcxCzAJBgNVBAYTAlVTMRMwEQYDVQQIEwpDYWxpZm9y bmlhMRYwFAYDVQQHEw1TYW4gRnJhbmNpc2NvMRUwEwYDVQQKEwxHaXRIdWIsIElu Yy4xFDASBgNVBAMMCyouZ2l0aHViLmlvMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8A MIIBCgKCAQEAuLBgDhov8bGGS2TsEZ+meb7oh/GIxbRJmxC7yq/qr75UDHhDf8p7 TkVbCyQp8bsj/Bmkx2xwSXZT0wkjZbJIe7Ycqgca4nka+Xpe5xb4pkrVOaPiDfdX 7+34CHZbUtqL0OYebi/5D5lLalLKNOGkySAz","date":"2024-01-21","objectID":"/posts/rtfmaleatoriedades-ocspstapling/:0:0","tags":["Linux","TLS"],"title":"RTFM \u0026 Aleatoriedades - OCSPStapling","uri":"/posts/rtfmaleatoriedades-ocspstapling/"},{"categories":null,"content":"Sempre existe a possibilidade de um dia aparecer um servidor com uma versão de SO não atual precisando que o NTP client seja configurado ou revisado… :) Instalando o serviço NTP Instale o pacote NTP com o utilitário yum $ yum install ntp -y Em seguida liste os comandos de administração fornecidos pelo pacote npt $ ntp\u003ctab\u003e\u003ctab\u003e ntpd ntpdate ntpdc ntp-keygen ntpq ntpstat ntptime Inicialize o serviço $ sudo service ntpd start ou $ sudo /etc/rc.d/init.d/ntpd start Ao iniciar o serviço, analise em seguida os logs no /var/log/messages $ sudo tail /var/log/messages ou $ grep ntpd /var/log/messages Jul 23 13:11:51 labcentos01 yum[9343]: Installed: ntpdate-4.2.4p83.el6.centos.x86_64 Jul 23 13:12:11 labcentos01 ntpd[9375]: ntpd Fri Feb 22 11:23:27 UTC 2013 (1) Jul 23 13:12:11 labcentos01 ntpd[9376]: precision = 0.111 usec Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #0 wildcard... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #1 wildca... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #2 lo, ::1... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #3 eth0, .... Jul 23 13:12:11 labcentos01 ntpd[9376]: Listening on interface #4 lo, 127.0.... Automatize o serviço para que inicie no boot: $ sudo chkconfig --level 35 ntpd on Configuração do arquivo padrão do serviço “/etc/ntp.conf” Segue o arquivo padrão fornecido pelo pacote de instalação: # be tightened as well, but to do so would effect some of # the administrative functions. restrict 127.0.0.1 restrict -6 ::1 # Hosts on local network are less restricted. #restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst #broadcast 192.168.1.255 autokey # broadcast server #broadcastclient # broadcast client #broadcast 224.0.1.1 autokey # multicast server #multicastclient 224.0.1.1 # multicast client #manycastserver 239.255.254.254 # manycast server #manycastclient 239.255.254.254 autokey # manycast client # Enable public key cryptography. #crypto includefile /etc/ntp/crypto/pw # Key file containing the keys and key identifiers used when operating # with symmetric key cryptography. keys /etc/ntp/keys # Specify the key identifiers which are trusted. #trustedkey 4 8 42 # Specify the key identifier to use with the ntpdc utility. #requestkey 8 # Specify the key identifier to use with the ntpq utility. #controlkey 8 # Enable writing of statistics records. #statistics clockstats cryptostats loopstats peerstat Modifique as linhas “server”, substituindo pelo servidor NTP local; sendo uma linha para cada servidor… : server 0.redhat.pool.ntp.org iburst server 1.redhat.pool.ntp.org iburst Modificando para o NTP Brasileiro ou na LAN: server 192.0.2.151 iburst ou server a.st1.ntp.br iburst ou server a.ntp.br iburst a flag iburst faz com que uma saraivada de mensagens sejam trocadas para preparar os dados e ajustar o relógio por cerca de 10s. Reinicie o serviço NTP sudo /etc/init.d/ntpd restart Agora visualize como ficou o arquivo de configuração do serviço NTP: $ sudo cat /etc/ntp.conf |grep -E -v \"^$|^#\" |nl 1 driftfile /var/lib/ntp/drift 2 restrict default kod nomodify notrap nopeer noquery 3 restrict -6 default kod nomodify notrap nopeer noquery 4 restrict 127.0.0.1 5 restrict -6 ::1 6 server 192.0.2.151 iburst 7 includefile /etc/ntp/crypto/pw 8 keys /etc/ntp/keys Outra opção interessante para habilitar no “ntp.conf” para a configuração cliente é a diretiva de estatísticas: # estatisticas do ntp que exibe informaões de funcionamento. statsdir /var/log/ntpstats/ statistics loopstats peerstats filegen loopstats file loopstats type day enable ilegen peerstats file peerstats type day enable Verificando se o daemon NTP está devidamente configurado e operando: Execute o comando “ntpq” com a opção “-c peers” que lista estatísticas dos servidores cadastrados no","date":"2024-01-09","objectID":"/posts/rtfmaleatoriedades-oldntp/:0:0","tags":["NTP","Linux","RTFM"],"title":"RTFM \u0026 Aleatoriedades - Old NTP Client","uri":"/posts/rtfmaleatoriedades-oldntp/"},{"categories":null,"content":"O intuito desse how to é apoiar na solução de problemas rede de containers Docker ","date":"2024-01-06","objectID":"/posts/rtfmaleatoriedades-ntcdocker/:0:0","tags":["Docker"],"title":"RTFM \u0026 Aleatoriedades - Network Trobleshooting Container Docker","uri":"/posts/rtfmaleatoriedades-ntcdocker/"},{"categories":null,"content":"Disclaimer Se caiu aqui no momento em que está tentando apagar um incendio: você está no lugar errado! Mas retorne depois do incendio .. ;) ","date":"2024-01-06","objectID":"/posts/rtfmaleatoriedades-ntcdocker/:1:0","tags":["Docker"],"title":"RTFM \u0026 Aleatoriedades - Network Trobleshooting Container Docker","uri":"/posts/rtfmaleatoriedades-ntcdocker/"},{"categories":null,"content":"Requeriments Para fazer um debug descente, precisamos estar familiarizados com questões básicas! ","date":"2024-01-06","objectID":"/posts/rtfmaleatoriedades-ntcdocker/:2:0","tags":["Docker"],"title":"RTFM \u0026 Aleatoriedades - Network Trobleshooting Container Docker","uri":"/posts/rtfmaleatoriedades-ntcdocker/"},{"categories":null,"content":"Como as coisas “funfam” dabaixo do capô da containerização Namespaces Linux fornecem as tecnologias fundamentais da implementação de containers. Fornecendo isolamento de recursos globais entre processos independentes Namespaces fornece isolamento e não restrição ao hardware adjacente! Isso é papel do cgroups São 8 namespaces até o momento Mount - Mount points cria uma hierarquia de diretórios isolado do sistema de arquivos do host, visivel apenas pelo processo em execução nessa árvore de diretórios do namespace. UTS - Hostname and NIS domain name cria isolamento dos identificadores hostname e o NIS domain name que são definidos usando sethostname(2), setdomainname(2) e pode ser recuperado usando uname(2) , gethostname(2) e getdomainname(2) . IPC - System V IPC, POSIX message queues isolam sysvipc(7) - System V Objetos IPC e mq_overview(7) - POSIX filas de mensagens. Dessa forma, o namespace tem seus identificadores IPC e filas de mensageria POSIX próprios, vistos apenas pelos processos que executam nele. PID - Process IDs Cria espaço do número de ID do processo isolados do host. Permite que o processo containerizado faça uso do recurso bem legal, o Freezing of tasks que permite suspender um conjunto de processos de um contêiner e migralos para outro container, em outro host, enquanto os processos internos mantêm os mesmos PIDs… agradeça ao Freezing tasks pelas mágicas no seu notebook ao hibernar… Network - Network devices, stacks, ports, etc. fornecem isolamento dos dispositivos de rede, pilhas de protocolos IP v4 e v6, tabelas de roteamento IP, regras de firewall, os diretórios /proc/net (link para /proc/ pid /net ), /sys/class/net , arquivos em /proc/sys/net , soquetes etc… Bem como também dos soquetes abstratos do domain unix(7). Tanto uma interface de rede física, quanto uma veth(4) User - User and group IDs Faz isolamento dos recursos credentials(7) que são os identificadores relacionados à segurança e atributos, em particular, IDs de usuário e IDs de grupo, o diretório raiz, keyrings(7) e capabilities(7). Cgroup - Cgroup root directory Faz o isolamento virtualizando a visão do cgroups(7) por um processo via /proc/pid/cgroup e /proc/pid/mountinfo. Dessa forma o namespace possui seu próprio conjunto de diretórios raiz cgroup, que são os caminhos relativos dos registros correspondentes no arquivo /proc/pid/cgroup, quando um processo cria um novo namespace usando clone(2) ou unshare(2) com a flag CLONE_NEWCGROUP… Time - Boot and monotonic clocks O time afeta afeta várias APIs como o clock_gettime(2), clock_nanosleep(2), nanosleep(2), timer_settime(2), timerfd_settime(2) e /proc/uptime, fazendo a virtualização isolada dos relógios de sistema: CLOCK_MONOTONIC (e também CLOCK_MONOTONIC_COARSE e CLOCK_MONOTONIC_RAW ), um relógio não configurável que representa um tempo monótono desde então(conforme descrito por POSIX - “algun ponto não especificado no passado”). CLOCK_BOOTTIME (e também CLOCK_BOOTTIME_ALARM ), um relógio não configurável que é idêntico a CLOCK_MONOTONIC , exceto que também inclui qualquer momento em que o sistema está suspenso. Dessa forma já conseguimos tridimensionalizar mentalmente que: A coisa toda é meio que um processo containerizado por recursos que o fazem rodar em um diretório onde existirá um sistema de arquivos, fazendo com que o processo o veja como o uma arvore filesystem, com seus pid/gid e pilha de rede, hostname e domainname / nisdomainname bem como as chamadas IPC e relógios de sistema isolados do host hospedeiro.. Aqui vale lembrar que esses namespaces não são de propriedade do processo! Eles operam de forma independente qualquer outro processo pode ser containerizado nesses namespaces já existentes, dessa forma compatilhando-os… E de forma independente pois você pode executar um processo dentro de um namespace Network, sem que ele tenha um Mount e UTS por exemplo isso é massa porque é possível usar um comando que existe no Host, porém a execução será dentro de um namespace! por isso, não é nec","date":"2024-01-06","objectID":"/posts/rtfmaleatoriedades-ntcdocker/:2:1","tags":["Docker"],"title":"RTFM \u0026 Aleatoriedades - Network Trobleshooting Container Docker","uri":"/posts/rtfmaleatoriedades-ntcdocker/"},{"categories":null,"content":"Swapping foi introduzida como um backup em disco para páginas não mapeadas. E existem três tipos de páginas que devem ser tratadas pelo subsistema de swapping: Pages que pertencem a uma região de memória anônima de um processo (User Mode stack) Dirty pages que pertencem a um mapeamento de memória privada de um processo Pages que pertencem a uma região de memória compartilhada IPC Numa “Regular Paging” cada entrada na “Page Table” inclui um sinalizador, uma “Present flag” e o Kernel explora esse sinalizador para sinalizar que uma página pertencente a um espaço de endereço de um processo qualquer foi “swapped out”! E além desse sinalizador, o Linux faz uso dos bits restantes do “Page Table” pra armazenar um identificador de “swapped-out page” que informa a localização no disco. A Principais características do subsistema swapping são: Configura area swap para armazenamento de Pages que não possuem “disk image”. Gerencia espaço na área de swap alocando e liberando “page slots”. Fornece a função de “swap out” pages da RAM para a área de swap e “swap in” pages da área de swap para RAM. Faz uso da “swapped-out page identifiers” das entradas na “Page Table” que foram swapped para acompanhar as posições dos dados na área de swap. Em suma, o swapping é o principal recurso de “page frame reclaiming”! E se queremos ter certeza que todos os “page frames” obtidos por um processo, não apenas os “pages” que contem “disk image”, possam ser recuperados pelo PFRA, devemos fazer uso do swapping… Com isso podemos deduzir que grandes áreas de swap dão poder ao Kernel para iniciar vários processos onde o total de solicitações de memória ultrapassa a quantidade de RAM física. E como na TI, nem tudo são flores, precisamos nos atentar que simular RAM em disco, nos traz um desempenho em milissegundos se comparado aos nanosegundos da RAM física ;) Note Referencia: Daniel P. Bovet, Marco Cesati - Understanding the Linux Kernel - Capítulo 2 - Memory Addressing e Capítulo 17 - Page Frame Reclaiming Agora que nivelamos a introdução sobre swapping, vamos criar um espaço de troca, do tipo arquivo, que não muda em nada quando partição em disco: a não ser o processo de particionamento de disco etc… Verificando se há algum swap sudo swapon --show Criando arquivo de swap de 2GiB sudo dd if=/dev/zero of=/swapfile count=2192 bs=1MiB Alterando permissão do arquivo sudo chmod 600 /swapfile Marcando o arquivo como um espaço de swap sudo mkswap /swapfile Verificando se está tudo ok sudo swapon --show Adicionando a linha no ‘/etc/fstab’ para montagem automática echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab Ajustando a configuração de Swap O parâmetro /proc/sys/vmwappiness configura a frequência com que o sistema transfere dados da RAM para o espaço de swap. Sendo um valor entre 0 e 100 que representa uma porcentagem! Um valor baixo significa que o seu sistema Linux troca processos raramente enquanto um alto valor significa que os processos são gravados em disco imediatamente Com valores próximos de zero, o kernel não irá transferir dados para o disco a menos que seja absolutamente necessário. Lembre-se, as interações com o arquivo de swap são “dispendiosas”! Pois são mais lentas que as interações com a RAM. Valores que estão mais próximos de 100 irão tentar colocar mais dados no swap em um esforço para manter mais espaço da RAM livre. Dependendo do perfil de memória de seus aplicativos ou do motivo pelo qual você está usando o seu servidor, isso pode ser melhor em alguns casos. Swappiness: 60 Swap a partir de 40% de uso de RAM. Swappiness: 40 Swap a partir de 60% de uso de RAM. Swappiness: 20 Swap a partir de 80% de uso de RAM. Swappiness: 10. Swap a partir de 90% de uso de RAM. Swappiness: 1 Swap a partir de 99% de uso de RAM. Para um desktop, um valor de swappiness de 60 não é um valor ruim e normalmente é o valor dfault em uma distro Linux. Mas para um servidor, podemos deixá-lo mais próximo de 0, para fazer uso somente quando realmente necessário Como ex","date":"2024-01-06","objectID":"/posts/rtfmaleatoriedades-swap/:0:0","tags":["Linux","RAM","Disk","SWAP"],"title":"RTFM \u0026 Aleatoriedades - Swap","uri":"/posts/rtfmaleatoriedades-swap/"},{"categories":null,"content":"Para quando a lei de Murphy exerce a sua força. É nessa hora, que do seu kit MacGyver, você tira o journalctl para identificar o que pode estar errado! Das muitas formas possíveis. Tem mais essa: $ journalctl --no-pager --since today --grep 'fail|error|fatal' --output json|jq Com a opção “–grep” filtramos palavras chave Com a opção “–since” melhoramos nossa assertividade. Ex: –since “1 hour ago” –since “1 minutes ago” –since “5 seconds ago” –since 07:00 –until “1 hour ago” Com o “–output” usando o formato json, fazemos um parser amigável pra organizarmos com jq. $ journalctl --no-pager --since today --grep 'fail|error|fatal' --output json|jq { \"_PID\": \"5605\", \"_SYSTEMD_SLICE\": \"user-1000.slice\", \"_SYSTEMD_USER_UNIT\": \"org.gnome.Shell@wayland.service\", \"_RUNTIME_SCOPE\": \"system\", \"_SYSTEMD_UNIT\": \"user@1000.service\", \"__SEQNUM\": \"7540847\", ... ... \"_SYSTEMD_OWNER_UID\": \"1000\", \"SYSLOG_IDENTIFIER\": \"google-chrome.desktop\", \"_COMM\": \"cat\", \"__MONOTONIC_TIMESTAMP\": \"285995139402\", \"_CMDLINE\": \"cat\", \"_BOOT_ID\": \"da45ccab9c404e9444444a9c51300cae\", \"_EXE\": \"/usr/bin/cat\" } { ... ... Ainda é possível filtrar por algum objeto com o jq e quantificar as ocorrências com sort e uniq Talvez, alguns objetos interessantes seriam _EXE, _CMDLINE, _PID, SYSLOG_IDENTIFIER, MESSAGE… $ journalctl --no-pager --since \"60 minutes ago\" --grep 'fail|error|fatal' --output json|jq '.SYSLOG_IDENTIFIER' | sort | uniq -c 1 \"audit\" 1 \"cupsd\" 19 \"discord.desktop\" 2 \"fprintd\" 7 \"gnome-shell\" 10518 \"google-chrome.desktop\" 18 null 4 \"org.gnome.Software.desktop\" 173 \"slack.desktop\" ","date":"2024-01-05","objectID":"/posts/rtfmaleatoriedades-journalctl/:0:0","tags":["SystemD","Linux"],"title":"RTFM \u0026 Aleatoriedades para SysAdmin - journalctl ","uri":"/posts/rtfmaleatoriedades-journalctl/"},{"categories":null,"content":"RAM é um hardware valioso e caro bem como a sua latência é ainda mais importante que a latência do disco. E por isso, o kernel Linux tenta ao máximo otimizar os uso da memória, fazendo uso de técnicas como compartilhando de páginas entre processos e Page Cache para melhorar a velocidade de I/O de armazenamento, armazenando um subconjunto de dados do disco na memória. O Page Cache realiza compartilhamento implícito de memória e de forma assíncrona com o armazenamento em segundo plano! Isso por sí só, traz ainda mais complexidade à estimativa de uso de memória por parte dos administradores! ","date":"2023-11-15","objectID":"/posts/rtfmaleatoriedades-pagecache/:0:0","tags":["first"],"title":"RTFM \u0026 Aleatoriedades  - Who Page Cache","uri":"/posts/rtfmaleatoriedades-pagecache/"},{"categories":null,"content":"Mas o que é Page Cache o Page Cache faz parte do Virtual File System - VFS que é uma camada de software do núcleo que trata de todas as chamadas de sistema relacionadas a um sistema de arquivos Unix. Sua principal vantagem é prover uma interface genérica para diversos tipos de sistemas de arquivos. Ou seja, o VFS permite que chamadas de sistemas genéricas, tais como open( ) e read( ),possam ser executadas independentemente do sistema de arquivos usados ou do meio físico! O que implica diretamente na latência de I/O das operações de leitura e gravação. Quando um sistema grava dados no cache, em algum momento também deve gravar esses dados no armazenamento. O tempo dessa gravação é controlado pelo que é conhecido como write policy, e existem duas abordagens básicas de escrita: Write-through: a gravação é feita de forma síncrona tanto no cache quanto no armazenamento de apoio. Write-back: inicialmente, a escrita é feita apenas no cache. A gravação no armazenamento de apoio é adiada até que o conteúdo modificado esteja prestes a ser substituído por outro bloco de cache. Nesse link você pode ter mais informações sobre o algorítimo Page é a unidade de memória que o Kernel trabalha com Page Cache, e geralmente possui 4k de comprimento mínimo de armazenamento no Page Cache. Dessa forma todo I/O de arquivo está alinhado a uma quantidade específica de páginas… Até aqui, podemos entender que o Page Cache, é o principal cache de disco usado pelo kernel do Linux e é utilizado ao ler ou gravar no disco quando novas páginas são adicionadas ao Page Cache para satisfazer as solicitações de leitura dos processos do User Mode stack. Se a página ainda não estiver no cache, uma nova entrada será adicionada ao cache e preenchida com os dados lidos do disco. Se houver memória livre suficiente, a página é mantida no cache por um período indefinido e pode então ser reutilizada por outros processos sem acessar o disco. Da mesma forma, antes de gravar page de dados em um dispositivo de bloco, o kernel verifica se a page correspondente já está incluída no cache; caso contrário, uma nova entrada é adicionada ao cache e preenchida com os dados a serem gravados no disco. A transferência de dados de I/O não começa imediatamente: - a atualização do disco é atrasada por alguns segundos, dando assim aos processos a chance de modificar ainda mais os dados a serem gravados em outras palavras, o kernel implementa operações de deferred write As páginas incluídas no Page Cache podem ser os seguintes tipos: Pages contendo dados de arquivos regulares; no Capítulo 16, descrevemos como o kernel lida com operações de leitura, gravação e mapeamento de memória neles. Pages contendo diretórios; o Linux lida com os diretórios de forma muito semelhante aos arquivos normais. Pages contendo dados lidos diretamente de arquivos de dispositivos de bloco (ignorando a camada do sistema de arquivos); o kernel os trata usando o mesmo conjunto de funções como para pages contendo dados de arquivos regulares. Pages contendo dados de processos do User Mode stack que foram trocados em disco; o kernel pode forçar a manter-se armazenado em page cache algumas pages cujo conteúdo já foi escrito em uma área de swap. Pages pertencentes a arquivos de sistemas de arquivos especiais, como o sistema de arquivos especial shm usado para região de memória compartilhada de comunicação entre processos (IPC). Como podemos ver, cada page incluída no Page Cache contém dados pertencentes a algum arquivo. Este arquivo – ou mais precisamente o inode do arquivo – é chamado de page’s owner. Praticamente todas as operações read() e write() de arquivos dependem do Page Cache. a única exceção ocorre quando um processo abre um arquivo com a flag O_DIRECT definido: neste caso, o cache da página é ignorado e as transferências de dados de E/S fazem uso de buffers no espaço de endereço do modo de usuário do processo. Várias aplicações database fazem uso da flag O_DIRECT pra que assim possam faze uso do próprio algorítim","date":"2023-11-15","objectID":"/posts/rtfmaleatoriedades-pagecache/:1:0","tags":["first"],"title":"RTFM \u0026 Aleatoriedades  - Who Page Cache","uri":"/posts/rtfmaleatoriedades-pagecache/"},{"categories":null,"content":"RSS e VSZ Vamos começar tendo como referencia o VSZ que é o tamanho da memória virtual que o Linux concedeu a um processo. Mas não necessariamente o processo está usando o valor informado. Um dos motivos são programas com funções para realizar determinadas tarefas, mas só as carregam na RAM, quando necessário. Bem como também a paginação por demanda do Linux, que só carrega páginas na memória quando o aplicativo tenta usá-las… Por isso a leitura que devemos fazer do valor é: memória se carregadas todas as suas funções e bibliotecas na memória física. Já RSS, é o tamanho do conjunto residente. É a quantidade de RAM que o processo no momento para carregar as suas páginas. Ainda assim não podemos tomar essa informação como concreta, devido as bibliotecas compartilhadas torna-se um valor impreciso por superestimativa… Primeiro criamos um processo em um novo cgroup Rodamos o comanod mtr utilizando o systemd-run para isolá-lo num cgroup(por que sim…rs) systemd-run --user -P -t -G --wait mtr 8.8.8.8 Em seguida coletamos o seu PID e verificamos os valores de RSS e VSZ Com o comando ps coletamos seu PID e os dados de RSS e VSZ O PID do processo $ ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk '{print $2}' 236341 E os dados de RSS e VSZ $ ps -o rss,vsz,cmd -p $(ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk '{print $2}') RSS VSZ CMD 7168 14940 systemd-run --user -P -t -G --wait mtr 8.8.8.8 Só a título de cuiriosidade, segue algumas formas de coverter o valor para megabytes: $ echo $((7168/1024)) 7 ou $ echo $((7168/1024)) |xargs -i printf \"%'.1f MB\" {} 7.0 MB ou $ numfmt --from=si --to=iec 7168K 6.9M ou $ numfmt --from=si --to-unit=1Mi --grouping 7168K 7 Podemos ver que o processo está consumindo 7168 Kilobytes. Em seguida usamos o procfs para ter mais detalhes desse uso de RAM que o RSS está apontando. Vamos ver o arquivo smaps_rollup que é uma soma das áreas de memória do smaps do nosso PID $ cat /proc/236341/smaps_rollup 559517c38000-7ffe5c398000 ---p 00000000 00:00 0 [rollup] Rss: 7368 kB Pss: 1171 kB Pss_Dirty: 868 kB Pss_Anon: 868 kB Pss_File: 303 kB Pss_Shmem: 0 kB Shared_Clean: 6444 kB Shared_Dirty: 0 kB Private_Clean: 56 kB Private_Dirty: 868 kB Referenced: 7368 kB Anonymous: 868 kB LazyFree: 0 kB AnonHugePages: 0 kB ShmemPmdMapped: 0 kB FilePmdMapped: 0 kB Shared_Hugetlb: 0 kB Private_Hugetlb: 0 kB Swap: 0 kB SwapPss: 0 kB Locked: 0 kB Para as métricas listadas RSS que já é nossa conhecida. PSS Proportional Set Size é o compartilhamento proporcional de memória do processo. É a contagem de páginas que ele possui na memória, onde cada página é dividida pelo número de processos que a compartilham. Portanto, se um processo tiver 1.000 páginas só para ele e 1.000 compartilhadas com outro processo, seu PSS será 1.500. Shared_Clean aqui vemos que nosso processo usa cache de página. E representa o maior uso da memória. No arquivo smaps, conseguimos ver todas as bibliotecas compartilhadas que foram abertas com mmap() e residem no Page Cache. Shared_Dirty quando o processo grava em arquivos com mmap(), esta linha mostra a quantidade de memória suja do cache de página ainda não salva. Referenced é a quantidade de memória referenciada ou acessada até o momento. O valor é sempre igual ou próximo RSS. Anonymous mostra a quantidade de memória que não pertence a nenhum arquivo. Até qui podemos ver que, embora o comando PS e Top nos mostre um RSS de 7MiB, a maior parte de seu RSS está oculto no cache de página e que quando ficarem inativas por um tempo, essas páginas, serão removidas da RAM pelo kernel. Nesse artigo do LWN.net temos mais informações direto da fonte ;). Continua em breve… ","date":"2023-11-15","objectID":"/posts/rtfmaleatoriedades-pagecache/:2:0","tags":["first"],"title":"RTFM \u0026 Aleatoriedades  - Who Page Cache","uri":"/posts/rtfmaleatoriedades-pagecache/"},{"categories":null,"content":"ipdo-awsrds ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:1:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"},{"categories":null,"content":"Função Scrip bash para descoberta dos IPs WAN dos DOcean Droplets e inserção em security groups EC2 das instâncias AWS RDS. ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:2:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"},{"categories":null,"content":"Atualizações v0.4 Como inteválo mínimo de execução na CRON são de 60 segundos! E eu precisava executar por mais vezes por minuto acabei contendo o scrip dentro de um laço wile que o executa por 10 vezes com intervalo de 2 segundos v0.5 removido laço de x execuções a cada 60s restruturado algumas conditional statement da inserção e remoção de IPs O diff, antes realizado globalmente, agora é realizado para cada Security Group v0.6 Implementado o builtin set com as options errtrace, errexit, nounset e pipefail para deixar o script mais criterioso quanto a erros Principalmente os de APIs 5xx sem a necessidade de fazer testes em funções, condições etc. Implementado trap para melhor localização do momento e local do erro. v0.7 Implementado arquivo PID. Modificado método de criação de array’s específicos para uso mapfile Melhorias no filtro diff dos arquivos de IPs Melhorias nos filtros para criação de array IPs Modificado no laço aninhado de inserção e remoção de IP para melhora do parser v0.8 Implementado tratativa para cod error diff Implementado arquivo de diff temporário para cada sec. group verificado Implementado tratativa para cod error na criação de array usando arquivo diff temporário Implementado remoção de arquivos temporários em cada laço v1.0 Agora sim! ipdo-awsrds agora é GA - Disponibilidade Geral! Versão estável para uso em ambiente produção. ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:3:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"},{"categories":null,"content":"Dependências AWS CLI AWS CLI EC2 API authorize-security-group-ingress API describe-security-groups RDS API describe-db-instances DigitalOcean CLI DO CLI API compute ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:4:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"},{"categories":null,"content":"Executando Crie diretório tools e tool/log em /usr/local mkdir -p /usr/local/tools/log \u0026\u0026 cd /usr/local/tools/ \u0026\u0026 \\ git clone git@github.com:0xttfx/ipdo-awsrds.git Agora criamos o arquivo path-tools.sh em /etc/profile.d/ para configurar o PATH para diretório tools sudo \u003e /etc/profile.d/path-tools.sh Em seguida adicione o conteúdo: # configurando PATH para incluir diretório tools caso exista. if [ -d \"/usr/local/tools/ipdo-awsrds\" ] ; then PATH=\"$PATH:/usr/local/tools/ipdo-awsrds\" fi Eof Para execução do script é necessário declarar o user profile aws cli usando a opção -u ipdo-awsrds -u \u003cnome\u003e ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:5:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"},{"categories":null,"content":"Automação Para automação da execução, adicione a seguinte linha na crontab do usuário(crontab -e) não privilégiado. Devido ao update, adição e remoção dos nós dos clusters, o script será executado a cada 1 mintuo! altere conforme sua necessidade. * * * * * /usr/bin/bash -x /usr/local/tools/ipdo-awsrds -u nome \u003e\u003e /usr/local/tools/log/ipdo-awsrds-$(date --date=\"today\" +\\%d\\%m\\%Y_\\%H\\%M\\%S).log 2\u003e\u00261 0 0 * * * /usr/bin/find /usr/local/tools/log/ -type f -mtime +5 -name 'exec-*.log' -exec rm {} + ","date":"2023-11-06","objectID":"/posts/ipdo-awsrds/:6:0","tags":["DOK","AWS","RDS"],"title":"IP DOK Set or Drop Sec Group AWS EC2 RDS","uri":"/posts/ipdo-awsrds/"}]