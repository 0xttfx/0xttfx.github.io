<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Só mais um SysAdmin</title>
        <link>https://0xttfx.github.io/posts/whoram/</link>
        <description>Recent content on Só mais um SysAdmin</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Wed, 15 Nov 2023 20:25:31 -0300</lastBuildDate>
        <atom:link href="https://0xttfx.github.io/posts/whoram/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>WhoRAM</title>
            <link>https://0xttfx.github.io/posts/2023/11/whoram/</link>
            <pubDate>Wed, 15 Nov 2023 20:25:31 -0300</pubDate>
            
            <guid>https://0xttfx.github.io/posts/2023/11/whoram/</guid>
            <description>RAM é um hardware valioso e caro bem como a sua latência é ainda mais importante que a latência do disco. E por isso, o kernel Linux tenta ao máximo otimizar os uso da memória, fazendo uso de técnicas como compartilhando de páginas entre processos e Page Cache para melhorar a velocidade de I/O de armazenamento, armazenando um subconjunto de dados do disco na memória. O Page Cache realiza compartilhamento implícito de memória e de forma assíncrona com o armazenamento em segundo plano!</description>
            <content type="html"><![CDATA[<p>RAM é um hardware valioso e caro bem como a sua latência é ainda mais importante que a latência do disco. E por isso, o kernel Linux tenta ao máximo otimizar os uso da memória, fazendo uso de técnicas como compartilhando de páginas entre processos e Page Cache para melhorar a velocidade de I/O de armazenamento, armazenando um subconjunto de dados do disco na memória.
O Page Cache realiza compartilhamento implícito de memória e de forma assíncrona com o armazenamento em segundo plano! Isso por sí só, traz ainda mais complexidade à estimativa de uso de memória por parte dos administradores!</p>
<h2 id="mas-o-que-é-page-cache">Mas o que é Page Cache</h2>
<p>o Page Cache faz parte do <a href="https://en.wikipedia.org/wiki/Virtual_file_system">Virtual File System - VFS</a> que é uma camada de software do núcleo que trata de todas as chamadas de sistema relacionadas a um sistema de arquivos Unix.
Sua principal vantagem é prover uma interface genérica para diversos tipos de sistemas de arquivos. Ou seja, o VFS permite que chamadas de sistemas genéricas, tais como open( ) e read( ),possam ser executadas independentemente do sistema de arquivos usados ou do meio físico! O que implica diretamente na latência de I/O das operações de leitura e gravação.</p>
<ul>
<li>
<p>Quando um sistema grava dados no cache, em algum momento também deve gravar esses dados no armazenamento. O tempo dessa gravação é controlado pelo que é conhecido como <em>write policy</em>, e existem duas abordagens básicas de escrita:</p>
<ul>
<li><em>Write-through</em>: a gravação é feita de forma síncrona tanto no cache quanto no armazenamento de apoio.</li>
<li><em>Write-back</em>: inicialmente, a escrita é feita apenas no cache. A gravação no armazenamento de apoio é adiada até que o conteúdo modificado esteja prestes a ser substituído por outro bloco de cache.
<ul>
<li>Nesse <a href="https://en.wikipedia.org/wiki/Cache_%28computing%29#Writing_policies">link você pode ter mais informações sobre o algorítimo</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Page é a unidade de memória que o Kernel trabalha com Page Cache, e geralmente possui 4k de comprimento mínimo de armazenamento no Page Cache. Dessa forma todo I/O de arquivo está alinhado a uma quantidade específica de páginas&hellip;</p>
<p>Até aqui, podemos entender que o Page Cache, é o principal cache de disco usado pelo kernel do Linux. Sendo utilizado ao ler ou gravar no disco; quando novas páginas são adicionadas ao cache de páginas para satisfazer as solicitações de leitura dos processos do Modo de Usuário.</p>
<ul>
<li>
<p>Se a página ainda não estiver no cache, uma nova entrada será adicionada ao cache e preenchida com os dados lidos do disco. Se houver memória livre suficiente, a página é mantida no cache por um período indefinido e pode então ser reutilizada por outros processos sem acessar o disco.</p>
</li>
<li>
<p>Da mesma forma, antes de gravar uma página de dados em um dispositivo de bloco, o kernel verifica se a página correspondente já está incluída no cache; caso contrário, uma nova entrada é adicionada ao cache e preenchida com os dados a serem gravados no disco.</p>
<ul>
<li>A transferência de dados de I/O não começa imediatamente: a atualização do disco é atrasada por alguns segundos, dando assim aos processos a chance de modificar ainda mais os dados a serem gravados (em outras palavras, o kernel implementa operações de deferred write).</li>
</ul>
</li>
</ul>
<p>As páginas incluídas no Page Cache podem ser dos seguintes tipos:</p>
<ul>
<li>Pages contendo dados de arquivos regulares; no Capítulo 16, descrevemos como o kernel lida com operações de leitura, gravação e mapeamento de memória neles.</li>
<li>Pages contendo diretórios; o Linux lida com os diretórios de forma muito semelhante aos arquivos normais.</li>
<li>Pages contendo dados lidos diretamente de arquivos de dispositivos de bloco (ignorando a camada do sistema de arquivos); o kernel os trata usando o mesmo
conjunto de funções como para pages contendo dados de arquivos regulares.</li>
<li>Pages contendo dados de processos do Modo Usuário que foram trocados em disco; o kernel pode ser forçado a manter-se armazenado em page cache algumas pages cujo conteúdo já foi escrito em uma área de swap.</li>
<li>Pages pertencentes a arquivos de sistemas de arquivos especiais, como o sistema de arquivos especial <em>shm</em> usado para região de memória compartilhada de comunicação entre processos (IPC).</li>
</ul>
<p>Como podemos ver, cada page incluída no Page Cache contém dados pertencentes a algum arquivo. Este arquivo – ou mais precisamente o inode do arquivo – é chamado de page’s owner.</p>
<p>Praticamente todas as operações read() e write() de arquivos dependem do Page Cache.</p>
<ul>
<li>a única exceção ocorre quando um processo abre um arquivo com a flag O_DIRECT definido: neste caso, o cache da página é ignorado e as transferências de dados de E/S fazem uso de buffers no espaço de endereço do modo de usuário do processo.
<ul>
<li>Várias aplicações database fazem uso da flag O_DIRECT pra que assim possam faze uso do próprio algorítimo de caching&hellip;</li>
</ul>
</li>
</ul>
<p>Os projetistas do kernel implementaram o Page Cache para atender a dois requisitos principais:</p>
<ul>
<li>Localizar rapidamente um page específica contendo dados relativos a um determinado proprietário.
Para aproveitar ao máximo o cache da página, pesquisá-lo deve ser uma operação muito rápida.</li>
<li>Acompanhar como cada page do cache deve ser tratada ao ler ou escrever seu conteúdo.
<ul>
<li>Por exemplo, a leitura de uma page de um arquivo regular, ou de um arquivo de dispositivo de bloco ou de uma área de swap, deve ser realizada de diferentes maneiras, portanto o kernel deve selecionar a operação adequada dependendo do proprietário da página.</li>
</ul>
</li>
</ul>
<p>A unidade de informação mantida no page cache é, obviamente, uma página inteira de dados.</p>
<ul>
<li>uma página não contém necessariamente blocos de disco fisicamente adjacentes, portanto ela não pode ser identificada por um número de dispositivo e um número de bloco.
<ul>
<li>Em vez disso, uma página no Page Cache é identificada por um proprietário e por um índice nos dados do proprietário – geralmente, um inode e um deslocamento dentro do arquivo correspondente.</li>
</ul>
</li>
</ul>
<p>A estrutura de dados principal do cache de página é o objeto address_space, uma estrutura de dados incorporada no objeto inode que possui a página.* Muitas páginas no cache podem referir-se ao mesmo proprietário, portanto, podem estar vinculadas ao mesmo objeto address_space. Este objeto também estabelece uma ligação entre as páginas do proprietário e um conjunto de métodos que operam nessas páginas. Cada descritor de página inclui dois campos chamados mapeamento e índice, que vinculam a página ao cache de páginas (consulte a seção “Descritores de páginas” no Capítulo 8). O primeiro campo aponta para o objeto address_space do inode que possui a página. O segundo campo especifica o deslocamento em unidades de tamanho de página dentro do “espaço de endereço” do proprietário, ou seja, a posição dos dados da página dentro da imagem de disco do proprietário. Esses dois campos são usados ao procurar uma página no cache de páginas. Surpreendentemente, o cache de páginas pode conter múltiplas cópias dos mesmos dados do disco. Por exemplo, o mesmo bloco de dados de 4 KB de um arquivo normal pode ser acessado das seguintes maneiras: * Ocorre uma exceção para páginas que foram trocadas. Essas páginas possuem um objeto address_space comum não incluído em nenhum inode.</p>
<p>Dessa forma vamos tentar algumas abordagens para determinar valores mais próximos do real para o consumo de memória RAM.</p>
<h1 id="rss-e-vsz">RSS e VSZ</h1>
<p>Vamos começar tendo como referencia o <strong>VSZ</strong> que é o tamanho da memória virtual que o Linux concedeu a um processo. Mas não necessariamente o processo está usando o valor informado. Um dos motivos são programas com funções para realizar determinadas tarefas, mas só as carregam na RAM, quando necessário. Bem como também a paginação por demanda do Linux, que só carrega páginas na memória quando o aplicativo tenta usá-las&hellip;  Por isso a leitura que devemos fazer do valor é: <em>memória se carregadas todas as suas funções e bibliotecas na memória física.</em></p>
<p>Já <strong>RSS</strong>, é o tamanho do conjunto residente. É a quantidade de RAM que o processo no momento para carregar as suas páginas. Ainda assim não podemos tomar essa informação como concreta, devido as bibliotecas compartilhadas torna-se um  valor impreciso por superestimativa&hellip;</p>
<ol>
<li>
<p>Primeiro criamos um processo em um novo cgroup</p>
<ul>
<li>Rodamos o comanod <em>mtr</em> utilizando o <code>systemd-run</code> para isolá-lo num cgroup(por que sim&hellip;rs)
<pre tabindex="0"><code>systemd-run --user -P -t -G --wait mtr 8.8.8.8
</code></pre></li>
</ul>
</li>
<li>
<p>Em seguida coletamos o seu PID e verificamos os valores de RSS e VSZ</p>
<ul>
<li>Com o comando <code>ps</code> coletamos seu PID e os dados de RSS e VSZ
<ul>
<li>O PID do processo
<pre tabindex="0"><code>$ ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk &#39;{print $2}&#39;
236341
</code></pre></li>
<li>E os dados de RSS e VSZ
<pre tabindex="0"><code>$  ps -o rss,vsz,cmd -p $(ps -aux |grep -E systemd-run.*mtr | grep -v grep |awk &#39;{print $2}&#39;)
  RSS    VSZ CMD
 7168  14940 systemd-run --user -P -t -G --wait mtr 8.8.8.8
</code></pre><ul>
<li>Só a título de cuiriosidade, segue algumas formas de coverter o valor para megabytes:
<pre tabindex="0"><code>$ echo $((7168/1024))
7

ou

$ echo $((7168/1024)) |xargs -i printf &#34;%&#39;.1f MB&#34; {}
7.0 MB

ou

$ numfmt --from=si --to=iec 7168K
6.9M

ou

$ numfmt --from=si --to-unit=1Mi --grouping 7168K
7
</code></pre></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Podemos ver que o processo está consumindo <strong>7168 Kilobytes</strong>.</p>
</li>
<li>
<p>Em seguida usamos o <strong>procfs</strong> para ter mais detalhes desse uso de RAM que o RSS está apontando.</p>
<ul>
<li>Vamos ver o arquivo <code>smaps_rollup</code> que é uma soma das áreas de memória do <code>smaps</code> do nosso PID
<pre tabindex="0"><code>$ cat /proc/236341/smaps_rollup 
559517c38000-7ffe5c398000 ---p 00000000 00:00 0                          [rollup]
Rss:                7368 kB
Pss:                1171 kB
Pss_Dirty:           868 kB
Pss_Anon:            868 kB
Pss_File:            303 kB
Pss_Shmem:             0 kB
Shared_Clean:       6444 kB
Shared_Dirty:          0 kB
Private_Clean:        56 kB
Private_Dirty:       868 kB
Referenced:         7368 kB
Anonymous:           868 kB
LazyFree:              0 kB
AnonHugePages:         0 kB
ShmemPmdMapped:        0 kB
FilePmdMapped:         0 kB
Shared_Hugetlb:        0 kB
Private_Hugetlb:       0 kB
Swap:                  0 kB
SwapPss:               0 kB
Locked:                0 kB
</code></pre>Para as métricas listadas
<ul>
<li><strong>RSS</strong> que já é nossa conhecida.</li>
<li><strong>PSS</strong> Proportional Set Size é o compartilhamento proporcional de memória do processo. É a contagem de páginas que ele possui na memória, onde cada página é dividida pelo número de processos que a compartilham. Portanto, se um processo tiver 1.000 páginas só para ele e 1.000 compartilhadas com outro processo, seu PSS será 1.500.</li>
<li><strong>Shared_Clean</strong> aqui vemos que nosso processo usa cache de página. E representa o maior uso da memória. No arquivo <em>smaps</em>, conseguimos ver todas as bibliotecas compartilhadas que foram abertas com mmap() e residem no Page Cache.</li>
<li><strong>Shared_Dirty</strong> quando o processo grava em arquivos com mmap(), esta linha mostra a quantidade de memória suja do cache de página ainda não salva.</li>
<li><strong>Referenced</strong> é a quantidade de memória referenciada ou acessada até o momento. O valor é sempre igual ou próximo RSS.</li>
<li><strong>Anonymous</strong> mostra a quantidade de memória que não pertence a nenhum arquivo.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Até qui podemos ver que, embora o comando PS e Top nos mostre um RSS de 7MiB, a maior parte de seu RSS está oculto no cache de página e que quando ficarem inativas por um tempo, essas páginas, serão removidas da RAM pelo kernel.</p>
<p><a href="https://lwn.net/Articles/642202/">Nesse artigo</a> do LWN.net temos mais informações direto da fonte ;).</p>
<h1 id="pmap">PMAP</h1>
<p>O kernel Linux 2.6.32 deu ao Linux um recurso chamado “Kernel SamePage Merging”. Isso significa que o Linux pode detectar regiões idênticas de dados em diferentes espaços de endereço. Imagine uma série de máquinas virtuais rodando em um único computador, e todas as máquinas virtuais rodando o mesmo sistema operacional. Usando um modelo de memória compartilhada e cópia na gravação, a sobrecarga no computador host pode ser drasticamente reduzida.</p>
<p>Tudo isso torna sofisticado o manuseio de memória no Linux. Mas é difícil observar um processo e saber qual é realmente o seu uso de memória.</p>
<p>O kernel expõe muito do que está fazendo com a RAM por meio de dois pseudoarquivos no pseudosistema de arquivos de informações do sistema “/proc”. Existem dois arquivos por processo, nomeados de acordo com o ID do processo ou PID de cada processo:* “/proc/$PID/maps” e “/proc/$PID/smaps”.</p>
<p>O valor [ anon ] é o mapeamento de memória anônimo, que faz parte da memória preenchida com dados não retirados do sistema de arquivos, mas alocados quando necessário.</p>
<p>&#x1f596;</p>
<ul>
<li>
<p><em>Address:</em> The beginning memory address allocation</p>
</li>
<li>
<p><em>Kbytes:</em> Memory allocation in kilobytes</p>
</li>
<li>
<p><em>RSS:</em> Resident set size of the process in memory</p>
</li>
<li>
<p><em>Dirty:</em> The status of the memory pages</p>
</li>
<li>
<p><em>Mode:</em> Access mode and privileges</p>
</li>
<li>
<p><em>Mapping:</em> The user-facing name of the application or library</p>
</li>
<li>
<p><em>Offset:</em>	offset into the file</p>
</li>
<li>
<p><em>Device:</em>	device name (major:minor)</p>
</li>
<li>
<p><em>r:</em> The mapped memory can be read by the process.</p>
</li>
<li>
<p><em>w:</em> The mapped memory can be written by the process.</p>
</li>
<li>
<p><em>x:</em> The process can execute any instructions contained in the mapped memory.</p>
</li>
<li>
<p><em>s:</em> The mapped memory is shared, and changes made to the shared memory are visible to all of the processes sharing the memory.</p>
</li>
<li>
<p><em>R:</em> There is no reservation for swap space for this mapped memory.</p>
</li>
<li>
<p><em>Address:</em> The start address of this mapping. This uses virtual memory addressing.</p>
</li>
<li>
<p><em>Perm:</em> The permissions of the memory.</p>
</li>
<li>
<p><em>Offset:</em> If the memory is file-based, the offset of this mapping inside the file.</p>
</li>
<li>
<p><em>Device:</em> The Linux device number, given in major and minor numbers. You can see the device numbers on your computer by running the lsblk command.</p>
</li>
<li>
<p><em>Inode:</em> The inode of the file the mapping is associated with. For example, in our example, this could be the inode that holds information about the pm program.</p>
</li>
<li>
<p><em>Size:</em> The size of the memory-mapped region.</p>
</li>
<li>
<p><em>KernelPageSize:</em> The page size used by the kernel.</p>
</li>
<li>
<p><em>MMUPageSize:</em> The page size used by the memory management unit.</p>
</li>
<li>
<p><em>Rss:</em> This is the resident set size. That is, the amount of memory that is currently in RAM, and not swapped out.</p>
</li>
<li>
<p><em>Pss:</em> This is the proportional share size. This is the private shared size added to the (shared size divided by the number of shares.)</p>
</li>
<li>
<p><em>Shared_Clean:</em> The amount of memory shared with other processes that has not been altered since the mapping was created. Note that even if memory is shareable, if it hasn&rsquo;t actually been shared it is still considered private memory.</p>
</li>
<li>
<p><em>Shared_Dirty:</em> The amount of memory shared with other processes that has been altered since the mapping was created.</p>
</li>
<li>
<p><em>Private_Clean:</em> The amount of private memory&mdash;not shared with other processes&mdash;that has not been altered since the mapping was created.</p>
</li>
<li>
<p><em>Private_Dirty:</em> The amount of private memory that has been altered since the mapping was created.</p>
</li>
<li>
<p><em>Referenced:</em> The amount of memory currently marked as referenced or accessed.</p>
</li>
<li>
<p><em>Anonymous:</em> Memory that does not have a device to swap out to. That is, it isn&rsquo;t file-backed.</p>
</li>
<li>
<p><em>LazyFree:</em> Pages that have been flagged as MADV_FREE. These pages have been marked as available to be freed and reclaimed, even though they may have unwritten changes in them. However, if subsequent changes occur after the MADV_FREE has been set on the memory mapping, the MADV_FREE flag is removed and the pages will not be reclaimed until the changes are written.</p>
</li>
<li>
<p><em>AnonHugePages:</em> These are non-file backed &ldquo;huge&rdquo; memory pages (larger than 4 KB).</p>
</li>
<li>
<p><em>ShmemPmdMapped:</em> Shared memory associated with huge pages. They may also be used by filesystems that reside entirely in memory.</p>
</li>
<li>
<p><em>FilePmdMapped:</em> The Page Middle Directory is one of the paging schemes available to the kernel. This is the number of file-backed pages pointed to by PMD entries.</p>
</li>
<li>
<p><em>Shared_Hugetlb:</em> Translation Lookaside Tables, or TLBs, are memory caches used to optimize the time taken to access userspace memory locations. This figure is the amount of RAM used in TLBs that are associated with shared huge memory pages.</p>
</li>
<li>
<p><em>Private_Hugetlb:</em> This figure is the amount of RAM used in TLBs that are associated with private huge memory pages.</p>
</li>
<li>
<p><em>Swap:</em> The amount of swap being used.</p>
</li>
<li>
<p><em>SwapPss:</em> The swap proportional share size. This is the amount of swap made up of swapped private memory pages added to the (shared size divided by the number of shares.)</p>
</li>
<li>
<p><em>Locked:</em> Memory mappings can be locked to prevent the operating system from paging out heap or off-heap memory.</p>
</li>
<li>
<p><em>THPeligible:</em> This is a flag indicating whether the mapping is eligible for allocating transparent huge pages. 1 means true, 0 means false. Transparent huge pages is a memory management system that reduces the overhead of TLB page lookups on computers with a large amount of RAM.</p>
</li>
<li>
<p><em>VmFlags:</em> See the list of flags below.</p>
</li>
<li>
<p><em>Mapping:</em> The name of the source of the mapping. This can be a process name, library name, or system names such as stack or heap.</p>
</li>
</ul>
<p>The VmFlags - will be a subset of the following list.</p>
<ul>
<li><em>rd:</em> Readable.</li>
<li><em>wr:</em> Writeable.</li>
<li><em>ex:</em> Executable.</li>
<li><em>sh:</em> Shared.</li>
<li><em>mr:</em> May read.</li>
<li><em>mw:</em> May write.</li>
<li><em>me:</em> May execute.</li>
<li><em>ms:</em> May share.</li>
<li><em>gd:</em> Stack segment grows down.</li>
<li><em>pf:</em> Pure page frame number range. Page frame numbers are a list of the physical memory pages.</li>
<li><em>dw:</em> Disabled write to the mapped file.</li>
<li><em>lo:</em> Pages are locked in memory.</li>
<li><em>io:</em> Memory-mapped I/O area.</li>
<li><em>sr:</em> Sequential read advise provided (by the madvise() function.)</li>
<li><em>rr:</em> Random read advise provided.</li>
<li><em>dc:</em> Do not copy this memory region if the process is forked.</li>
<li><em>de:</em> Do not expand this memory region on remapping.</li>
<li><em>ac:</em> Area is accountable.</li>
<li><em>nr:</em> Swap space is not reserved for the area.</li>
<li><em>ht:</em> Area uses huge TLB pages.</li>
<li><em>sf:</em> Synchronous page fault.</li>
<li><em>ar:</em> Architecture-specific flag.</li>
<li><em>wf:</em> Wipe this memory region if the process is forked.</li>
<li><em>dd:</em> Do not include this memory region in core dumps.</li>
<li><em>sd:</em> Soft dirty flag.</li>
<li><em>mm:</em> Mixed map area.</li>
<li><em>hg:</em> Huge page advise flag.</li>
<li><em>nh:</em> No huge page advise flag.</li>
<li><em>mg:</em> Mergeable advise flag.</li>
<li><em>bt:</em> ARM64 bias temperature instability guarded page.</li>
<li><em>mt:</em> ARM64 Memory tagging extension tags are enabled.</li>
<li><em>um:</em> Userfaultfd missing tracking.</li>
<li><em>uw:</em> Userfaultfd wr-protect tracking.</li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
